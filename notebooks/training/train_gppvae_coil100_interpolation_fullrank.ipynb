{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ce9b3e8",
   "metadata": {},
   "source": [
    "# GP-VAE Training on COIL-100 (Interpolation Task) - FullRank Kernel\n",
    "\n",
    "This notebook trains **GP-VAE** on COIL-100 dataset using the **FullRank kernel** for the **interpolation task**.\n",
    "\n",
    "## Task: Interpolation\n",
    "- **Train**: 9 views at even indices (0¬∞, 40¬∞, 80¬∞, 120¬∞, 160¬∞, 200¬∞, 240¬∞, 280¬∞, 320¬∞)\n",
    "- **Val**: 5 views at odd indices (20¬∞, 100¬∞, 180¬∞, 260¬∞, 340¬∞)\n",
    "- **Test**: 4 views (60¬∞, 140¬∞, 220¬∞, 300¬∞)\n",
    "- **Goal**: Predict unseen intermediate views using GP interpolation\n",
    "\n",
    "## Kernel: FullRank\n",
    "- **Free-form learnable covariance matrix** K = L @ L^T\n",
    "- **No geometric assumptions** - ignores angle values entirely\n",
    "- **Parameters**: Q√óQ lower triangular matrix (Q=18 ‚Üí 171 effective params)\n",
    "- **Best for**: Baseline comparison, no prior structure assumed\n",
    "- **Note**: May struggle with interpolation since it doesn't encode angular structure\n",
    "\n",
    "## Dataset Info:\n",
    "- **COIL-100**: 100 objects √ó 18 views (every 20¬∞: 0¬∞, 20¬∞, ..., 340¬∞)\n",
    "- **Image size**: 128√ó128√ó3 RGB\n",
    "\n",
    "## Prerequisites:\n",
    "- ‚úÖ Trained VAE weights from `train_vae_colab_interpolation.ipynb`\n",
    "- ‚úÖ COIL-100 data file: `data/coil-100/coil100_task2_interpolation.h5`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4b48c9",
   "metadata": {},
   "source": [
    "## 1. Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fb3b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è WARNING: GPU not detected!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda651a6",
   "metadata": {},
   "source": [
    "## 2. Auto-Detect Project Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a610256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "print(f\"üìç Current directory: {current_dir}\")\n",
    "\n",
    "# Task configuration\n",
    "DATA_TASK = \"task2_interpolation\"\n",
    "KERNEL_TYPE = \"full_rank\"\n",
    "\n",
    "if current_dir == '/content':\n",
    "    print(\"\\nüîÑ Mounting Google Drive...\")\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        drive_path = '/content/drive/MyDrive/gppvae'\n",
    "        if os.path.exists(drive_path):\n",
    "            PROJECT_PATH = drive_path\n",
    "            print(f\"‚úÖ Found project in Google Drive: {PROJECT_PATH}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Project not found at: {drive_path}\")\n",
    "            PROJECT_PATH = '/content'\n",
    "    except Exception as e:\n",
    "        print(f\"Could not mount Drive: {e}\")\n",
    "        PROJECT_PATH = '/content'\n",
    "else:\n",
    "    if 'notebooks' in current_dir:\n",
    "        PROJECT_PATH = os.path.dirname(current_dir)\n",
    "    else:\n",
    "        PROJECT_PATH = current_dir\n",
    "    print(f\"üíª Using project path: {PROJECT_PATH}\")\n",
    "\n",
    "# Check required files\n",
    "print(f\"\\nüîç Checking required files:\")\n",
    "data_path = os.path.join(PROJECT_PATH, f'data/coil-100/coil100_{DATA_TASK}.h5')\n",
    "required = {\n",
    "    'GPPVAE code': os.path.exists(os.path.join(PROJECT_PATH, 'GPPVAE')),\n",
    "    'COIL-100 data': os.path.exists(data_path),\n",
    "}\n",
    "\n",
    "# Look for VAE weights trained on interpolation task\n",
    "vae_base_dir = os.path.join(PROJECT_PATH, f'out/vae_colab_{DATA_TASK}')\n",
    "vae_run_found = False\n",
    "if os.path.exists(vae_base_dir):\n",
    "    runs = [d for d in os.listdir(vae_base_dir) if os.path.isdir(os.path.join(vae_base_dir, d))]\n",
    "    for run in runs:\n",
    "        weights_dir = os.path.join(vae_base_dir, run, 'weights')\n",
    "        if os.path.exists(weights_dir) and any(f.endswith('.pt') for f in os.listdir(weights_dir)):\n",
    "            vae_run_found = True\n",
    "            break\n",
    "required['VAE weights'] = vae_run_found\n",
    "\n",
    "for name, exists in required.items():\n",
    "    status = \"‚úÖ\" if exists else \"‚ùå\"\n",
    "    print(f\"   {status} {name}\")\n",
    "\n",
    "print(f\"\\nüìä Interpolation Task Info:\")\n",
    "print(f\"   Train: 9 views (even indices) √ó 100 objects = 900 samples\")\n",
    "print(f\"   Val: 5 views (odd indices) √ó 100 objects = 500 samples\")\n",
    "print(f\"   Test: 4 views √ó 100 objects = 400 samples\")\n",
    "print(f\"\\n‚ö†Ô∏è Note: FullRank kernel ignores angular structure - may struggle with interpolation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ecabc5",
   "metadata": {},
   "source": [
    "## 3. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd1aca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q wandb==0.12.21 imageio==2.15.0 pyyaml\n",
    "\n",
    "import wandb\n",
    "import numpy as np\n",
    "print(\"‚úÖ All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e11848",
   "metadata": {},
   "source": [
    "## 4. Login to W&B (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7e0e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b0fb61",
   "metadata": {},
   "source": [
    "## 5. Navigate to Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406b86d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir(PROJECT_PATH)\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "\n",
    "sys.path.insert(0, os.path.join(PROJECT_PATH, 'GPPVAE/pysrc/coil100'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a953f37",
   "metadata": {},
   "source": [
    "## 6. Find VAE Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd9d2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# Look for VAE trained on interpolation task\n",
    "vae_base_dir = f'./out/vae_colab_{DATA_TASK}'\n",
    "vae_runs = []\n",
    "\n",
    "if os.path.exists(vae_base_dir):\n",
    "    for run_dir in sorted(os.listdir(vae_base_dir), reverse=True):\n",
    "        run_path = os.path.join(vae_base_dir, run_dir)\n",
    "        cfg_path = os.path.join(run_path, 'vae.cfg.p')\n",
    "        weights_dir = os.path.join(run_path, 'weights')\n",
    "\n",
    "        if os.path.exists(cfg_path) and os.path.exists(weights_dir):\n",
    "            weight_files = sorted([f for f in os.listdir(weights_dir) if f.endswith('.pt')])\n",
    "            if weight_files:\n",
    "                vae_runs.append({\n",
    "                    'run_dir': run_dir,\n",
    "                    'cfg_path': cfg_path,\n",
    "                    'weights_dir': weights_dir,\n",
    "                    'weight_files': weight_files\n",
    "                })\n",
    "\n",
    "if vae_runs:\n",
    "    print(f\"‚úÖ Found {len(vae_runs)} VAE run(s) for interpolation task\")\n",
    "    latest = vae_runs[0]\n",
    "    print(f\"\\nüí° Latest: {latest['run_dir']}\")\n",
    "    print(f\"   VAE_CFG = '{latest['cfg_path']}'\")\n",
    "    print(f\"   VAE_WEIGHTS = '{os.path.join(latest['weights_dir'], latest['weight_files'][-1])}'\")\n",
    "else:\n",
    "    print(\"‚ùå No VAE runs found for interpolation task!\")\n",
    "    print(\"   Run train_vae_colab_interpolation.ipynb first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c431a5d",
   "metadata": {},
   "source": [
    "## 7. Configure Training\n",
    "\n",
    "**FullRank Kernel:**\n",
    "- No hyperparameters to set - learns free-form Q√óQ covariance\n",
    "- 171 effective parameters for Q=18 views\n",
    "- May overfit on interpolation task due to lack of structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a8f1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# ============================================================================\n",
    "# UPDATE THESE PATHS!\n",
    "# ============================================================================\n",
    "VAE_CFG = './out/vae_colab_task2_interpolation/YYYYMMDD_HHMMSS/vae.cfg.p'  # UPDATE\n",
    "VAE_WEIGHTS = './out/vae_colab_task2_interpolation/YYYYMMDD_HHMMSS/weights/weights.00499.pt'  # UPDATE\n",
    "\n",
    "CONFIG = {\n",
    "    # Data\n",
    "    'data': f'./data/coil-100/coil100_{DATA_TASK}.h5',\n",
    "    'outdir': f'./out/gppvae_coil100_{KERNEL_TYPE}_{DATA_TASK}/{timestamp}',\n",
    "\n",
    "    # VAE\n",
    "    'vae_cfg': VAE_CFG,\n",
    "    'vae_weights': VAE_WEIGHTS,\n",
    "\n",
    "    # Training (increased for early stopping)\n",
    "    'epochs': 1200,\n",
    "    'batch_size': 64,\n",
    "    'vae_lr': 0.001,\n",
    "    'gp_lr': 0.001,\n",
    "    'xdim': 64,\n",
    "\n",
    "    # Kernel - FullRank (no extra parameters needed)\n",
    "    'view_kernel': KERNEL_TYPE,\n",
    "    'kernel_kwargs': {},  # FullRank has no hyperparameters\n",
    "\n",
    "    # Logging\n",
    "    'epoch_cb': 100,\n",
    "    'use_wandb': True,\n",
    "    'wandb_project': 'gppvae-coil100',\n",
    "    'wandb_run_name': f'gppvae_{KERNEL_TYPE}_{DATA_TASK}_{timestamp}',\n",
    "    'seed': 0,\n",
    "}\n",
    "\n",
    "print(\"GP-VAE Training Configuration (Interpolation Task):\")\n",
    "print(\"=\" * 60)\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key:20s}: {value}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if not os.path.exists(CONFIG['vae_weights']):\n",
    "    print(f\"\\n‚ö†Ô∏è Update VAE_CFG and VAE_WEIGHTS paths!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c09c22",
   "metadata": {},
   "source": [
    "## 8. Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f46ad83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Add coil100 to path FIRST before importing anything\n",
    "import sys\n",
    "import os\n",
    "\n",
    "coil100_path = os.path.join(PROJECT_PATH, 'GPPVAE/pysrc/coil100')\n",
    "sys.path.insert(0, coil100_path)\n",
    "\n",
    "os.chdir(coil100_path)\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from vae import FaceVAE\n",
    "from vmod import Vmodel\n",
    "from gp import GP\n",
    "import numpy as np\n",
    "import logging\n",
    "import pylab as pl\n",
    "from utils import smartSum, smartAppendDict, smartAppend, export_scripts\n",
    "from callbacks import callback_gppvae\n",
    "import pickle\n",
    "import time\n",
    "import wandb\n",
    "\n",
    "from data_parser import COIL100Dataset, get_n_views, get_num_objects\n",
    "\n",
    "import data_parser\n",
    "print(f\"‚úÖ data_parser loaded from: {data_parser.__file__}\")\n",
    "if 'coil100' in data_parser.__file__:\n",
    "    print(\"‚úÖ Using COIL-100 data_parser (correct!)\")\n",
    "else:\n",
    "    print(\"‚ùå WARNING: Using faceplace data_parser (wrong!)\")\n",
    "print(\"‚úÖ All modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9827097",
   "metadata": {},
   "source": [
    "## 9. Setup Training Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f1145b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(PROJECT_PATH)\n",
    "\n",
    "outdir = CONFIG['outdir']\n",
    "wdir = os.path.join(outdir, \"weights\")\n",
    "fdir = os.path.join(outdir, \"plots\")\n",
    "os.makedirs(wdir, exist_ok=True)\n",
    "os.makedirs(fdir, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "log_format = \"%(asctime)s %(message)s\"\n",
    "logging.basicConfig(level=logging.INFO, format=log_format, datefmt=\"%m/%d %I:%M:%S %p\")\n",
    "fh = logging.FileHandler(os.path.join(outdir, \"log.txt\"))\n",
    "fh.setFormatter(logging.Formatter(log_format))\n",
    "logging.getLogger().addHandler(fh)\n",
    "\n",
    "export_scripts(os.path.join(outdir, \"scripts\"))\n",
    "print(f\"‚úÖ Output: {outdir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0a6967",
   "metadata": {},
   "source": [
    "## 10. Initialize Models\n",
    "\n",
    "**FullRank Kernel for Interpolation:**\n",
    "- Learns free-form covariance between all 18 view indices\n",
    "- No angular structure encoded - treats views as unordered categories\n",
    "- Challenge: Must learn that view 1 (20¬∞) is \"between\" views 0 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f1b150",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(CONFIG['seed'])\n",
    "\n",
    "if CONFIG['use_wandb']:\n",
    "    wandb.init(project=CONFIG['wandb_project'], name=CONFIG['wandb_run_name'], config=CONFIG)\n",
    "\n",
    "# Load VAE\n",
    "vae_cfg = pickle.load(open(CONFIG['vae_cfg'], \"rb\"))\n",
    "vae = FaceVAE(**vae_cfg).to(device)\n",
    "vae.load_state_dict(torch.load(CONFIG['vae_weights'], map_location=device))\n",
    "print(f\"‚úÖ VAE loaded\")\n",
    "\n",
    "# Load data\n",
    "train_data = COIL100Dataset(CONFIG['data'], split='train', use_angle_encoding=False)\n",
    "val_data = COIL100Dataset(CONFIG['data'], split='val', use_angle_encoding=False)\n",
    "train_queue = DataLoader(train_data, batch_size=CONFIG['batch_size'], shuffle=True)\n",
    "val_queue = DataLoader(val_data, batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "\n",
    "P = get_num_objects(CONFIG['data'])\n",
    "Q = get_n_views()\n",
    "print(f\"P={P}, Q={Q}\")\n",
    "\n",
    "# Show interpolation task structure\n",
    "train_views = sorted(train_data.Rid.unique().tolist())\n",
    "val_views = sorted(val_data.Rid.unique().tolist())\n",
    "print(f\"\\nüìä Interpolation Task:\")\n",
    "print(f\"   Train views (Rid): {train_views} ‚Üí angles {[v*20 for v in train_views]}¬∞\")\n",
    "print(f\"   Val views (Rid):   {val_views} ‚Üí angles {[v*20 for v in val_views]}¬∞\")\n",
    "print(f\"   Train samples: {len(train_data)}, Val samples: {len(val_data)}\")\n",
    "\n",
    "# Create tensors\n",
    "Dt = Variable(train_data.Did.long(), requires_grad=False).to(device)\n",
    "Dv = Variable(val_data.Did.long(), requires_grad=False).to(device)\n",
    "Wt = Variable(train_data.Rid.long(), requires_grad=False).to(device)\n",
    "Wv = Variable(val_data.Rid.long(), requires_grad=False).to(device)\n",
    "\n",
    "# Initialize Vmodel with FullRank kernel\n",
    "print(f\"\\nüî¨ Initializing '{KERNEL_TYPE}' kernel (Q={Q} ‚Üí {Q*(Q+1)//2} effective params)...\")\n",
    "vm = Vmodel(P=P, Q=Q, p=CONFIG['xdim'], view_kernel=CONFIG['view_kernel'], **CONFIG['kernel_kwargs']).to(device)\n",
    "gp = GP(n_rand_effs=1).to(device)\n",
    "\n",
    "# Show initial kernel matrix\n",
    "K = vm.get_kernel_matrix()\n",
    "print(f\"\\nüìà Initial kernel (identity since L starts as I):\")\n",
    "print(f\"   K[0,0]={K[0,0].item():.4f} (self)\")\n",
    "print(f\"   K[0,1]={K[0,1].item():.4f} (views 0-1)\")\n",
    "print(f\"   K[0,2]={K[0,2].item():.4f} (views 0-2)\")\n",
    "\n",
    "gp_params = nn.ParameterList()\n",
    "gp_params.extend(vm.parameters())\n",
    "gp_params.extend(gp.parameters())\n",
    "\n",
    "vae_optimizer = optim.Adam(vae.parameters(), lr=CONFIG['vae_lr'])\n",
    "gp_optimizer = optim.Adam(gp_params, lr=CONFIG['gp_lr'])\n",
    "print(f\"\\n‚úÖ Models initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb67e46",
   "metadata": {},
   "source": [
    "## 11. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fea6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_Y(vae, train_queue):\n",
    "    vae.eval()\n",
    "    with torch.no_grad():\n",
    "        n = train_queue.dataset.Y.shape[0]\n",
    "        Zm = Variable(torch.zeros(n, vae_cfg[\"zdim\"]), requires_grad=False).to(device)\n",
    "        Zs = Variable(torch.zeros(n, vae_cfg[\"zdim\"]), requires_grad=False).to(device)\n",
    "        for data in train_queue:\n",
    "            y = data[0].to(device)\n",
    "            idxs = data[-1].to(device)\n",
    "            zm, zs = vae.encode(y)\n",
    "            Zm[idxs], Zs[idxs] = zm.detach(), zs.detach()\n",
    "    return Zm, Zs\n",
    "\n",
    "def eval_step(vae, gp, vm, val_queue, Zm, Vt, Vv, Wv, val_Rid):\n",
    "    \"\"\"Evaluate GP-VAE on validation set with per-view MSE tracking.\"\"\"\n",
    "    rv = {}\n",
    "    with torch.no_grad():\n",
    "        _X = vm.x().data.cpu().numpy()\n",
    "        _W = vm.v().data.cpu().numpy()\n",
    "        covs = {\"XX\": np.dot(_X, _X.T), \"WW\": np.dot(_W, _W.T)}\n",
    "        rv[\"vars\"] = gp.get_vs().data.cpu().numpy()\n",
    "\n",
    "        vs = gp.get_vs()\n",
    "        U, UBi, _ = gp.U_UBi_Shb([Vt], vs)\n",
    "        Kiz = gp.solve(Zm, U, UBi, vs)\n",
    "        Zo = vs[0] * Vv.mm(Vt.transpose(0, 1).mm(Kiz))\n",
    "\n",
    "        mse_out = Variable(torch.zeros(Vv.shape[0], 1), requires_grad=False).to(device)\n",
    "        mse_val = Variable(torch.zeros(Vv.shape[0], 1), requires_grad=False).to(device)\n",
    "        all_Yv, all_Yr, all_Yo = [], [], []\n",
    "\n",
    "        for data in val_queue:\n",
    "            idxs = data[-1].to(device)\n",
    "            Yv = data[0].to(device)\n",
    "            Zv = vae.encode(Yv)[0].detach()\n",
    "            Yr = vae.decode(Zv)\n",
    "            Yo = vae.decode(Zo[idxs])\n",
    "\n",
    "            mse_out[idxs] = ((Yv - Yo) ** 2).view(Yv.shape[0], -1).mean(1)[:, None].detach()\n",
    "            mse_val[idxs] = ((Yv - Yr) ** 2).view(Yv.shape[0], -1).mean(1)[:, None].detach()\n",
    "            all_Yv.append(Yv.data.cpu().numpy().transpose(0, 2, 3, 1))\n",
    "            all_Yr.append(Yr.data.cpu().numpy().transpose(0, 2, 3, 1))\n",
    "            all_Yo.append(Yo.data.cpu().numpy().transpose(0, 2, 3, 1))\n",
    "\n",
    "        all_Yv = np.concatenate(all_Yv, axis=0)\n",
    "        all_Yr = np.concatenate(all_Yr, axis=0)\n",
    "        all_Yo = np.concatenate(all_Yo, axis=0)\n",
    "        n_total = all_Yv.shape[0]\n",
    "        sample_indices = np.arange(0, n_total, max(1, n_total // 24))[:24]\n",
    "        imgs = {\"Yv\": all_Yv[sample_indices], \"Yr\": all_Yr[sample_indices], \"Yo\": all_Yo[sample_indices]}\n",
    "        rv[\"mse_out\"] = float(mse_out.data.mean().cpu())\n",
    "        rv[\"mse_val\"] = float(mse_val.data.mean().cpu())\n",
    "        \n",
    "        # Compute per-view MSE\n",
    "        mse_out_cpu = mse_out.data.cpu().squeeze()\n",
    "        val_Rid_cpu = val_Rid.cpu()\n",
    "        unique_views = torch.unique(val_Rid_cpu).tolist()\n",
    "        for view_idx in unique_views:\n",
    "            mask = (val_Rid_cpu == view_idx)\n",
    "            view_mse = mse_out_cpu[mask].mean().item()\n",
    "            angle = int(view_idx * 20)\n",
    "            rv[f\"mse_view_{angle:03d}\"] = view_mse\n",
    "        \n",
    "    return rv, imgs, covs\n",
    "\n",
    "def backprop_and_update(vae, gp, vm, train_queue, Dt, Wt, Eps, Zb, Vbs, vbs, vae_optimizer, gp_optimizer):\n",
    "    rv = {}\n",
    "    vae_optimizer.zero_grad()\n",
    "    gp_optimizer.zero_grad()\n",
    "    vae.train(); gp.train(); vm.train()\n",
    "\n",
    "    for data in train_queue:\n",
    "        y = data[0].to(device)\n",
    "        eps = Eps[data[-1]]\n",
    "        _d, _w = Dt[data[-1]], Wt[data[-1]]\n",
    "        _Zb = Zb[data[-1]]\n",
    "        _Vbs = [Vbs[0][data[-1]]]\n",
    "\n",
    "        zm, zs = vae.encode(y)\n",
    "        z = zm + zs * eps\n",
    "        yr = vae.decode(z)\n",
    "        recon_term, mse = vae.nll(y, yr)\n",
    "\n",
    "        _Vs = [vm(_d, _w)]\n",
    "        gp_nll_fo = gp.taylor_expansion(z, _Vs, _Zb, _Vbs, vbs) / vae.K\n",
    "        pen_term = -0.5 * zs.sum(1)[:, None] / vae.K\n",
    "\n",
    "        loss = (recon_term + gp_nll_fo + pen_term).sum()\n",
    "        loss.backward()\n",
    "\n",
    "        _n = train_queue.dataset.Y.shape[0]\n",
    "        smartSum(rv, \"mse\", float(mse.data.sum().cpu()) / _n)\n",
    "        smartSum(rv, \"recon_term\", float(recon_term.data.sum().cpu()) / _n)\n",
    "        smartSum(rv, \"pen_term\", float(pen_term.data.sum().cpu()) / _n)\n",
    "\n",
    "    vae_optimizer.step()\n",
    "    gp_optimizer.step()\n",
    "    return rv\n",
    "\n",
    "print(\"‚úÖ Training functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafa8d4f",
   "metadata": {},
   "source": [
    "## 12. Train GP-VAE üöÄ (with Early Stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5728ca2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {}\n",
    "start_time = time.time()\n",
    "\n",
    "# -----------------------------\n",
    "# Early stopping configuration\n",
    "# -----------------------------\n",
    "early_stop_patience = 150        # epochs without improvement\n",
    "early_stop_min_delta = 1e-4      # minimum improvement threshold\n",
    "\n",
    "best_mse_out = float(\"inf\")\n",
    "best_epoch = -1\n",
    "no_improve_epochs = 0\n",
    "\n",
    "# Get validation view indices for per-view MSE tracking\n",
    "val_Rid = val_data.Rid.to(device)\n",
    "val_view_angles = sorted([int(v * 20) for v in val_data.Rid.unique().tolist()])\n",
    "print(f\"üìä Tracking per-view MSE for validation angles: {val_view_angles}¬∞\")\n",
    "\n",
    "print(f\"\\nüöÄ Training GP-VAE with {KERNEL_TYPE} kernel for up to {CONFIG['epochs']} epochs...\")\n",
    "print(f\"üõë Early stopping patience = {early_stop_patience}\")\n",
    "print(f\"   Task: INTERPOLATION (predicting unseen intermediate views)\")\n",
    "print(f\"   ‚ö†Ô∏è FullRank has no angular structure - baseline comparison\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for epoch in range(CONFIG['epochs']):\n",
    "    epoch_start = time.time()\n",
    "\n",
    "    # -------- Encode training data --------\n",
    "    Zm, Zs = encode_Y(vae, train_queue)\n",
    "    Eps = Variable(torch.randn(*Zs.shape), requires_grad=False).to(device)\n",
    "    Z = Zm + Eps * Zs\n",
    "\n",
    "    # -------- Precompute V --------\n",
    "    Vt = vm(Dt, Wt).detach()\n",
    "    Vv = vm(Dv, Wv).detach()\n",
    "\n",
    "    # -------- Validation step --------\n",
    "    rv_eval, imgs, covs = eval_step(\n",
    "        vae, gp, vm, val_queue, Zm, Vt, Vv, Wv, val_Rid\n",
    "    )\n",
    "\n",
    "    # -------- GP Taylor expansion --------\n",
    "    Zb, Vbs, vbs, gp_nll = gp.taylor_coeff(Z, [Vt])\n",
    "    rv_eval[\"gp_nll\"] = float(gp_nll.data.mean().cpu()) / vae.K\n",
    "\n",
    "    # -------- Backprop --------\n",
    "    rv_back = backprop_and_update(\n",
    "        vae, gp, vm, train_queue, Dt, Wt,\n",
    "        Eps, Zb, Vbs, vbs,\n",
    "        vae_optimizer, gp_optimizer\n",
    "    )\n",
    "\n",
    "    rv_back[\"loss\"] = (\n",
    "        rv_back[\"recon_term\"] +\n",
    "        rv_eval[\"gp_nll\"] +\n",
    "        rv_back[\"pen_term\"]\n",
    "    )\n",
    "\n",
    "    # -------- Logging --------\n",
    "    smartAppendDict(history, rv_eval)\n",
    "    smartAppendDict(history, rv_back)\n",
    "    smartAppend(history, \"vs\", gp.get_vs().data.cpu().numpy())\n",
    "\n",
    "    vs = gp.get_vs().data.cpu().numpy()\n",
    "    variance_ratio = vs[0] / (vs[0] + vs[1])\n",
    "\n",
    "    current_mse_out = rv_eval[\"mse_out\"]\n",
    "\n",
    "    # -------- Early stopping check --------\n",
    "    if current_mse_out < best_mse_out - early_stop_min_delta:\n",
    "        best_mse_out = current_mse_out\n",
    "        best_epoch = epoch\n",
    "        no_improve_epochs = 0\n",
    "\n",
    "        # Save BEST checkpoint\n",
    "        torch.save(\n",
    "            vae.state_dict(),\n",
    "            os.path.join(wdir, \"vae_weights.best.pt\")\n",
    "        )\n",
    "        torch.save(\n",
    "            {'gp_state': gp.state_dict(), 'vm_state': vm.state_dict()},\n",
    "            os.path.join(wdir, \"gp_weights.best.pt\")\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        no_improve_epochs += 1\n",
    "\n",
    "    # -------- Console output --------\n",
    "    if epoch % 5 == 0 or epoch == CONFIG['epochs'] - 1:\n",
    "        view_mse_str = \" | \".join([f\"{a}¬∞:{rv_eval[f'mse_view_{a:03d}']:.4f}\" for a in val_view_angles])\n",
    "        print(\n",
    "            f\"Epoch {epoch:4d} | \"\n",
    "            f\"MSE train: {rv_back['mse']:.6f} | \"\n",
    "            f\"MSE interp: {current_mse_out:.6f} | \"\n",
    "            f\"GP NLL: {rv_eval['gp_nll']:.4f} | \"\n",
    "            f\"v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): {variance_ratio:.3f}\"\n",
    "        )\n",
    "        print(f\"         Per-view: {view_mse_str}\")\n",
    "\n",
    "    # -------- wandb --------\n",
    "    if CONFIG['use_wandb']:\n",
    "        log_dict = {\n",
    "            \"epoch\": epoch,\n",
    "            \"mse_train\": rv_back[\"mse\"],\n",
    "            \"mse_interp\": current_mse_out,\n",
    "            \"gp_nll\": rv_eval[\"gp_nll\"],\n",
    "            \"variance_ratio\": variance_ratio,\n",
    "            \"best_mse_out\": best_mse_out,\n",
    "            \"no_improve_epochs\": no_improve_epochs,\n",
    "        }\n",
    "        for angle in val_view_angles:\n",
    "            log_dict[f\"mse_view_{angle:03d}\"] = rv_eval[f\"mse_view_{angle:03d}\"]\n",
    "        wandb.log(log_dict)\n",
    "\n",
    "    # -------- Periodic checkpoint + plots --------\n",
    "    if epoch % CONFIG['epoch_cb'] == 0 or epoch == CONFIG['epochs'] - 1:\n",
    "        torch.save(\n",
    "            vae.state_dict(),\n",
    "            os.path.join(wdir, f\"vae_weights.{epoch:05d}.pt\")\n",
    "        )\n",
    "        torch.save(\n",
    "            {'gp_state': gp.state_dict(), 'vm_state': vm.state_dict()},\n",
    "            os.path.join(wdir, f\"gp_weights.{epoch:05d}.pt\")\n",
    "        )\n",
    "        ffile = os.path.join(fdir, f\"plot.{epoch:05d}.png\")\n",
    "        callback_gppvae(epoch, history, covs, imgs, ffile)\n",
    "        if CONFIG['use_wandb']:\n",
    "            wandb.log({\"reconstructions\": wandb.Image(ffile)})\n",
    "        print(\"  ‚úì Checkpoint saved\")\n",
    "\n",
    "    # -------- Stop condition --------\n",
    "    if no_improve_epochs >= early_stop_patience:\n",
    "        print(\n",
    "            f\"\\n‚èπ Early stopping triggered at epoch {epoch}\\n\"\n",
    "            f\"   Best epoch: {best_epoch}\\n\"\n",
    "            f\"   Best mse_out: {best_mse_out:.6f}\"\n",
    "        )\n",
    "        break\n",
    "\n",
    "print(\n",
    "    f\"\\n‚úÖ Training complete in {(time.time()-start_time)/60:.1f} min\\n\"\n",
    "    f\"   Best epoch: {best_epoch}\\n\"\n",
    "    f\"   Best mse_out: {best_mse_out:.6f}\"\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Final per-view MSE:\")\n",
    "for angle in val_view_angles:\n",
    "    print(f\"   {angle:3d}¬∞: {rv_eval[f'mse_view_{angle:03d}']:.6f}\")\n",
    "\n",
    "if CONFIG['use_wandb']:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cca6154",
   "metadata": {},
   "source": [
    "## 13. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6c2c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_data = COIL100Dataset(CONFIG['data'], split='test', use_angle_encoding=False)\n",
    "test_queue = DataLoader(test_data, batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "\n",
    "test_views = sorted(test_data.Rid.unique().tolist())\n",
    "print(f\"Test views (Rid): {test_views} ‚Üí angles {[v*20 for v in test_views]}¬∞\")\n",
    "print(f\"Test samples: {len(test_data)}\")\n",
    "\n",
    "Dtest = Variable(test_data.Did.long(), requires_grad=False).to(device)\n",
    "Wtest = Variable(test_data.Rid.long(), requires_grad=False).to(device)\n",
    "\n",
    "vae.eval(); vm.eval(); gp.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    Zm, _ = encode_Y(vae, train_queue)\n",
    "    Vt = vm(Dt, Wt).detach()\n",
    "    Vtest = vm(Dtest, Wtest).detach()\n",
    "\n",
    "    vs = gp.get_vs()\n",
    "    U, UBi, _ = gp.U_UBi_Shb([Vt], vs)\n",
    "    Kiz = gp.solve(Zm, U, UBi, vs)\n",
    "    Zo_test = vs[0] * Vtest.mm(Vt.transpose(0, 1).mm(Kiz))\n",
    "\n",
    "    test_Rid = test_data.Rid\n",
    "    mse_per_view = {}\n",
    "    mse_test_total = 0.0\n",
    "    \n",
    "    for data in test_queue:\n",
    "        idxs = data[-1].to(device)\n",
    "        Ytest = data[0].to(device)\n",
    "        Yo = vae.decode(Zo_test[idxs])\n",
    "        mse_batch = ((Ytest - Yo) ** 2).view(Ytest.shape[0], -1).mean(1)\n",
    "        \n",
    "        for i, idx in enumerate(data[-1]):\n",
    "            view = int(test_Rid[idx].item())\n",
    "            if view not in mse_per_view:\n",
    "                mse_per_view[view] = []\n",
    "            mse_per_view[view].append(mse_batch[i].item())\n",
    "        \n",
    "        mse_test_total += mse_batch.sum().item()\n",
    "\n",
    "    mse_test = mse_test_total / len(test_data)\n",
    "    print(f\"\\nüéØ Test MSE (interpolation): {mse_test:.6f}\")\n",
    "    print(f\"\\nüìä Test per-view MSE:\")\n",
    "    for view in sorted(mse_per_view.keys()):\n",
    "        angle = int(view * 20)\n",
    "        view_mse = np.mean(mse_per_view[view])\n",
    "        print(f\"   {angle:3d}¬∞: {view_mse:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec7f3a4",
   "metadata": {},
   "source": [
    "## 14. View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0f6679",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import glob\n",
    "\n",
    "plot_files = sorted(glob.glob(os.path.join(fdir, \"*.png\")))\n",
    "if plot_files:\n",
    "    display(Image(filename=plot_files[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32050d10",
   "metadata": {},
   "source": [
    "## 15. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf5a955",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r /content/gppvae_fullrank_interpolation_output.zip {CONFIG['outdir']}\n",
    "from google.colab import files\n",
    "files.download('/content/gppvae_fullrank_interpolation_output.zip')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
