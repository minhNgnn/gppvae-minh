{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f8a173e",
   "metadata": {
    "id": "0f8a173e"
   },
   "source": [
    "# GP-VAE Training on Google Colab\n",
    "\n",
    "This notebook trains the **GP-VAE (Gaussian Process Variational Autoencoder)** model using Google Colab's free GPU.\n",
    "\n",
    "## What is GP-VAE?\n",
    "GP-VAE adds a **Gaussian Process prior** to the VAE latent space to model structured correlations:\n",
    "- **VAE**: Learns image ‚Üî latent code mapping\n",
    "- **GP Prior**: Models correlations between latent codes based on:\n",
    "  - Object identity (same person's face)\n",
    "  - View angle (front, side, profile)\n",
    "  - Other factors of variation\n",
    "\n",
    "## Prerequisites ‚ö†Ô∏è\n",
    "**You MUST have trained VAE weights first!** This model loads pre-trained VAE and fine-tunes it jointly with the GP.\n",
    "\n",
    "Required files:\n",
    "- ‚úÖ `out/vae_colab/YYYYMMDD_HHMMSS/vae.cfg.p` - VAE configuration\n",
    "- ‚úÖ `out/vae_colab/YYYYMMDD_HHMMSS/weights/weights.00000.pt` - Trained VAE weights\n",
    "\n",
    "## Output Directory Structure:\n",
    "\n",
    "Each training run creates a **timestamped directory** to avoid overwriting previous runs:\n",
    "- Format: `./out/gppvae_colab/YYYYMMDD_HHMMSS/`\n",
    "- Example: `./out/gppvae_colab/20251224_143530/weights/weights.00100.pt`\n",
    "- This allows you to compare different training runs and keep a history!\n",
    "\n",
    "Cell 6 below will automatically find your latest VAE training run.\n",
    "\n",
    "## Setup Instructions:\n",
    "\n",
    "1. **Open this notebook in VS Code**\n",
    "2. **Connect to Colab**: Click kernel picker ‚Üí \"Connect to Colab\" ‚Üí Choose **GPU runtime (T4)**\n",
    "3. **Important**: When prompted with \"Alias your server\", press Enter\n",
    "4. **Run cell 2** - it will automatically detect your project location\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d4d88e",
   "metadata": {
    "id": "a7d4d88e"
   },
   "source": [
    "## 1. Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9450aba9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9450aba9",
    "outputId": "deb4f4a3-5f0c-4034-c366-71bc7cd7826b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.0+cpu\n",
      "CUDA available: False\n",
      "‚ö†Ô∏è WARNING: GPU not detected! Go to Runtime ‚Üí Change runtime type ‚Üí GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è WARNING: GPU not detected! Go to Runtime ‚Üí Change runtime type ‚Üí GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a792140f",
   "metadata": {
    "id": "a792140f"
   },
   "source": [
    "## 2. Auto-Detect Project Path\n",
    "\n",
    "This automatically finds your project files on the Colab runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33fa06a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33fa06a0",
    "outputId": "ebe5a2e6-1fb2-4b38-8a8f-cf37ab98a6dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìç Current directory: /content\n",
      "\n",
      "üîÑ Mounting Google Drive...\n",
      "Mounted at /content/drive\n",
      "‚úÖ Found project in Google Drive: /content/drive/MyDrive/gppvae\n",
      "\n",
      "üìÅ Contents of /content/drive/MyDrive/gppvae:\n",
      "   üìÇ GPPVAE/\n",
      "   üìÇ data/\n",
      "   üìÑ environment.yml\n",
      "   üìÇ notebooks/\n",
      "   üìÇ out/\n",
      "\n",
      "üîç Checking required files:\n",
      "   ‚úÖ GPPVAE code\n",
      "   ‚úÖ data/faceplace\n",
      "   ‚úÖ data_faces.h5\n",
      "   ‚úÖ VAE config\n",
      "   ‚úÖ VAE weights\n",
      "\n",
      "üì¶ Found 3 VAE training run(s):\n",
      "   1. 20251224_171841/ (11 checkpoints)\n",
      "      Latest: weights.00099.pt\n",
      "   2. 20251224_171753/ (0 checkpoints)\n",
      "   3. 20251224_120136/ (16 checkpoints)\n",
      "      Latest: weights.00140.pt\n",
      "\n",
      "üí° Cell 6 below will help you choose which run to use\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Get current directory\n",
    "current_dir = os.getcwd()\n",
    "print(f\"üìç Current directory: {current_dir}\")\n",
    "\n",
    "# Check if on Colab and need to mount Drive\n",
    "if current_dir == '/content':\n",
    "    print(\"\\nüîÑ Mounting Google Drive...\")\n",
    "\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "\n",
    "        # Check for project in Drive\n",
    "        drive_path = '/content/drive/MyDrive/gppvae'\n",
    "        if os.path.exists(drive_path):\n",
    "            PROJECT_PATH = drive_path\n",
    "            print(f\"‚úÖ Found project in Google Drive: {PROJECT_PATH}\")\n",
    "        else:\n",
    "            print(f\"\\n‚ö†Ô∏è  Project not found at: {drive_path}\")\n",
    "            print(\"\\nPlease upload your gppvae folder to Google Drive!\")\n",
    "            print(\"Required structure:\")\n",
    "            print(\"  MyDrive/gppvae/\")\n",
    "            print(\"    ‚îú‚îÄ‚îÄ GPPVAE/\")\n",
    "            print(\"    ‚îú‚îÄ‚îÄ data/faceplace/data_faces.h5\")\n",
    "            print(\"    ‚îî‚îÄ‚îÄ out/vae_colab/YYYYMMDD_HHMMSS/\")\n",
    "            print(\"        ‚îú‚îÄ‚îÄ vae.cfg.p\")\n",
    "            print(\"        ‚îî‚îÄ‚îÄ weights/weights.00000.pt\")\n",
    "            PROJECT_PATH = '/content'\n",
    "    except Exception as e:\n",
    "        print(f\"Could not mount Drive: {e}\")\n",
    "        PROJECT_PATH = '/content'\n",
    "else:\n",
    "    # Running via VS Code sync\n",
    "    if 'notebooks' in current_dir:\n",
    "        PROJECT_PATH = os.path.dirname(current_dir)\n",
    "    else:\n",
    "        PROJECT_PATH = current_dir\n",
    "    print(f\"üíª Using project path: {PROJECT_PATH}\")\n",
    "\n",
    "# Verify structure\n",
    "print(f\"\\nüìÅ Contents of {PROJECT_PATH}:\")\n",
    "if os.path.exists(PROJECT_PATH):\n",
    "    items = os.listdir(PROJECT_PATH)\n",
    "    for item in sorted(items)[:15]:\n",
    "        item_path = os.path.join(PROJECT_PATH, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            print(f\"   üìÇ {item}/\")\n",
    "        else:\n",
    "            print(f\"   üìÑ {item}\")\n",
    "\n",
    "    # Check required files (with timestamped directory structure)\n",
    "    print(f\"\\nüîç Checking required files:\")\n",
    "    required = {\n",
    "        'GPPVAE code': os.path.exists(os.path.join(PROJECT_PATH, 'GPPVAE')),\n",
    "        'data/faceplace': os.path.exists(os.path.join(PROJECT_PATH, 'data/faceplace')),\n",
    "        'data_faces.h5': os.path.exists(os.path.join(PROJECT_PATH, 'data/faceplace/data_faces.h5')),\n",
    "    }\n",
    "\n",
    "    # Check for VAE runs (timestamped subdirectories)\n",
    "    vae_base_dir = os.path.join(PROJECT_PATH, 'out/vae_colab')\n",
    "    vae_run_found = False\n",
    "    vae_weights_found = False\n",
    "\n",
    "    if os.path.exists(vae_base_dir):\n",
    "        # Look for timestamped subdirectories\n",
    "        potential_runs = [d for d in os.listdir(vae_base_dir)\n",
    "                         if os.path.isdir(os.path.join(vae_base_dir, d)) and d[0].isdigit()]\n",
    "\n",
    "        for run_dir in potential_runs:\n",
    "            run_path = os.path.join(vae_base_dir, run_dir)\n",
    "            cfg_path = os.path.join(run_path, 'vae.cfg.p')\n",
    "            weights_dir = os.path.join(run_path, 'weights')\n",
    "\n",
    "            if os.path.exists(cfg_path):\n",
    "                vae_run_found = True\n",
    "\n",
    "            if os.path.exists(weights_dir):\n",
    "                weight_files = [f for f in os.listdir(weights_dir) if f.endswith('.pt')]\n",
    "                if weight_files:\n",
    "                    vae_weights_found = True\n",
    "                    break\n",
    "\n",
    "    required['VAE config'] = vae_run_found\n",
    "    required['VAE weights'] = vae_weights_found\n",
    "\n",
    "    for name, exists in required.items():\n",
    "        status = \"‚úÖ\" if exists else \"‚ùå\"\n",
    "        print(f\"   {status} {name}\")\n",
    "\n",
    "    # Show VAE runs if they exist\n",
    "    if os.path.exists(vae_base_dir):\n",
    "        potential_runs = sorted([d for d in os.listdir(vae_base_dir)\n",
    "                                if os.path.isdir(os.path.join(vae_base_dir, d)) and d[0].isdigit()],\n",
    "                               reverse=True)\n",
    "\n",
    "        if potential_runs:\n",
    "            print(f\"\\nüì¶ Found {len(potential_runs)} VAE training run(s):\")\n",
    "            for i, run_dir in enumerate(potential_runs[:3], 1):  # Show latest 3\n",
    "                run_path = os.path.join(vae_base_dir, run_dir)\n",
    "                weights_dir = os.path.join(run_path, 'weights')\n",
    "\n",
    "                if os.path.exists(weights_dir):\n",
    "                    weight_files = sorted([f for f in os.listdir(weights_dir) if f.endswith('.pt')])\n",
    "                    print(f\"   {i}. {run_dir}/ ({len(weight_files)} checkpoints)\")\n",
    "                    if weight_files:\n",
    "                        print(f\"      Latest: {weight_files[-1]}\")\n",
    "\n",
    "            if len(potential_runs) > 3:\n",
    "                print(f\"   ... and {len(potential_runs) - 3} more\")\n",
    "\n",
    "            print(f\"\\nüí° Cell 6 below will help you choose which run to use\")\n",
    "\n",
    "    if not all(required.values()):\n",
    "        print(f\"\\n‚ö†Ô∏è  Missing required files!\")\n",
    "        if not required['VAE weights']:\n",
    "            print(\"\\nüö® CRITICAL: No trained VAE weights found!\")\n",
    "            print(\"   You must train VAE first before running GP-VAE\")\n",
    "            print(\"   Use the train_vae_colab.ipynb notebook\")\n",
    "else:\n",
    "    print(f\"‚ùå Path doesn't exist: {PROJECT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd61ed4d",
   "metadata": {
    "id": "dd61ed4d"
   },
   "source": [
    "## 3. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eb3366a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5eb3366a",
    "outputId": "027a06c6-024e-4d67-beea-996b4ba9e7de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m√ó\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m√ó\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "‚úÖ All dependencies installed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install -q wandb==0.12.21 imageio==2.15.0 pyyaml\n",
    "\n",
    "# Verify installations\n",
    "import wandb\n",
    "import imageio\n",
    "import yaml\n",
    "import numpy as np\n",
    "print(\"‚úÖ All dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428e2eb3",
   "metadata": {
    "id": "428e2eb3"
   },
   "source": [
    "## 4. Login to Weights & Biases (Optional)\n",
    "\n",
    "Track your experiments with W&B for better monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a116fb79",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a116fb79",
    "outputId": "8a31f636-1530-40c5-fa2e-498b55efb5a4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
      "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into https://api.wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find your API key here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminh1008\u001b[0m (\u001b[33mminh1008-ludwig-maximilianuniversity-of-munich\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "# Or run offline without W&B:\n",
    "# import os\n",
    "# os.environ['WANDB_MODE'] = 'offline'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064cf6ef",
   "metadata": {
    "id": "064cf6ef"
   },
   "source": [
    "## 5. Navigate to Project Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9ddd5a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9ddd5a1",
    "outputId": "c6dc5e29-daff-468b-823e-a96de71ee1b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /content/drive/MyDrive/gppvae\n",
      "\n",
      "Project structure:\n",
      "total 17\n",
      "drwx------ 3 root root 4096 Dec 23 14:09 data\n",
      "-rw------- 1 root root  258 Dec 23 11:40 environment.yml\n",
      "drwx------ 2 root root 4096 Dec 23 14:09 GPPVAE\n",
      "drwx------ 2 root root 4096 Dec 23 14:09 notebooks\n",
      "drwx------ 3 root root 4096 Dec 23 14:21 out\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir(PROJECT_PATH)\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "\n",
    "# Add to Python path\n",
    "sys.path.insert(0, os.path.join(PROJECT_PATH, 'GPPVAE/pysrc/faceplace'))\n",
    "\n",
    "print(\"\\nProject structure:\")\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638c36f7",
   "metadata": {
    "id": "638c36f7"
   },
   "source": [
    "## 6. Verify VAE Weights\n",
    "\n",
    "**Critical check:** Make sure you have trained VAE weights!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26a9a8de",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "26a9a8de",
    "outputId": "09546a11-9fcf-4477-d2b0-60d82fdd95fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 2 VAE training run(s):\n",
      "\n",
      "Run 1: 20251224_171841\n",
      "   Config: zdim=256, nf=32\n",
      "   Checkpoints: 11 files\n",
      "      üì¶ weights.00000.pt ... weights.00099.pt\n",
      "\n",
      "Run 2: 20251224_120136\n",
      "   Config: zdim=256, nf=32\n",
      "   Checkpoints: 16 files\n",
      "      üì¶ weights.00000.pt ... weights.00140.pt\n",
      "\n",
      "üí° Recommendation:\n",
      "   Use latest run: 20251224_171841\n",
      "   Latest checkpoint: weights.00099.pt\n",
      "   \n",
      "   Set in next cell:\n",
      "   CONFIG['vae_cfg'] = './out/vae_colab/20251224_171841/vae.cfg.p'\n",
      "   CONFIG['vae_weights'] = './out/vae_colab/20251224_171841/weights/weights.00099.pt'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "# Check for VAE runs (may be in timestamped subdirectories)\n",
    "vae_base_dir = './out/vae_colab'\n",
    "vae_runs = []\n",
    "\n",
    "if os.path.exists(vae_base_dir):\n",
    "    # Look for timestamped subdirectories\n",
    "    potential_runs = [d for d in os.listdir(vae_base_dir) if os.path.isdir(os.path.join(vae_base_dir, d))]\n",
    "    for run_dir in sorted(potential_runs, reverse=True):  # Most recent first\n",
    "        run_path = os.path.join(vae_base_dir, run_dir)\n",
    "        cfg_path = os.path.join(run_path, 'vae.cfg.p')\n",
    "        weights_dir = os.path.join(run_path, 'weights')\n",
    "\n",
    "        if os.path.exists(cfg_path) and os.path.exists(weights_dir):\n",
    "            weight_files = sorted([f for f in os.listdir(weights_dir) if f.endswith('.pt')])\n",
    "            if weight_files:\n",
    "                vae_runs.append({\n",
    "                    'run_dir': run_dir,\n",
    "                    'cfg_path': cfg_path,\n",
    "                    'weights_dir': weights_dir,\n",
    "                    'weight_files': weight_files\n",
    "                })\n",
    "\n",
    "if vae_runs:\n",
    "    print(f\"‚úÖ Found {len(vae_runs)} VAE training run(s):\\n\")\n",
    "\n",
    "    for i, run in enumerate(vae_runs, 1):\n",
    "        print(f\"Run {i}: {run['run_dir']}\")\n",
    "\n",
    "        # Load and show config\n",
    "        vae_cfg = pickle.load(open(run['cfg_path'], 'rb'))\n",
    "        print(f\"   Config: zdim={vae_cfg.get('zdim', 'N/A')}, nf={vae_cfg.get('nf', 'N/A')}\")\n",
    "\n",
    "        # Show checkpoints\n",
    "        print(f\"   Checkpoints: {len(run['weight_files'])} files\")\n",
    "        if len(run['weight_files']) <= 3:\n",
    "            for wf in run['weight_files']:\n",
    "                print(f\"      üì¶ {wf}\")\n",
    "        else:\n",
    "            print(f\"      üì¶ {run['weight_files'][0]} ... {run['weight_files'][-1]}\")\n",
    "        print()\n",
    "\n",
    "    # Recommendation\n",
    "    latest_run = vae_runs[0]\n",
    "    latest_weight = latest_run['weight_files'][-1]\n",
    "    recommended_path = os.path.join(latest_run['weights_dir'], latest_weight)\n",
    "\n",
    "    print(f\"üí° Recommendation:\")\n",
    "    print(f\"   Use latest run: {latest_run['run_dir']}\")\n",
    "    print(f\"   Latest checkpoint: {latest_weight}\")\n",
    "    print(f\"   \\n   Set in next cell:\")\n",
    "    print(f\"   CONFIG['vae_cfg'] = '{latest_run['cfg_path']}'\")\n",
    "    print(f\"   CONFIG['vae_weights'] = '{recommended_path}'\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No trained VAE runs found!\")\n",
    "    print(\"\\n   Please train VAE first using train_vae_colab.ipynb\")\n",
    "    print(f\"   Expected location: {vae_base_dir}/YYYYMMDD_HHMMSS/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fa53f3",
   "metadata": {
    "id": "10fa53f3"
   },
   "source": [
    "## 8. Configure GP-VAE Training\n",
    "\n",
    "Adjust these parameters as needed:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70721bf",
   "metadata": {
    "id": "d70721bf"
   },
   "source": [
    "## 7. Choose View Kernel üî¨\n",
    "\n",
    "**NEW: Kernel Selection for View Correlations**\n",
    "\n",
    "The view kernel models how correlations between face angles (0¬∞, 15¬∞, 30¬∞, ..., 90¬∞) are structured.\n",
    "\n",
    "### Available Kernels:\n",
    "\n",
    "1. **`'legacy'`** - Original implementation (normalized embeddings, 81 params)\n",
    "   - Most flexible but can overfit\n",
    "   - Good baseline for comparison\n",
    "\n",
    "2. **`'fullrank'`** - Direct full-rank covariance (45 params)\n",
    "   - Flexible but still many parameters\n",
    "   - Better than legacy due to fewer constraints\n",
    "\n",
    "3. **`'periodic'`** ‚≠ê **RECOMMENDED** - Periodic kernel (1 param: lengthscale)\n",
    "   - Knows that 0¬∞ = 360¬∞ (periodicity!)\n",
    "   - Smooth correlations between nearby angles\n",
    "   - Massive regularization (only 1 parameter)\n",
    "   - Best for rotation data\n",
    "\n",
    "4. **`'vonmises'`** ‚≠ê **RECOMMENDED** - Von Mises kernel (1 param: kappa)\n",
    "   - Designed specifically for circular/angular data\n",
    "   - Similar to Periodic but different parameterization\n",
    "   - Also best for rotation data\n",
    "\n",
    "5. **`'matern'`** - Mat√©rn kernel (1 param: lengthscale)\n",
    "   - More realistic than RBF, less smooth\n",
    "   - Good for modeling realistic correlations\n",
    "   - Can choose smoothness: nu=1.5 or nu=2.5\n",
    "\n",
    "6. **`'linear'`** - Low-rank linear (rank√ó9 params)\n",
    "   - Original GP-VAE kernel from Casale et al. (2018)\n",
    "   - Good middle-ground\n",
    "\n",
    "7. **`'rbf'`** - RBF/Gaussian (1 param: lengthscale)\n",
    "   - Smooth but NOT periodic\n",
    "   - Use only if views don't wrap around\n",
    "\n",
    "### Expected Performance:\n",
    "\n",
    "| Metric | Legacy | FullRank | Periodic | VonMises | Mat√©rn |\n",
    "|--------|--------|----------|----------|----------|--------|\n",
    "| Val MSE | Medium | Medium | **Best** | **Best** | Good |\n",
    "| Out-of-sample | Worst | Bad | **Best** | **Best** | Good |\n",
    "| Overfitting | High | Medium | Low | Low | Low |\n",
    "| Parameters | 81 | 45 | 1 | 1 | 1 |\n",
    "| Smoothness | - | - | Very smooth | Very smooth | Adjustable |\n",
    "\n",
    "**Recommendation**:\n",
    "- **Best for rotations**: `'periodic'` or `'vonmises'`\n",
    "- **More realistic**: `'matern'` (less smooth than periodic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedc7dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VIEW SPLIT CONFIGURATION - For Hard Held-Out Views Experiment\n",
    "# ============================================================================\n",
    "\n",
    "# Experiment mode\n",
    "VIEW_SPLIT_MODE = 'by_view'  # 'random' or 'by_view'\n",
    "\n",
    "# View angle mapping (after angular ordering fix):\n",
    "# Index 0: 90L (-90¬∞), 1: 60L (-60¬∞), 2: 45L (-45¬∞), 3: 30L (-30¬∞), 4: 00F (0¬∞),\n",
    "# Index 5: 30R (+30¬∞), 6: 45R (+45¬∞), 7: 60R (+60¬∞), 8: 90R (+90¬∞)\n",
    "\n",
    "if VIEW_SPLIT_MODE == 'by_view':\n",
    "    # EXPERIMENT 1: Train on central views, test on extreme angles\n",
    "    TRAIN_VIEW_INDICES = [3, 4, 5]  # -30L, 00F, 30R (60¬∞ range)\n",
    "    VAL_VIEW_INDICES = [0, 1, 2, 6, 7, 8]  # Extreme angles (¬±45¬∞, ¬±60¬∞, ¬±90¬∞)\n",
    "    \n",
    "    print(\"üî¨ EXPERIMENT MODE: Hard Held-Out Views\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Training views (central):\")\n",
    "    print(\"  Index 3: 30L (-30¬∞)\")\n",
    "    print(\"  Index 4: 00F (  0¬∞)\")\n",
    "    print(\"  Index 5: 30R (+30¬∞)\")\n",
    "    print(\"\\nValidation views (extreme):\")\n",
    "    print(\"  Index 0: 90L (-90¬∞)\")\n",
    "    print(\"  Index 1: 60L (-60¬∞)\")\n",
    "    print(\"  Index 2: 45L (-45¬∞)\")\n",
    "    print(\"  Index 6: 45R (+45¬∞)\")\n",
    "    print(\"  Index 7: 60R (+60¬∞)\")\n",
    "    print(\"  Index 8: 90R (+90¬∞)\")\n",
    "    print(\"=\" * 60)\n",
    "else:\n",
    "    TRAIN_VIEW_INDICES = None\n",
    "    VAL_VIEW_INDICES = None\n",
    "    print(\"üìä Standard Mode: Random 90/10 train/val split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c3fdd1f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6c3fdd1f",
    "outputId": "846ffd40-3977-4551-cee6-72a2da5c5561"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Kernel Configuration:\n",
      "============================================================\n",
      "Kernel type: legacy\n",
      "Parameters: (default)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# KERNEL CONFIGURATION - Choose one option below\n",
    "# ============================================================================\n",
    "\n",
    "# Option 1: Periodic kernel (RECOMMENDED for face rotations)\n",
    "# KERNEL_CONFIG = {\n",
    "#     'view_kernel': 'periodic',\n",
    "#     'kernel_kwargs': {'lengthscale': 1.0}\n",
    "# }\n",
    "\n",
    "# Option 2: Von Mises kernel (RECOMMENDED alternative)\n",
    "# KERNEL_CONFIG = {\n",
    "#     'view_kernel': 'vonmises',\n",
    "#     'kernel_kwargs': {'kappa': 1.0}\n",
    "# }\n",
    "\n",
    "# Option 3: Mat√©rn kernel (realistic, less smooth than periodic)\n",
    "# KERNEL_CONFIG = {\n",
    "#     'view_kernel': 'matern',\n",
    "#     'kernel_kwargs': {'lengthscale': 1.0, 'nu': 1.5}  # nu=1.5 or nu=2.5\n",
    "# }\n",
    "\n",
    "# Option 4: Legacy (original implementation - baseline)\n",
    "KERNEL_CONFIG = {\n",
    "    'view_kernel': 'legacy',\n",
    "    'kernel_kwargs': {}\n",
    "}\n",
    "\n",
    "# Option 5: Full Rank (flexible, 45 params)\n",
    "# KERNEL_CONFIG = {\n",
    "#     'view_kernel': 'fullrank',\n",
    "#     'kernel_kwargs': {}\n",
    "# }\n",
    "\n",
    "# Option 6: Linear low-rank (original GP-VAE paper)\n",
    "# KERNEL_CONFIG = {\n",
    "#     'view_kernel': 'linear',\n",
    "#     'kernel_kwargs': {'rank': 3}\n",
    "# }\n",
    "\n",
    "# Option 7: RBF (smooth but not periodic)\n",
    "# KERNEL_CONFIG = {\n",
    "#     'view_kernel': 'rbf',\n",
    "#     'kernel_kwargs': {'lengthscale': 1.0}\n",
    "# }\n",
    "\n",
    "print(\"Selected Kernel Configuration:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Kernel type: {KERNEL_CONFIG['view_kernel']}\")\n",
    "if KERNEL_CONFIG['kernel_kwargs']:\n",
    "    print(f\"Parameters: {KERNEL_CONFIG['kernel_kwargs']}\")\n",
    "else:\n",
    "    print(\"Parameters: (default)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb82c9c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aeb82c9c",
    "outputId": "5f20927f-147d-4093-faf5-3bb8ca453955"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GP-VAE Training Configuration:\n",
      "============================================================\n",
      "  data                : ./data/faceplace/data_faces.h5\n",
      "  outdir              : ./out/gppvae_colab/legacy_20251224_173025\n",
      "  vae_cfg             : ./out/vae_colab/20251224_171841/vae.cfg.p\n",
      "  vae_weights         : ./out/vae_colab/20251224_171841/weights/weights.00099.pt\n",
      "  epochs              : 100\n",
      "  batch_size          : 64\n",
      "  vae_lr              : 0.001\n",
      "  gp_lr               : 0.001\n",
      "  xdim                : 64\n",
      "  view_kernel         : legacy\n",
      "  kernel_kwargs       : {}\n",
      "  epoch_cb            : 10\n",
      "  use_wandb           : True\n",
      "  wandb_project       : gppvae\n",
      "  wandb_run_name      : colab_kernel_legacy_20251224_173025\n",
      "  seed                : 0\n",
      "============================================================\n",
      "\n",
      "‚úÖ Output will be saved to:\n",
      "   ./out/gppvae_colab/legacy_20251224_173025\n",
      "\n",
      "   Directory name includes kernel type for easy comparison!\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# GP-VAE Training configuration\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "kernel_name = KERNEL_CONFIG['view_kernel']\n",
    "\n",
    "# Include view split mode in directory name\n",
    "view_mode_str = 'central_views' if VIEW_SPLIT_MODE == 'by_view' else 'random'\n",
    "\n",
    "CONFIG = {\n",
    "    'data': './data/faceplace/data_faces.h5',\n",
    "    # Output directory now includes kernel name AND view split mode\n",
    "    'outdir': f'./out/gppvae_colab/{kernel_name}_{view_mode_str}_{timestamp}',\n",
    "    'vae_cfg': './out/vae_colab/20251224_171841/vae.cfg.p',\n",
    "    'vae_weights': './out/vae_colab/20251224_171841/weights/weights.00099.pt',\n",
    "\n",
    "    # Training hyperparameters\n",
    "    'epochs': 100,\n",
    "    'batch_size': 64,\n",
    "    'vae_lr': 0.001,\n",
    "    'gp_lr': 0.001,\n",
    "    'xdim': 64,\n",
    "\n",
    "    # Kernel configuration\n",
    "    'view_kernel': KERNEL_CONFIG['view_kernel'],\n",
    "    'kernel_kwargs': KERNEL_CONFIG['kernel_kwargs'],\n",
    "\n",
    "    # Experiment configuration (NEW)\n",
    "    'view_split_mode': VIEW_SPLIT_MODE,\n",
    "    'train_view_indices': TRAIN_VIEW_INDICES,\n",
    "    'val_view_indices': VAL_VIEW_INDICES,\n",
    "\n",
    "    # Logging\n",
    "    'epoch_cb': 10,\n",
    "    'use_wandb': True,\n",
    "    'wandb_project': 'gppvae-exp1',\n",
    "    'wandb_run_name': f'exp1_{kernel_name}_{view_mode_str}_{timestamp}',\n",
    "    'seed': 0,\n",
    "}\n",
    "\n",
    "print(\"GP-VAE Training Configuration:\")\n",
    "print(\"=\" * 60)\n",
    "for key, value in CONFIG.items():\n",
    "    if key in ['train_view_indices', 'val_view_indices'] and value is not None:\n",
    "        print(f\"  {key:20s}: {value}\")\n",
    "    elif key not in ['train_view_indices', 'val_view_indices']:\n",
    "        print(f\"  {key:20s}: {value}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Verify VAE weights path\n",
    "if not os.path.exists(CONFIG['vae_weights']):\n",
    "    print(f\"\\n‚ö†Ô∏è  WARNING: VAE weights not found at:\")\n",
    "    print(f\"   {CONFIG['vae_weights']}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Output will be saved to:\")\n",
    "print(f\"   {CONFIG['outdir']}\")\n",
    "print(f\"\\n   Directory name includes kernel type AND experiment mode!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9255bb2",
   "metadata": {
    "id": "f9255bb2"
   },
   "source": [
    "## 9. Import Training Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ab22b2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "16ab22b2",
    "outputId": "93b6b8ad-4655-4726-dcfa-5852edf0cbb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All modules imported successfully!\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.join(PROJECT_PATH, 'GPPVAE/pysrc/faceplace'))\n",
    "\n",
    "# Import modules\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from vae import FaceVAE\n",
    "from vmod import Vmodel\n",
    "from gp import GP\n",
    "import h5py\n",
    "import numpy as np\n",
    "import logging\n",
    "import pylab as pl\n",
    "from utils import smartSum, smartAppendDict, smartAppend, export_scripts\n",
    "from callbacks import callback_gppvae\n",
    "import pickle\n",
    "import time\n",
    "import wandb\n",
    "\n",
    "# IMPORTANT: Use experiment 1 data parser with view-based splitting\n",
    "from data_parser_exp1 import read_face_data, FaceDataset\n",
    "\n",
    "print(\"‚úÖ All modules imported successfully!\")\n",
    "print(\"‚úÖ Using data_parser_exp1 for view-based splitting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1953910",
   "metadata": {
    "id": "e1953910"
   },
   "source": [
    "## 10. Setup Training Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd715632",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dd715632",
    "outputId": "6f342c97-759a-46eb-94f3-d36d2656a6e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "‚úÖ Training environment setup complete!\n",
      "   Outputs will be saved to: ./out/gppvae_colab/legacy_20251224_173025\n"
     ]
    }
   ],
   "source": [
    "# Go back to project root\n",
    "os.chdir(PROJECT_PATH)\n",
    "\n",
    "# Create output directories\n",
    "outdir = CONFIG['outdir']\n",
    "wdir = os.path.join(outdir, \"weights\")\n",
    "fdir = os.path.join(outdir, \"plots\")\n",
    "os.makedirs(wdir, exist_ok=True)\n",
    "os.makedirs(fdir, exist_ok=True)\n",
    "\n",
    "# Setup device (GPU)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Setup logging\n",
    "log_format = \"%(asctime)s %(message)s\"\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=log_format,\n",
    "    datefmt=\"%m/%d %I:%M:%S %p\",\n",
    ")\n",
    "fh = logging.FileHandler(os.path.join(outdir, \"log.txt\"))\n",
    "fh.setFormatter(logging.Formatter(log_format))\n",
    "logging.getLogger().addHandler(fh)\n",
    "\n",
    "# Copy code to output\n",
    "export_scripts(os.path.join(outdir, \"scripts\"))\n",
    "\n",
    "print(\"‚úÖ Training environment setup complete!\")\n",
    "print(f\"   Outputs will be saved to: {outdir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36678b2b",
   "metadata": {
    "id": "36678b2b"
   },
   "source": [
    "## 10. Initialize Models and Data\n",
    "\n",
    "This cell:\n",
    "1. Loads pre-trained VAE\n",
    "2. Creates GP and Vmodel\n",
    "3. Loads dataset\n",
    "4. Sets up optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7bf143",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "id": "9c7bf143",
    "outputId": "24d04fb1-8bfe-4b19-b3d5-892a0e43dbb0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">colab_kernel_legacy_20251224_173025</strong> at: <a href='https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae/runs/g1hx8uyd' target=\"_blank\">https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae/runs/g1hx8uyd</a><br> View project at: <a href='https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae' target=\"_blank\">https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/content/wandb/run-20251224_173045-g1hx8uyd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20251224_173122-t1u5guk8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae/runs/t1u5guk8' target=\"_blank\">colab_kernel_legacy_20251224_173025</a></strong> to <a href='https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae' target=\"_blank\">https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae/runs/t1u5guk8' target=\"_blank\">https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae/runs/t1u5guk8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE config: {'nf': 32, 'zdim': 256, 'vy': 0.002}\n",
      "\n",
      "Loading pre-trained VAE...\n",
      "‚úÖ VAE loaded from ./out/vae_colab/20251224_171841/weights/weights.00099.pt\n",
      "   Total VAE parameters: 553,304\n",
      "\n",
      "Loading dataset...\n",
      "‚úÖ Data loaded:\n",
      "   Training samples: 3868\n",
      "   Validation samples: 484\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-475078740.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# Create object and view variables for GP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mDt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mWt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mDv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    401\u001b[0m             )\n\u001b[1;32m    402\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cuda_getDeviceCount\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             raise AssertionError(\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "torch.manual_seed(CONFIG['seed'])\n",
    "\n",
    "# Initialize W&B\n",
    "if CONFIG['use_wandb']:\n",
    "    wandb.init(\n",
    "        project=CONFIG['wandb_project'],\n",
    "        name=CONFIG['wandb_run_name'],\n",
    "        config=CONFIG\n",
    "    )\n",
    "\n",
    "# Load VAE configuration\n",
    "vae_cfg = pickle.load(open(CONFIG['vae_cfg'], \"rb\"))\n",
    "print(f\"VAE config: {vae_cfg}\")\n",
    "\n",
    "# Load pre-trained VAE\n",
    "print(\"\\nLoading pre-trained VAE...\")\n",
    "vae = FaceVAE(**vae_cfg).to(device)\n",
    "vae_state = torch.load(CONFIG['vae_weights'], map_location=device)\n",
    "vae.load_state_dict(vae_state)\n",
    "print(f\"‚úÖ VAE loaded from {CONFIG['vae_weights']}\")\n",
    "print(f\"   Total VAE parameters: {sum(p.numel() for p in vae.parameters()):,}\")\n",
    "\n",
    "# Load data with experiment configuration\n",
    "print(\"\\nLoading dataset...\")\n",
    "img, obj, view = read_face_data(\n",
    "    CONFIG['data'],\n",
    "    view_split_mode=CONFIG['view_split_mode'],\n",
    "    train_view_indices=CONFIG.get('train_view_indices'),\n",
    "    val_view_indices=CONFIG.get('val_view_indices')\n",
    ")\n",
    "\n",
    "train_data = FaceDataset(img[\"train\"], obj[\"train\"], view[\"train\"])\n",
    "val_data = FaceDataset(img[\"val\"], obj[\"val\"], view[\"val\"])\n",
    "train_queue = DataLoader(train_data, batch_size=CONFIG['batch_size'], shuffle=True)\n",
    "val_queue = DataLoader(val_data, batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "\n",
    "# Enhanced diagnostic logging\n",
    "print(f\"\\n‚úÖ Data loaded:\")\n",
    "print(f\"   Training samples: {len(train_data)}\")\n",
    "print(f\"   Validation samples: {len(val_data)}\")\n",
    "print(f\"   Unique train views: {np.unique(view['train'].numpy())}\")\n",
    "print(f\"   Unique val views: {np.unique(view['val'].numpy())}\")\n",
    "print(f\"   Unique train identities: {len(np.unique(obj['train'].numpy()))}\")\n",
    "print(f\"   Unique val identities: {len(np.unique(obj['val'].numpy()))}\")\n",
    "\n",
    "# Validation checks for experiment mode\n",
    "if CONFIG['view_split_mode'] == 'by_view':\n",
    "    print(\"\\nüîç Experiment Mode Validation Checks:\")\n",
    "    \n",
    "    # Check 1: View split correctness\n",
    "    train_views_set = set(np.unique(view['train'].numpy().flatten()).astype(int))\n",
    "    val_views_set = set(np.unique(view['val'].numpy().flatten()).astype(int))\n",
    "    \n",
    "    assert train_views_set == set(CONFIG['train_view_indices']), f\"Train views mismatch!\"\n",
    "    assert val_views_set == set(CONFIG['val_view_indices']), f\"Val views mismatch!\"\n",
    "    assert len(train_views_set & val_views_set) == 0, \"Train and val views overlap!\"\n",
    "    print(\"   ‚úÖ View split verified correctly!\")\n",
    "    \n",
    "    # Check 2: Identity coverage\n",
    "    train_ids = set(np.unique(obj['train'].numpy()))\n",
    "    val_ids = set(np.unique(obj['val'].numpy()))\n",
    "    assert train_ids == val_ids, \"Identity sets don't match between train/val!\"\n",
    "    print(f\"   ‚úÖ All {len(train_ids)} identities present in both train/val!\")\n",
    "    \n",
    "    # Check 3: Sample distribution\n",
    "    train_samples_per_id = len(img['train']) / len(train_ids)\n",
    "    val_samples_per_id = len(img['val']) / len(val_ids)\n",
    "    print(f\"   ‚úÖ Train samples per identity: {train_samples_per_id:.1f} (expected: {len(CONFIG['train_view_indices'])}.0)\")\n",
    "    print(f\"   ‚úÖ Val samples per identity: {val_samples_per_id:.1f} (expected: {len(CONFIG['val_view_indices'])}.0)\")\n",
    "\n",
    "# Create object and view variables for GP\n",
    "Dt = Variable(obj[\"train\"][:, 0].long(), requires_grad=False).cuda()\n",
    "Wt = Variable(view[\"train\"][:, 0].long(), requires_grad=False).cuda()\n",
    "Dv = Variable(obj[\"val\"][:, 0].long(), requires_grad=False).cuda()\n",
    "Wv = Variable(view[\"val\"][:, 0].long(), requires_grad=False).cuda()\n",
    "\n",
    "# Initialize GP and Vmodel\n",
    "print(\"\\nInitializing GP-VAE components...\")\n",
    "\n",
    "# IMPORTANT: Count unique identities and views AFTER filtering\n",
    "# The data parser may have filtered out some identities\n",
    "train_identities = np.unique(obj[\"train\"].numpy())\n",
    "train_views = np.unique(view[\"train\"].numpy())\n",
    "val_identities = np.unique(obj[\"val\"].numpy())\n",
    "val_views = np.unique(view[\"val\"].numpy())\n",
    "\n",
    "# For Vmodel, we need the TOTAL number of unique objects and views across ALL data\n",
    "# (not just train, since we'll use it for val too)\n",
    "all_identities = np.unique(np.concatenate([obj[\"train\"].numpy(), obj[\"val\"].numpy()]))\n",
    "all_views = np.unique(np.concatenate([view[\"train\"].numpy(), view[\"val\"].numpy()]))\n",
    "\n",
    "P = len(all_identities)  # Number of unique objects (people)\n",
    "Q = len(all_views)  # Number of unique views (angles)\n",
    "\n",
    "print(f\"   Objects (people): {P}\")\n",
    "print(f\"   Views (angles): {Q}\")\n",
    "print(f\"   Train identities: {len(train_identities)}, Val identities: {len(val_identities)}\")\n",
    "print(f\"   Train views: {sorted(train_views.tolist())}, Val views: {sorted(val_views.tolist())}\")\n",
    "\n",
    "vm = Vmodel(\n",
    "    P, Q,\n",
    "    p=CONFIG['xdim'],\n",
    "    q=Q,\n",
    "    view_kernel=CONFIG['view_kernel'],\n",
    "    **CONFIG['kernel_kwargs']\n",
    ").cuda()\n",
    "\n",
    "print(f\"\\nüî¨ Initializing view kernel: '{CONFIG['view_kernel']}'\")\n",
    "if CONFIG['kernel_kwargs']:\n",
    "    print(f\"   Kernel parameters: {CONFIG['kernel_kwargs']}\")\n",
    "else:\n",
    "    print(f\"   Kernel parameters: (default)\")\n",
    "\n",
    "gp = GP(n_rand_effs=1).to(device)\n",
    "\n",
    "# Combine GP parameters (Vmodel + GP)\n",
    "gp_params = nn.ParameterList()\n",
    "gp_params.extend(vm.parameters())\n",
    "gp_params.extend(gp.parameters())\n",
    "\n",
    "print(f\"‚úÖ GP-VAE components initialized:\")\n",
    "print(f\"   Vmodel parameters: {sum(p.numel() for p in vm.parameters()):,}\")\n",
    "print(f\"   GP parameters: {sum(p.numel() for p in gp.parameters()):,}\")\n",
    "print(f\"   Total trainable: {sum(p.numel() for p in vae.parameters()) + sum(p.numel() for p in gp_params):,}\")\n",
    "\n",
    "# Create optimizers (separate for VAE and GP)\n",
    "vae_optimizer = optim.Adam(vae.parameters(), lr=CONFIG['vae_lr'])\n",
    "gp_optimizer = optim.Adam(gp_params, lr=CONFIG['gp_lr'])\n",
    "print(f\"\\n‚úÖ Optimizers created:\")\n",
    "print(f\"   VAE optimizer: Adam(lr={CONFIG['vae_lr']})\")\n",
    "print(f\"   GP optimizer: Adam(lr={CONFIG['gp_lr']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9082858",
   "metadata": {
    "id": "b9082858"
   },
   "source": [
    "## 11. Define Training Functions\n",
    "\n",
    "These functions handle the complex GP-VAE training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa7bebf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dfa7bebf",
    "outputId": "5209bec0-2e7f-430f-8472-b2a9c74d3021"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training functions defined\n"
     ]
    }
   ],
   "source": [
    "def encode_Y(vae, train_queue):\n",
    "    \"\"\"Encode all training images to get latent codes\"\"\"\n",
    "    vae.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        n = train_queue.dataset.Y.shape[0]\n",
    "        Zm = Variable(torch.zeros(n, vae_cfg[\"zdim\"]), requires_grad=False).cuda()\n",
    "        Zs = Variable(torch.zeros(n, vae_cfg[\"zdim\"]), requires_grad=False).cuda()\n",
    "\n",
    "        for batch_i, data in enumerate(train_queue):\n",
    "            y = data[0].cuda()\n",
    "            idxs = data[-1].cuda()\n",
    "            zm, zs = vae.encode(y)\n",
    "            Zm[idxs], Zs[idxs] = zm.detach(), zs.detach()\n",
    "\n",
    "    return Zm, Zs\n",
    "\n",
    "\n",
    "def eval_step(vae, gp, vm, val_queue, Zm, Vt, Vv, Wv):\n",
    "    \"\"\"Enhanced evaluation with per-view metrics for Experiment #1\"\"\"\n",
    "    rv = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _X = vm.x().data.cpu().numpy()\n",
    "        _W = vm.v().data.cpu().numpy()\n",
    "        covs = {\"XX\": np.dot(_X, _X.T), \"WW\": np.dot(_W, _W.T)}\n",
    "        rv[\"vars\"] = gp.get_vs().data.cpu().numpy()\n",
    "\n",
    "        # Out-of-sample prediction\n",
    "        vs = gp.get_vs()\n",
    "        U, UBi, _ = gp.U_UBi_Shb([Vt], vs)\n",
    "        Kiz = gp.solve(Zm, U, UBi, vs)\n",
    "        Zo = vs[0] * Vv.mm(Vt.transpose(0, 1).mm(Kiz))\n",
    "\n",
    "        mse_out = Variable(torch.zeros(Vv.shape[0], 1), requires_grad=False).cuda()\n",
    "        mse_val = Variable(torch.zeros(Vv.shape[0], 1), requires_grad=False).cuda()\n",
    "\n",
    "        for batch_i, data in enumerate(val_queue):\n",
    "            idxs = data[-1].cuda()\n",
    "            Yv = data[0].cuda()\n",
    "            Zv = vae.encode(Yv)[0].detach()\n",
    "            Yr = vae.decode(Zv)\n",
    "            Yo = vae.decode(Zo[idxs])\n",
    "            mse_out[idxs] = ((Yv - Yo) ** 2).view(Yv.shape[0], -1).mean(1)[:, None].detach()\n",
    "            mse_val[idxs] = ((Yv - Yr) ** 2).view(Yv.shape[0], -1).mean(1)[:, None].detach()\n",
    "\n",
    "            # Store examples for visualization\n",
    "            if batch_i == 0:\n",
    "                imgs = {}\n",
    "                imgs[\"Yv\"] = Yv[:24].data.cpu().numpy().transpose(0, 2, 3, 1)\n",
    "                imgs[\"Yr\"] = Yr[:24].data.cpu().numpy().transpose(0, 2, 3, 1)\n",
    "                imgs[\"Yo\"] = Yo[:24].data.cpu().numpy().transpose(0, 2, 3, 1)\n",
    "\n",
    "        rv[\"mse_out\"] = float(mse_out.data.mean().cpu())\n",
    "        rv[\"mse_val\"] = float(mse_val.data.mean().cpu())\n",
    "        \n",
    "        # NEW: Per-view metrics for Experiment #1\n",
    "        unique_views = torch.unique(Wv).cpu().numpy()\n",
    "        mse_val_per_view = {}\n",
    "        mse_out_per_view = {}\n",
    "        \n",
    "        for view_idx in unique_views:\n",
    "            view_mask = (Wv.cpu().numpy().flatten() == view_idx)\n",
    "            mse_val_per_view[int(view_idx)] = float(mse_val.cpu().numpy()[view_mask].mean())\n",
    "            mse_out_per_view[int(view_idx)] = float(mse_out.cpu().numpy()[view_mask].mean())\n",
    "        \n",
    "        rv['mse_val_per_view'] = mse_val_per_view\n",
    "        rv['mse_out_per_view'] = mse_out_per_view\n",
    "\n",
    "    return rv, imgs, covs\n",
    "\n",
    "\n",
    "def backprop_and_update(vae, gp, vm, train_queue, Dt, Wt, Eps, Zb, Vbs, vbs, vae_optimizer, gp_optimizer):\n",
    "    \"\"\"Joint optimization of VAE and GP\"\"\"\n",
    "    rv = {}\n",
    "\n",
    "    vae_optimizer.zero_grad()\n",
    "    gp_optimizer.zero_grad()\n",
    "    vae.train()\n",
    "    gp.train()\n",
    "    vm.train()\n",
    "\n",
    "    for batch_i, data in enumerate(train_queue):\n",
    "        # Get batch data\n",
    "        y = data[0].cuda()\n",
    "        eps = Eps[data[-1]]\n",
    "        _d = Dt[data[-1]]\n",
    "        _w = Wt[data[-1]]\n",
    "        _Zb = Zb[data[-1]]\n",
    "        _Vbs = [Vbs[0][data[-1]]]\n",
    "\n",
    "        # Forward through VAE\n",
    "        zm, zs = vae.encode(y)\n",
    "        z = zm + zs * eps\n",
    "        yr = vae.decode(z)\n",
    "        recon_term, mse = vae.nll(y, yr)\n",
    "\n",
    "        # Forward through GP\n",
    "        _Vs = [vm(_d, _w)]\n",
    "        gp_nll_fo = gp.taylor_expansion(z, _Vs, _Zb, _Vbs, vbs) / vae.K\n",
    "\n",
    "        # Penalization term\n",
    "        pen_term = -0.5 * zs.sum(1)[:, None] / vae.K\n",
    "\n",
    "        # Joint loss and backward\n",
    "        loss = (recon_term + gp_nll_fo + pen_term).sum()\n",
    "        loss.backward()\n",
    "\n",
    "        # Accumulate metrics\n",
    "        _n = train_queue.dataset.Y.shape[0]\n",
    "        smartSum(rv, \"mse\", float(mse.data.sum().cpu()) / _n)\n",
    "        smartSum(rv, \"recon_term\", float(recon_term.data.sum().cpu()) / _n)\n",
    "        smartSum(rv, \"pen_term\", float(pen_term.data.sum().cpu()) / _n)\n",
    "\n",
    "    # Update both optimizers\n",
    "    vae_optimizer.step()\n",
    "    gp_optimizer.step()\n",
    "\n",
    "    return rv\n",
    "\n",
    "\n",
    "print(\"‚úÖ Training functions defined with per-view metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c869fdf",
   "metadata": {
    "id": "4c869fdf"
   },
   "source": [
    "## 12. Train GP-VAE Model üöÄ\n",
    "\n",
    "**This is joint optimization!** Both VAE and GP are updated together each iteration.\n",
    "\n",
    "Training process per epoch:\n",
    "1. Encode images to latent codes (VAE)\n",
    "2. Compute GP prior likelihood on latents\n",
    "3. Backpropagate through joint loss\n",
    "4. Update VAE, GP, and Vmodel simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6f1485",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2f6f1485",
    "outputId": "053c5605-907c-4589-b32c-117106400335"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting GP-VAE training for 200 epochs...\n",
      "================================================================================\n",
      "Training mode: JOINT OPTIMIZATION (VAE + GP updated together)\n",
      "================================================================================\n",
      "Epoch    0/200 | MSE train: 0.003776 | MSE val: 0.004238 | MSE out: 0.068923 | GP NLL: 0.0020 | Gap(T-V): -0.000461 | Gap(V-O): 0.064686 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.500 | Time: 5.9s\n",
      "  ‚úì Checkpoint saved at epoch 0\n",
      "Epoch    5/200 | MSE train: 0.030871 | MSE val: 0.031063 | MSE out: 0.071995 | GP NLL: 0.0006 | Gap(T-V): -0.000192 | Gap(V-O): 0.040932 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.497 | Time: 5.9s\n",
      "Epoch   10/200 | MSE train: 0.014819 | MSE val: 0.015153 | MSE out: 0.056098 | GP NLL: 0.0008 | Gap(T-V): -0.000333 | Gap(V-O): 0.040946 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.497 | Time: 6.0s\n",
      "  ‚úì Checkpoint saved at epoch 10\n",
      "Epoch   15/200 | MSE train: 0.011634 | MSE val: 0.011731 | MSE out: 0.050627 | GP NLL: 0.0011 | Gap(T-V): -0.000097 | Gap(V-O): 0.038896 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.496 | Time: 5.9s\n",
      "Epoch   20/200 | MSE train: 0.008930 | MSE val: 0.009169 | MSE out: 0.045992 | GP NLL: 0.0007 | Gap(T-V): -0.000239 | Gap(V-O): 0.036823 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.497 | Time: 6.0s\n",
      "  ‚úì Checkpoint saved at epoch 20\n",
      "Epoch   25/200 | MSE train: 0.007450 | MSE val: 0.007705 | MSE out: 0.042271 | GP NLL: 0.0009 | Gap(T-V): -0.000255 | Gap(V-O): 0.034566 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.497 | Time: 6.1s\n",
      "Epoch   30/200 | MSE train: 0.006495 | MSE val: 0.006773 | MSE out: 0.041347 | GP NLL: 0.0009 | Gap(T-V): -0.000278 | Gap(V-O): 0.034574 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.498 | Time: 5.9s\n",
      "  ‚úì Checkpoint saved at epoch 30\n",
      "Epoch   35/200 | MSE train: 0.006081 | MSE val: 0.006399 | MSE out: 0.039861 | GP NLL: 0.0010 | Gap(T-V): -0.000317 | Gap(V-O): 0.033463 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.499 | Time: 5.9s\n",
      "Epoch   40/200 | MSE train: 0.005573 | MSE val: 0.005884 | MSE out: 0.037822 | GP NLL: 0.0008 | Gap(T-V): -0.000312 | Gap(V-O): 0.031938 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.500 | Time: 6.0s\n",
      "  ‚úì Checkpoint saved at epoch 40\n",
      "Epoch   45/200 | MSE train: 0.005129 | MSE val: 0.005469 | MSE out: 0.036762 | GP NLL: 0.0007 | Gap(T-V): -0.000340 | Gap(V-O): 0.031294 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.502 | Time: 6.0s\n",
      "Epoch   50/200 | MSE train: 0.004898 | MSE val: 0.005260 | MSE out: 0.035936 | GP NLL: 0.0007 | Gap(T-V): -0.000363 | Gap(V-O): 0.030676 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.504 | Time: 6.0s\n",
      "  ‚úì Checkpoint saved at epoch 50\n",
      "Epoch   55/200 | MSE train: 0.004704 | MSE val: 0.005076 | MSE out: 0.034997 | GP NLL: 0.0006 | Gap(T-V): -0.000372 | Gap(V-O): 0.029920 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.506 | Time: 5.9s\n",
      "Epoch   60/200 | MSE train: 0.004567 | MSE val: 0.004950 | MSE out: 0.034271 | GP NLL: 0.0005 | Gap(T-V): -0.000383 | Gap(V-O): 0.029321 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.508 | Time: 5.9s\n",
      "  ‚úì Checkpoint saved at epoch 60\n",
      "Epoch   65/200 | MSE train: 0.004435 | MSE val: 0.004830 | MSE out: 0.033673 | GP NLL: 0.0004 | Gap(T-V): -0.000396 | Gap(V-O): 0.028843 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.510 | Time: 6.0s\n",
      "Epoch   70/200 | MSE train: 0.004341 | MSE val: 0.004744 | MSE out: 0.033129 | GP NLL: 0.0003 | Gap(T-V): -0.000402 | Gap(V-O): 0.028385 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.513 | Time: 6.0s\n",
      "  ‚úì Checkpoint saved at epoch 70\n",
      "Epoch   75/200 | MSE train: 0.004252 | MSE val: 0.004662 | MSE out: 0.032572 | GP NLL: 0.0003 | Gap(T-V): -0.000410 | Gap(V-O): 0.027910 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.516 | Time: 6.0s\n",
      "Epoch   80/200 | MSE train: 0.004178 | MSE val: 0.004596 | MSE out: 0.032078 | GP NLL: 0.0002 | Gap(T-V): -0.000417 | Gap(V-O): 0.027482 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.519 | Time: 5.9s\n",
      "  ‚úì Checkpoint saved at epoch 80\n",
      "Epoch   85/200 | MSE train: 0.004112 | MSE val: 0.004537 | MSE out: 0.031650 | GP NLL: 0.0001 | Gap(T-V): -0.000425 | Gap(V-O): 0.027114 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.522 | Time: 5.9s\n",
      "Epoch   90/200 | MSE train: 0.004054 | MSE val: 0.004486 | MSE out: 0.031280 | GP NLL: 0.0001 | Gap(T-V): -0.000431 | Gap(V-O): 0.026794 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.525 | Time: 6.0s\n",
      "  ‚úì Checkpoint saved at epoch 90\n",
      "Epoch   95/200 | MSE train: 0.004004 | MSE val: 0.004442 | MSE out: 0.030958 | GP NLL: 0.0001 | Gap(T-V): -0.000438 | Gap(V-O): 0.026516 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.528 | Time: 6.0s\n",
      "Epoch  100/200 | MSE train: 0.003958 | MSE val: 0.004401 | MSE out: 0.030626 | GP NLL: 0.0000 | Gap(T-V): -0.000442 | Gap(V-O): 0.026225 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.531 | Time: 5.9s\n",
      "  ‚úì Checkpoint saved at epoch 100\n",
      "Epoch  105/200 | MSE train: 0.003918 | MSE val: 0.004364 | MSE out: 0.030331 | GP NLL: -0.0000 | Gap(T-V): -0.000447 | Gap(V-O): 0.025966 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.535 | Time: 5.9s\n",
      "Epoch  110/200 | MSE train: 0.003881 | MSE val: 0.004331 | MSE out: 0.030049 | GP NLL: -0.0001 | Gap(T-V): -0.000450 | Gap(V-O): 0.025718 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.538 | Time: 5.9s\n",
      "  ‚úì Checkpoint saved at epoch 110\n",
      "Epoch  115/200 | MSE train: 0.003848 | MSE val: 0.004302 | MSE out: 0.029804 | GP NLL: -0.0001 | Gap(T-V): -0.000454 | Gap(V-O): 0.025502 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.541 | Time: 6.0s\n",
      "Epoch  120/200 | MSE train: 0.003818 | MSE val: 0.004276 | MSE out: 0.029591 | GP NLL: -0.0001 | Gap(T-V): -0.000458 | Gap(V-O): 0.025315 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.544 | Time: 6.0s\n",
      "  ‚úì Checkpoint saved at epoch 120\n",
      "Epoch  125/200 | MSE train: 0.003790 | MSE val: 0.004252 | MSE out: 0.029399 | GP NLL: -0.0002 | Gap(T-V): -0.000461 | Gap(V-O): 0.025147 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.548 | Time: 5.9s\n",
      "Epoch  130/200 | MSE train: 0.003765 | MSE val: 0.004230 | MSE out: 0.029225 | GP NLL: -0.0002 | Gap(T-V): -0.000465 | Gap(V-O): 0.024995 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.551 | Time: 5.9s\n",
      "  ‚úì Checkpoint saved at epoch 130\n",
      "Epoch  135/200 | MSE train: 0.003742 | MSE val: 0.004209 | MSE out: 0.029067 | GP NLL: -0.0002 | Gap(T-V): -0.000467 | Gap(V-O): 0.024858 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.554 | Time: 6.0s\n",
      "Epoch  140/200 | MSE train: 0.003720 | MSE val: 0.004191 | MSE out: 0.028927 | GP NLL: -0.0003 | Gap(T-V): -0.000470 | Gap(V-O): 0.024737 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.557 | Time: 6.0s\n",
      "  ‚úì Checkpoint saved at epoch 140\n",
      "Epoch  145/200 | MSE train: 0.003701 | MSE val: 0.004173 | MSE out: 0.028801 | GP NLL: -0.0003 | Gap(T-V): -0.000473 | Gap(V-O): 0.024627 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.561 | Time: 5.9s\n",
      "Epoch  150/200 | MSE train: 0.003682 | MSE val: 0.004157 | MSE out: 0.028689 | GP NLL: -0.0003 | Gap(T-V): -0.000475 | Gap(V-O): 0.024532 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.564 | Time: 5.9s\n",
      "  ‚úì Checkpoint saved at epoch 150\n",
      "Epoch  155/200 | MSE train: 0.003665 | MSE val: 0.004142 | MSE out: 0.028587 | GP NLL: -0.0003 | Gap(T-V): -0.000477 | Gap(V-O): 0.024445 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.567 | Time: 5.9s\n",
      "Epoch  160/200 | MSE train: 0.003649 | MSE val: 0.004128 | MSE out: 0.028494 | GP NLL: -0.0004 | Gap(T-V): -0.000479 | Gap(V-O): 0.024366 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.570 | Time: 6.0s\n",
      "  ‚úì Checkpoint saved at epoch 160\n",
      "Epoch  165/200 | MSE train: 0.003634 | MSE val: 0.004115 | MSE out: 0.028413 | GP NLL: -0.0004 | Gap(T-V): -0.000481 | Gap(V-O): 0.024298 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.574 | Time: 6.0s\n",
      "Epoch  170/200 | MSE train: 0.003619 | MSE val: 0.004103 | MSE out: 0.028339 | GP NLL: -0.0004 | Gap(T-V): -0.000483 | Gap(V-O): 0.024236 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.577 | Time: 6.0s\n",
      "  ‚úì Checkpoint saved at epoch 170\n",
      "Epoch  175/200 | MSE train: 0.003606 | MSE val: 0.004091 | MSE out: 0.028271 | GP NLL: -0.0004 | Gap(T-V): -0.000485 | Gap(V-O): 0.024181 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.580 | Time: 5.9s\n",
      "Epoch  180/200 | MSE train: 0.003594 | MSE val: 0.004080 | MSE out: 0.028215 | GP NLL: -0.0005 | Gap(T-V): -0.000486 | Gap(V-O): 0.024135 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.583 | Time: 5.9s\n",
      "  ‚úì Checkpoint saved at epoch 180\n",
      "Epoch  185/200 | MSE train: 0.003582 | MSE val: 0.004070 | MSE out: 0.028158 | GP NLL: -0.0005 | Gap(T-V): -0.000488 | Gap(V-O): 0.024088 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.586 | Time: 6.0s\n",
      "Epoch  190/200 | MSE train: 0.003571 | MSE val: 0.004060 | MSE out: 0.028125 | GP NLL: -0.0005 | Gap(T-V): -0.000490 | Gap(V-O): 0.024065 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.589 | Time: 6.0s\n",
      "  ‚úì Checkpoint saved at epoch 190\n",
      "Epoch  195/200 | MSE train: 0.003570 | MSE val: 0.004059 | MSE out: 0.028044 | GP NLL: -0.0005 | Gap(T-V): -0.000490 | Gap(V-O): 0.023984 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.592 | Time: 6.0s\n",
      "Epoch  199/200 | MSE train: 0.003646 | MSE val: 0.004134 | MSE out: 0.028013 | GP NLL: -0.0005 | Gap(T-V): -0.000488 | Gap(V-O): 0.023879 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.595 | Time: 6.0s\n",
      "  ‚úì Checkpoint saved at epoch 199\n",
      "\n",
      "================================================================================\n",
      "‚úÖ GP-VAE training complete!\n",
      "   Total time: 20.2 minutes (0.34 hours)\n",
      "   Average time per epoch: 6.1 seconds\n",
      "   Final training MSE: 0.003646\n",
      "   Final validation MSE: 0.004134\n",
      "   Final out-of-sample MSE: 0.028013\n",
      "   Final GP NLL: -0.0005\n",
      "\n",
      "üî¨ Final Diagnostics:\n",
      "   Train-Val Gap: -0.000488 (lower = less overfitting)\n",
      "   Val-Out Gap: 0.023879 (lower = better GP interpolation)\n",
      "   Variance Ratio: 0.595 (higher = more structure learned)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>diagnostics/gap_train_val</td><td>‚ñÅ‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>diagnostics/gap_val_out</td><td>‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>diagnostics/variance_ratio</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà</td></tr><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>gp_nll</td><td>‚ñà‚ñÜ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>loss</td><td>‚ñà‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>mse_out</td><td>‚ñà‚ñá‚ñÜ‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>mse_train</td><td>‚ñà‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>mse_val</td><td>‚ñÅ‚ñá‚ñà‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>pen_term</td><td>‚ñá‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>+4</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>diagnostics/gap_train_val</td><td>-0.00049</td></tr><tr><td>diagnostics/gap_val_out</td><td>0.02388</td></tr><tr><td>diagnostics/variance_ratio</td><td>0.59482</td></tr><tr><td>epoch</td><td>199</td></tr><tr><td>gp_nll</td><td>-0.0005</td></tr><tr><td>loss</td><td>-2.19633</td></tr><tr><td>mse_out</td><td>0.02801</td></tr><tr><td>mse_train</td><td>0.00365</td></tr><tr><td>mse_val</td><td>0.00413</td></tr><tr><td>pen_term</td><td>-1e-05</td></tr><tr><td>+5</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">colab_kernel_legacy_20251224_133711</strong> at: <a href='https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae/runs/whvlt26f' target=\"_blank\">https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae/runs/whvlt26f</a><br> View project at: <a href='https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae' target=\"_blank\">https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae</a><br>Synced 5 W&B file(s), 42 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/content/wandb/run-20251224_133722-whvlt26f/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîó View detailed results in W&B dashboard\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "history = {}\n",
    "start_time = time.time()\n",
    "\n",
    "print(f\"üöÄ Starting GP-VAE Experiment #1 training for {CONFIG['epochs']} epochs...\")\n",
    "print(\"=\" * 80)\n",
    "print(\"Training mode: JOINT OPTIMIZATION (VAE + GP updated together)\")\n",
    "print(f\"Experiment: Hard Held-Out Views\")\n",
    "print(f\"  Training views: {CONFIG.get('train_view_indices', 'all')}\")\n",
    "print(f\"  Validation views: {CONFIG.get('val_view_indices', 'all')}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for epoch in range(CONFIG['epochs']):\n",
    "    epoch_start = time.time()\n",
    "\n",
    "    # 1. Encode all training images\n",
    "    Zm, Zs = encode_Y(vae, train_queue)\n",
    "\n",
    "    # 2. Sample latent codes\n",
    "    Eps = Variable(torch.randn(*Zs.shape), requires_grad=False).cuda()\n",
    "    Z = Zm + Eps * Zs\n",
    "\n",
    "    # 3. Compute variance matrices\n",
    "    Vt = vm(Dt, Wt).detach()\n",
    "    Vv = vm(Dv, Wv).detach()\n",
    "\n",
    "    # 4. Evaluate on validation set (with per-view metrics)\n",
    "    rv_eval, imgs, covs = eval_step(vae, gp, vm, val_queue, Zm, Vt, Vv, Wv)\n",
    "\n",
    "    # 5. Compute GP Taylor expansion coefficients\n",
    "    Zb, Vbs, vbs, gp_nll = gp.taylor_coeff(Z, [Vt])\n",
    "    rv_eval[\"gp_nll\"] = float(gp_nll.data.mean().cpu()) / vae.K\n",
    "\n",
    "    # 6. Joint training step (VAE + GP)\n",
    "    rv_back = backprop_and_update(\n",
    "        vae, gp, vm, train_queue, Dt, Wt, Eps,\n",
    "        Zb, Vbs, vbs, vae_optimizer, gp_optimizer\n",
    "    )\n",
    "    rv_back[\"loss\"] = rv_back[\"recon_term\"] + rv_eval[\"gp_nll\"] + rv_back[\"pen_term\"]\n",
    "\n",
    "    # Store history\n",
    "    smartAppendDict(history, rv_eval)\n",
    "    smartAppendDict(history, rv_back)\n",
    "    smartAppend(history, \"vs\", gp.get_vs().data.cpu().numpy())\n",
    "\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    total_time = time.time() - start_time\n",
    "\n",
    "    # üî¨ Compute diagnostic metrics\n",
    "    train_val_gap = rv_back[\"mse\"] - rv_eval[\"mse_val\"]\n",
    "    val_out_gap = rv_eval[\"mse_out\"] - rv_eval[\"mse_val\"]\n",
    "\n",
    "    vs = gp.get_vs().data.cpu().numpy()\n",
    "    variance_ratio = vs[0] / (vs[0] + vs[1])\n",
    "\n",
    "    # Check if kernel has learnable lengthscale\n",
    "    learned_lengthscale = None\n",
    "    if hasattr(vm, 'view_kernel') and hasattr(vm.view_kernel, 'log_lengthscale'):\n",
    "        learned_lengthscale = torch.exp(vm.view_kernel.log_lengthscale).item()\n",
    "\n",
    "    # Print progress\n",
    "    if epoch % 5 == 0 or epoch == CONFIG['epochs'] - 1:\n",
    "        print(f\"Epoch {epoch:4d}/{CONFIG['epochs']} | \"\n",
    "              f\"MSE train: {rv_back['mse']:.6f} | \"\n",
    "              f\"MSE val: {rv_eval['mse_val']:.6f} | \"\n",
    "              f\"MSE out: {rv_eval['mse_out']:.6f} | \"\n",
    "              f\"GP NLL: {rv_eval['gp_nll']:.4f} | \"\n",
    "              f\"Gap(T-V): {train_val_gap:.6f} | \"\n",
    "              f\"Gap(V-O): {val_out_gap:.6f} | \"\n",
    "              f\"v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): {variance_ratio:.3f}\" +\n",
    "              (f\" | ‚Ñì: {learned_lengthscale:.3f}\" if learned_lengthscale else \"\") +\n",
    "              f\" | Time: {epoch_time:.1f}s\")\n",
    "        \n",
    "        # Print per-view breakdown (Experiment #1 specific)\n",
    "        if CONFIG['view_split_mode'] == 'by_view' and epoch % 10 == 0:\n",
    "            print(\"   Per-view MSE_out:\")\n",
    "            view_names = {0: \"90L\", 1: \"60L\", 2: \"45L\", 3: \"30L\", 4: \"00F\", \n",
    "                         5: \"30R\", 6: \"45R\", 7: \"60R\", 8: \"90R\"}\n",
    "            for view_idx in sorted(rv_eval['mse_out_per_view'].keys()):\n",
    "                mse = rv_eval['mse_out_per_view'][view_idx]\n",
    "                view_name = view_names.get(view_idx, f\"V{view_idx}\")\n",
    "                print(f\"      {view_name}: {mse:.6f}\")\n",
    "\n",
    "    # Log to W&B\n",
    "    if CONFIG['use_wandb']:\n",
    "        log_dict = {\n",
    "            \"epoch\": epoch,\n",
    "            \"mse_train\": rv_back[\"mse\"],\n",
    "            \"mse_val\": rv_eval[\"mse_val\"],\n",
    "            \"mse_out\": rv_eval[\"mse_out\"],\n",
    "            \"gp_nll\": rv_eval[\"gp_nll\"],\n",
    "            \"recon_term\": rv_back[\"recon_term\"],\n",
    "            \"pen_term\": rv_back[\"pen_term\"],\n",
    "            \"loss\": rv_back[\"loss\"],\n",
    "            \"vars\": rv_eval[\"vars\"],\n",
    "            \"time/epoch_seconds\": epoch_time,\n",
    "            # üî¨ Diagnostic metrics\n",
    "            \"diagnostics/gap_train_val\": train_val_gap,\n",
    "            \"diagnostics/gap_val_out\": val_out_gap,\n",
    "            \"diagnostics/variance_ratio\": variance_ratio,\n",
    "            \"vars/v0_object\": vs[0],\n",
    "            \"vars/v1_noise\": vs[1],\n",
    "        }\n",
    "\n",
    "        # Add lengthscale if available\n",
    "        if learned_lengthscale is not None:\n",
    "            log_dict[\"kernel/lengthscale\"] = learned_lengthscale\n",
    "        \n",
    "        # Add per-view metrics (Experiment #1 specific)\n",
    "        if 'mse_val_per_view' in rv_eval:\n",
    "            for view_idx, mse in rv_eval['mse_val_per_view'].items():\n",
    "                view_names = {0: \"90L\", 1: \"60L\", 2: \"45L\", 3: \"30L\", 4: \"00F\",\n",
    "                             5: \"30R\", 6: \"45R\", 7: \"60R\", 8: \"90R\"}\n",
    "                view_name = view_names.get(view_idx, f\"V{view_idx}\")\n",
    "                log_dict[f\"mse_val_per_view/{view_name}\"] = mse\n",
    "        \n",
    "        if 'mse_out_per_view' in rv_eval:\n",
    "            for view_idx, mse in rv_eval['mse_out_per_view'].items():\n",
    "                view_names = {0: \"90L\", 1: \"60L\", 2: \"45L\", 3: \"30L\", 4: \"00F\",\n",
    "                             5: \"30R\", 6: \"45R\", 7: \"60R\", 8: \"90R\"}\n",
    "                view_name = view_names.get(view_idx, f\"V{view_idx}\")\n",
    "                log_dict[f\"mse_out_per_view/{view_name}\"] = mse\n",
    "\n",
    "        wandb.log(log_dict)\n",
    "\n",
    "    # Save checkpoint\n",
    "    if epoch % CONFIG['epoch_cb'] == 0 or epoch == CONFIG['epochs'] - 1:\n",
    "        logging.info(f\"Epoch {epoch} - saving checkpoint\")\n",
    "\n",
    "        # Save VAE weights\n",
    "        vae_file = os.path.join(wdir, f\"vae_weights.{epoch:05d}.pt\")\n",
    "        torch.save(vae.state_dict(), vae_file)\n",
    "\n",
    "        # Save GP weights\n",
    "        gp_file = os.path.join(wdir, f\"gp_weights.{epoch:05d}.pt\")\n",
    "        torch.save({\n",
    "            'gp_state': gp.state_dict(),\n",
    "            'vm_state': vm.state_dict(),\n",
    "            'gp_params': gp_params.state_dict(),\n",
    "        }, gp_file)\n",
    "\n",
    "        # Save visualization\n",
    "        ffile = os.path.join(fdir, f\"plot.{epoch:05d}.png\")\n",
    "        callback_gppvae(epoch, history, covs, imgs, ffile)\n",
    "\n",
    "        if CONFIG['use_wandb']:\n",
    "            wandb.log({\n",
    "                \"reconstructions\": wandb.Image(ffile),\n",
    "                \"covariances/XX\": wandb.Image(ffile),\n",
    "            })\n",
    "\n",
    "        print(f\"  ‚úì Checkpoint saved at epoch {epoch}\")\n",
    "\n",
    "# At the end, enhanced summary with per-view breakdown\n",
    "total_time = time.time() - start_time\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"‚úÖ GP-VAE Experiment #1 training complete!\")\n",
    "print(f\"   Total time: {total_time/60:.1f} minutes ({total_time/3600:.2f} hours)\")\n",
    "print(f\"   Average time per epoch: {total_time/CONFIG['epochs']:.1f} seconds\")\n",
    "print(f\"   Final training MSE: {rv_back['mse']:.6f}\")\n",
    "print(f\"   Final validation MSE: {rv_eval['mse_val']:.6f}\")\n",
    "print(f\"   Final out-of-sample MSE: {rv_eval['mse_out']:.6f}\")\n",
    "print(f\"   Final GP NLL: {rv_eval['gp_nll']:.4f}\")\n",
    "\n",
    "print(f\"\\nüî¨ Final Diagnostics:\")\n",
    "print(f\"   Train-Val Gap: {train_val_gap:.6f} (lower = less overfitting)\")\n",
    "print(f\"   Val-Out Gap: {val_out_gap:.6f} (lower = better GP interpolation)\")\n",
    "print(f\"   Variance Ratio: {variance_ratio:.3f} (higher = more structure learned)\")\n",
    "if learned_lengthscale is not None:\n",
    "    print(f\"   Learned Lengthscale: {learned_lengthscale:.3f}\")\n",
    "\n",
    "# Experiment #1 specific: Per-view breakdown\n",
    "if CONFIG['view_split_mode'] == 'by_view' and 'mse_out_per_view' in rv_eval:\n",
    "    print(f\"\\nüìä Final Per-View MSE_out (Experiment #1):\")\n",
    "    view_names = {0: \"90L (-90¬∞)\", 1: \"60L (-60¬∞)\", 2: \"45L (-45¬∞)\", 3: \"30L (-30¬∞)\", \n",
    "                 4: \"00F (0¬∞)\", 5: \"30R (+30¬∞)\", 6: \"45R (+45¬∞)\", 7: \"60R (+60¬∞)\", 8: \"90R (+90¬∞)\"}\n",
    "    \n",
    "    # Separate training and validation views\n",
    "    train_view_indices = CONFIG.get('train_view_indices', [])\n",
    "    val_view_indices = CONFIG.get('val_view_indices', [])\n",
    "    \n",
    "    print(\"   VALIDATION VIEWS (held-out, extreme angles):\")\n",
    "    extreme_mses = []\n",
    "    for view_idx in sorted(rv_eval['mse_out_per_view'].keys()):\n",
    "        if view_idx in val_view_indices:\n",
    "            mse = rv_eval['mse_out_per_view'][view_idx]\n",
    "            extreme_mses.append(mse)\n",
    "            view_name = view_names.get(view_idx, f\"V{view_idx}\")\n",
    "            print(f\"      {view_name:15s}: {mse:.6f}\")\n",
    "    \n",
    "    if extreme_mses:\n",
    "        avg_extreme = np.mean(extreme_mses)\n",
    "        print(f\"\\n   Average MSE on extreme angles: {avg_extreme:.6f}\")\n",
    "        print(f\"   Overall MSE_out: {rv_eval['mse_out']:.6f}\")\n",
    "\n",
    "if CONFIG['use_wandb']:\n",
    "    wandb.finish()\n",
    "    print(\"\\nüîó View detailed results in W&B dashboard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a98f4bc",
   "metadata": {
    "id": "9a98f4bc"
   },
   "source": [
    "## 13. Download Results\n",
    "\n",
    "Download the trained model and visualizations to your computer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337a096a",
   "metadata": {
    "id": "337a096a"
   },
   "outputs": [],
   "source": [
    "# Compress output folder\n",
    "output_zip = '/content/gppvae_output.zip'\n",
    "!zip -r {output_zip} {CONFIG['outdir']}\n",
    "\n",
    "# Download\n",
    "from google.colab import files\n",
    "print(\"Preparing download...\")\n",
    "files.download(output_zip)\n",
    "print(\"\\n‚úÖ Download started! Extract the zip on your local machine.\")\n",
    "print(f\"\\nContents include:\")\n",
    "print(f\"  - Trained VAE weights (fine-tuned)\")\n",
    "print(f\"  - GP + Vmodel weights\")\n",
    "print(f\"  - Visualization plots\")\n",
    "print(f\"  - Training logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f397bbc",
   "metadata": {
    "id": "7f397bbc"
   },
   "source": [
    "## 14. Visualize Results\n",
    "\n",
    "View the latest reconstruction and covariance plots:"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
