{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0f8a173e",
      "metadata": {
        "id": "0f8a173e"
      },
      "source": [
        "# GP-VAE Training on Google Colab\n",
        "\n",
        "This notebook trains the **GP-VAE (Gaussian Process Variational Autoencoder)** model using Google Colab's free GPU.\n",
        "\n",
        "## What is GP-VAE?\n",
        "GP-VAE adds a **Gaussian Process prior** to the VAE latent space to model structured correlations:\n",
        "- **VAE**: Learns image ‚Üî latent code mapping\n",
        "- **GP Prior**: Models correlations between latent codes based on:\n",
        "  - Object identity (same person's face)\n",
        "  - View angle (front, side, profile)\n",
        "  - Other factors of variation\n",
        "\n",
        "## Prerequisites ‚ö†Ô∏è\n",
        "**You MUST have trained VAE weights first!** This model loads pre-trained VAE and fine-tunes it jointly with the GP.\n",
        "\n",
        "Required files:\n",
        "- ‚úÖ `out/vae_colab/YYYYMMDD_HHMMSS/vae.cfg.p` - VAE configuration\n",
        "- ‚úÖ `out/vae_colab/YYYYMMDD_HHMMSS/weights/weights.00000.pt` - Trained VAE weights\n",
        "\n",
        "## Output Directory Structure:\n",
        "\n",
        "Each training run creates a **timestamped directory** to avoid overwriting previous runs:\n",
        "- Format: `./out/gppvae_colab/YYYYMMDD_HHMMSS/`\n",
        "- Example: `./out/gppvae_colab/20251224_143530/weights/weights.00100.pt`\n",
        "- This allows you to compare different training runs and keep a history!\n",
        "\n",
        "Cell 6 below will automatically find your latest VAE training run.\n",
        "\n",
        "## Setup Instructions:\n",
        "\n",
        "1. **Open this notebook in VS Code**\n",
        "2. **Connect to Colab**: Click kernel picker ‚Üí \"Connect to Colab\" ‚Üí Choose **GPU runtime (T4)**\n",
        "3. **Important**: When prompted with \"Alias your server\", press Enter\n",
        "4. **Run cell 2** - it will automatically detect your project location\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7d4d88e",
      "metadata": {
        "id": "a7d4d88e"
      },
      "source": [
        "## 1. Check GPU Availability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9450aba9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9450aba9",
        "outputId": "c3002593-11d9-4ebe-a493-24c315ae4a3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.9.0+cu126\n",
            "CUDA available: True\n",
            "GPU Device: NVIDIA A100-SXM4-40GB\n",
            "GPU Memory: 42.47 GB\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è WARNING: GPU not detected! Go to Runtime ‚Üí Change runtime type ‚Üí GPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a792140f",
      "metadata": {
        "id": "a792140f"
      },
      "source": [
        "## 2. Auto-Detect Project Path\n",
        "\n",
        "This automatically finds your project files on the Colab runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33fa06a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33fa06a0",
        "outputId": "fade0d3a-107c-4bc2-8af0-62184c1e90cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìç Current directory: /content\n",
            "\n",
            "üîÑ Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "‚úÖ Found project in Google Drive: /content/drive/MyDrive/gppvae\n",
            "\n",
            "üìÅ Contents of /content/drive/MyDrive/gppvae:\n",
            "   üìÇ GPPVAE/\n",
            "   üìÇ data/\n",
            "   üìÑ environment.yml\n",
            "   üìÇ notebooks/\n",
            "   üìÇ out/\n",
            "\n",
            "üîç Checking required files:\n",
            "   ‚úÖ GPPVAE code\n",
            "   ‚úÖ data/faceplace\n",
            "   ‚úÖ data_faces.h5\n",
            "   ‚úÖ VAE config\n",
            "   ‚úÖ VAE weights\n",
            "\n",
            "üì¶ Found 3 VAE training run(s):\n",
            "   1. 20251224_171841/ (11 checkpoints)\n",
            "      Latest: weights.00099.pt\n",
            "   2. 20251224_171753/ (0 checkpoints)\n",
            "   3. 20251224_120136/ (16 checkpoints)\n",
            "      Latest: weights.00140.pt\n",
            "\n",
            "üí° Cell 6 below will help you choose which run to use\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# Get current directory\n",
        "current_dir = os.getcwd()\n",
        "print(f\"üìç Current directory: {current_dir}\")\n",
        "\n",
        "# Check if on Colab and need to mount Drive\n",
        "if current_dir == '/content':\n",
        "    print(\"\\nüîÑ Mounting Google Drive...\")\n",
        "\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "\n",
        "        # Check for project in Drive\n",
        "        drive_path = '/content/drive/MyDrive/gppvae'\n",
        "        if os.path.exists(drive_path):\n",
        "            PROJECT_PATH = drive_path\n",
        "            print(f\"‚úÖ Found project in Google Drive: {PROJECT_PATH}\")\n",
        "        else:\n",
        "            print(f\"\\n‚ö†Ô∏è  Project not found at: {drive_path}\")\n",
        "            print(\"\\nPlease upload your gppvae folder to Google Drive!\")\n",
        "            print(\"Required structure:\")\n",
        "            print(\"  MyDrive/gppvae/\")\n",
        "            print(\"    ‚îú‚îÄ‚îÄ GPPVAE/\")\n",
        "            print(\"    ‚îú‚îÄ‚îÄ data/faceplace/data_faces.h5\")\n",
        "            print(\"    ‚îî‚îÄ‚îÄ out/vae_colab/YYYYMMDD_HHMMSS/\")\n",
        "            print(\"        ‚îú‚îÄ‚îÄ vae.cfg.p\")\n",
        "            print(\"        ‚îî‚îÄ‚îÄ weights/weights.00000.pt\")\n",
        "            PROJECT_PATH = '/content'\n",
        "    except Exception as e:\n",
        "        print(f\"Could not mount Drive: {e}\")\n",
        "        PROJECT_PATH = '/content'\n",
        "else:\n",
        "    # Running via VS Code sync\n",
        "    if 'notebooks' in current_dir:\n",
        "        PROJECT_PATH = os.path.dirname(current_dir)\n",
        "    else:\n",
        "        PROJECT_PATH = current_dir\n",
        "    print(f\"üíª Using project path: {PROJECT_PATH}\")\n",
        "\n",
        "# Verify structure\n",
        "print(f\"\\nüìÅ Contents of {PROJECT_PATH}:\")\n",
        "if os.path.exists(PROJECT_PATH):\n",
        "    items = os.listdir(PROJECT_PATH)\n",
        "    for item in sorted(items)[:15]:\n",
        "        item_path = os.path.join(PROJECT_PATH, item)\n",
        "        if os.path.isdir(item_path):\n",
        "            print(f\"   üìÇ {item}/\")\n",
        "        else:\n",
        "            print(f\"   üìÑ {item}\")\n",
        "\n",
        "    # Check required files (with timestamped directory structure)\n",
        "    print(f\"\\nüîç Checking required files:\")\n",
        "    required = {\n",
        "        'GPPVAE code': os.path.exists(os.path.join(PROJECT_PATH, 'GPPVAE')),\n",
        "        'data/faceplace': os.path.exists(os.path.join(PROJECT_PATH, 'data/faceplace')),\n",
        "        'data_faces.h5': os.path.exists(os.path.join(PROJECT_PATH, 'data/faceplace/data_faces.h5')),\n",
        "    }\n",
        "\n",
        "    # Check for VAE runs (timestamped subdirectories)\n",
        "    vae_base_dir = os.path.join(PROJECT_PATH, 'out/vae_colab')\n",
        "    vae_run_found = False\n",
        "    vae_weights_found = False\n",
        "\n",
        "    if os.path.exists(vae_base_dir):\n",
        "        # Look for timestamped subdirectories\n",
        "        potential_runs = [d for d in os.listdir(vae_base_dir)\n",
        "                         if os.path.isdir(os.path.join(vae_base_dir, d)) and d[0].isdigit()]\n",
        "\n",
        "        for run_dir in potential_runs:\n",
        "            run_path = os.path.join(vae_base_dir, run_dir)\n",
        "            cfg_path = os.path.join(run_path, 'vae.cfg.p')\n",
        "            weights_dir = os.path.join(run_path, 'weights')\n",
        "\n",
        "            if os.path.exists(cfg_path):\n",
        "                vae_run_found = True\n",
        "\n",
        "            if os.path.exists(weights_dir):\n",
        "                weight_files = [f for f in os.listdir(weights_dir) if f.endswith('.pt')]\n",
        "                if weight_files:\n",
        "                    vae_weights_found = True\n",
        "                    break\n",
        "\n",
        "    required['VAE config'] = vae_run_found\n",
        "    required['VAE weights'] = vae_weights_found\n",
        "\n",
        "    for name, exists in required.items():\n",
        "        status = \"‚úÖ\" if exists else \"‚ùå\"\n",
        "        print(f\"   {status} {name}\")\n",
        "\n",
        "    # Show VAE runs if they exist\n",
        "    if os.path.exists(vae_base_dir):\n",
        "        potential_runs = sorted([d for d in os.listdir(vae_base_dir)\n",
        "                                if os.path.isdir(os.path.join(vae_base_dir, d)) and d[0].isdigit()],\n",
        "                               reverse=True)\n",
        "\n",
        "        if potential_runs:\n",
        "            print(f\"\\nüì¶ Found {len(potential_runs)} VAE training run(s):\")\n",
        "            for i, run_dir in enumerate(potential_runs[:3], 1):  # Show latest 3\n",
        "                run_path = os.path.join(vae_base_dir, run_dir)\n",
        "                weights_dir = os.path.join(run_path, 'weights')\n",
        "\n",
        "                if os.path.exists(weights_dir):\n",
        "                    weight_files = sorted([f for f in os.listdir(weights_dir) if f.endswith('.pt')])\n",
        "                    print(f\"   {i}. {run_dir}/ ({len(weight_files)} checkpoints)\")\n",
        "                    if weight_files:\n",
        "                        print(f\"      Latest: {weight_files[-1]}\")\n",
        "\n",
        "            if len(potential_runs) > 3:\n",
        "                print(f\"   ... and {len(potential_runs) - 3} more\")\n",
        "\n",
        "            print(f\"\\nüí° Cell 6 below will help you choose which run to use\")\n",
        "\n",
        "    if not all(required.values()):\n",
        "        print(f\"\\n‚ö†Ô∏è  Missing required files!\")\n",
        "        if not required['VAE weights']:\n",
        "            print(\"\\nüö® CRITICAL: No trained VAE weights found!\")\n",
        "            print(\"   You must train VAE first before running GP-VAE\")\n",
        "            print(\"   Use the train_vae_colab.ipynb notebook\")\n",
        "else:\n",
        "    print(f\"‚ùå Path doesn't exist: {PROJECT_PATH}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd61ed4d",
      "metadata": {
        "id": "dd61ed4d"
      },
      "source": [
        "## 3. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5eb3366a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eb3366a",
        "outputId": "d2d592d4-2781-476a-f77b-a06dc96fc238"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m√ó\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m√ó\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "‚úÖ All dependencies installed successfully!\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install -q wandb==0.12.21 imageio==2.15.0 pyyaml\n",
        "\n",
        "# Verify installations\n",
        "import wandb\n",
        "import imageio\n",
        "import yaml\n",
        "import numpy as np\n",
        "print(\"‚úÖ All dependencies installed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "428e2eb3",
      "metadata": {
        "id": "428e2eb3"
      },
      "source": [
        "## 4. Login to Weights & Biases (Optional)\n",
        "\n",
        "Track your experiments with W&B for better monitoring."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a116fb79",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a116fb79",
        "outputId": "274485e2-33b2-4f00-b462-24f00b055d55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into https://api.wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find your API key here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminh1008\u001b[0m (\u001b[33mminh1008-ludwig-maximilianuniversity-of-munich\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login()\n",
        "\n",
        "# Or run offline without W&B:\n",
        "# import os\n",
        "# os.environ['WANDB_MODE'] = 'offline'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "064cf6ef",
      "metadata": {
        "id": "064cf6ef"
      },
      "source": [
        "## 5. Navigate to Project Directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9ddd5a1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9ddd5a1",
        "outputId": "771193d0-bf83-4bba-8af9-06a80417df91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current directory: /content/drive/MyDrive/gppvae\n",
            "\n",
            "Project structure:\n",
            "total 17\n",
            "drwx------ 3 root root 4096 Dec 23 14:09 data\n",
            "-rw------- 1 root root  258 Dec 23 11:40 environment.yml\n",
            "drwx------ 2 root root 4096 Dec 23 14:09 GPPVAE\n",
            "drwx------ 2 root root 4096 Dec 23 14:09 notebooks\n",
            "drwx------ 3 root root 4096 Dec 23 14:21 out\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "os.chdir(PROJECT_PATH)\n",
        "print(f\"Current directory: {os.getcwd()}\")\n",
        "\n",
        "# Add to Python path\n",
        "sys.path.insert(0, os.path.join(PROJECT_PATH, 'GPPVAE/pysrc/faceplace'))\n",
        "\n",
        "print(\"\\nProject structure:\")\n",
        "!ls -la"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "638c36f7",
      "metadata": {
        "id": "638c36f7"
      },
      "source": [
        "## 6. Verify VAE Weights\n",
        "\n",
        "**Critical check:** Make sure you have trained VAE weights!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26a9a8de",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26a9a8de",
        "outputId": "7a7b1f42-dddd-4a8c-e4ce-1a0ab3dc5684"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Found 4 VAE training run(s):\n",
            "\n",
            "Run 1: 20260103_192743\n",
            "   Config: zdim=256, nf=32\n",
            "   Checkpoints: 11 files\n",
            "      üì¶ weights.00000.pt ... weights.00499.pt\n",
            "\n",
            "Run 2: 20260103_191647\n",
            "   Config: zdim=256, nf=32\n",
            "   Checkpoints: 2 files\n",
            "      üì¶ weights.00000.pt\n",
            "      üì¶ weights.00050.pt\n",
            "\n",
            "Run 3: 20260103_190918\n",
            "   Config: zdim=256, nf=32\n",
            "   Checkpoints: 2 files\n",
            "      üì¶ weights.00000.pt\n",
            "      üì¶ weights.00050.pt\n",
            "\n",
            "Run 4: 20260103_184756\n",
            "   Config: zdim=256, nf=32\n",
            "   Checkpoints: 5 files\n",
            "      üì¶ weights.00000.pt ... weights.00200.pt\n",
            "\n",
            "üí° Recommendation:\n",
            "   Use latest run: 20260103_192743\n",
            "   Latest checkpoint: weights.00499.pt\n",
            "   \n",
            "   Set in next cell:\n",
            "   CONFIG['vae_cfg'] = './out/vae_colab_interpolation/20260103_192743/vae.cfg.p'\n",
            "   CONFIG['vae_weights'] = './out/vae_colab_interpolation/20260103_192743/weights/weights.00499.pt'\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pickle\n",
        "import glob\n",
        "\n",
        "# Check for VAE runs (may be in timestamped subdirectories)\n",
        "vae_base_dir = './out/vae_colab_interpolation'\n",
        "vae_runs = []\n",
        "\n",
        "if os.path.exists(vae_base_dir):\n",
        "    # Look for timestamped subdirectories\n",
        "    potential_runs = [d for d in os.listdir(vae_base_dir) if os.path.isdir(os.path.join(vae_base_dir, d))]\n",
        "    for run_dir in sorted(potential_runs, reverse=True):  # Most recent first\n",
        "        run_path = os.path.join(vae_base_dir, run_dir)\n",
        "        cfg_path = os.path.join(run_path, 'vae.cfg.p')\n",
        "        weights_dir = os.path.join(run_path, 'weights')\n",
        "\n",
        "        if os.path.exists(cfg_path) and os.path.exists(weights_dir):\n",
        "            weight_files = sorted([f for f in os.listdir(weights_dir) if f.endswith('.pt')])\n",
        "            if weight_files:\n",
        "                vae_runs.append({\n",
        "                    'run_dir': run_dir,\n",
        "                    'cfg_path': cfg_path,\n",
        "                    'weights_dir': weights_dir,\n",
        "                    'weight_files': weight_files\n",
        "                })\n",
        "\n",
        "if vae_runs:\n",
        "    print(f\"‚úÖ Found {len(vae_runs)} VAE training run(s):\\n\")\n",
        "\n",
        "    for i, run in enumerate(vae_runs, 1):\n",
        "        print(f\"Run {i}: {run['run_dir']}\")\n",
        "\n",
        "        # Load and show config\n",
        "        vae_cfg = pickle.load(open(run['cfg_path'], 'rb'))\n",
        "        print(f\"   Config: zdim={vae_cfg.get('zdim', 'N/A')}, nf={vae_cfg.get('nf', 'N/A')}\")\n",
        "\n",
        "        # Show checkpoints\n",
        "        print(f\"   Checkpoints: {len(run['weight_files'])} files\")\n",
        "        if len(run['weight_files']) <= 3:\n",
        "            for wf in run['weight_files']:\n",
        "                print(f\"      üì¶ {wf}\")\n",
        "        else:\n",
        "            print(f\"      üì¶ {run['weight_files'][0]} ... {run['weight_files'][-1]}\")\n",
        "        print()\n",
        "\n",
        "    # Recommendation\n",
        "    latest_run = vae_runs[0]\n",
        "    latest_weight = latest_run['weight_files'][-1]\n",
        "    recommended_path = os.path.join(latest_run['weights_dir'], latest_weight)\n",
        "\n",
        "    print(f\"üí° Recommendation:\")\n",
        "    print(f\"   Use latest run: {latest_run['run_dir']}\")\n",
        "    print(f\"   Latest checkpoint: {latest_weight}\")\n",
        "    print(f\"   \\n   Set in next cell:\")\n",
        "    print(f\"   CONFIG['vae_cfg'] = '{latest_run['cfg_path']}'\")\n",
        "    print(f\"   CONFIG['vae_weights'] = '{recommended_path}'\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå No trained VAE runs found!\")\n",
        "    print(\"\\n   Please train VAE first using train_vae_colab.ipynb\")\n",
        "    print(f\"   Expected location: {vae_base_dir}/YYYYMMDD_HHMMSS/\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10fa53f3",
      "metadata": {
        "id": "10fa53f3"
      },
      "source": [
        "## 8. Configure GP-VAE Training\n",
        "\n",
        "Adjust these parameters as needed:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d70721bf",
      "metadata": {
        "id": "d70721bf"
      },
      "source": [
        "## 7. Choose View Kernel üî¨\n",
        "\n",
        "**NEW: Kernel Selection for View Correlations**\n",
        "\n",
        "The view kernel models how correlations between face angles (0¬∞, 15¬∞, 30¬∞, ..., 90¬∞) are structured.\n",
        "\n",
        "### Available Kernels:\n",
        "\n",
        "1. **`'legacy'`** - Original implementation (normalized embeddings, 81 params)\n",
        "   - Most flexible but can overfit\n",
        "   - Good baseline for comparison\n",
        "\n",
        "2. **`'fullrank'`** - Direct full-rank covariance (45 params)\n",
        "   - Flexible but still many parameters\n",
        "   - Better than legacy due to fewer constraints\n",
        "\n",
        "3. **`'periodic'`** ‚≠ê **RECOMMENDED** - Periodic kernel (1 param: lengthscale)\n",
        "   - Knows that 0¬∞ = 360¬∞ (periodicity!)\n",
        "   - Smooth correlations between nearby angles\n",
        "   - Massive regularization (only 1 parameter)\n",
        "   - Best for rotation data\n",
        "\n",
        "4. **`'vonmises'`** ‚≠ê **RECOMMENDED** - Von Mises kernel (1 param: kappa)\n",
        "   - Designed specifically for circular/angular data\n",
        "   - Similar to Periodic but different parameterization\n",
        "   - Also best for rotation data\n",
        "\n",
        "5. **`'matern'`** - Mat√©rn kernel (1 param: lengthscale)\n",
        "   - More realistic than RBF, less smooth\n",
        "   - Good for modeling realistic correlations\n",
        "   - Can choose smoothness: nu=1.5 or nu=2.5\n",
        "\n",
        "6. **`'linear'`** - Low-rank linear (rank√ó9 params)\n",
        "   - Original GP-VAE kernel from Casale et al. (2018)\n",
        "   - Good middle-ground\n",
        "\n",
        "7. **`'rbf'`** - RBF/Gaussian (1 param: lengthscale)\n",
        "   - Smooth but NOT periodic\n",
        "   - Use only if views don't wrap around\n",
        "\n",
        "8. **`'spectral_mixture'`** ‚≠ê **NEW** - Spectral Mixture kernel (3√ó3 params)\n",
        "   - Learns mixture of frequencies in the spectral domain\n",
        "   - Very flexible - can model periodic AND non-periodic patterns\n",
        "   - Each component has: weight, mean frequency, lengthscale\n",
        "   - Good for complex correlation structures\n",
        "   - Requires continuous angle encoding\n",
        "\n",
        "### Expected Performance:\n",
        "\n",
        "| Metric | Legacy | FullRank | Periodic | VonMises | Mat√©rn | Spectral |\n",
        "|--------|--------|----------|----------|----------|--------|----------|\n",
        "| Val MSE | Medium | Medium | **Best** | **Best** | Good | **Excellent** |\n",
        "| Out-of-sample | Worst | Bad | **Best** | **Best** | Good | **Excellent** |\n",
        "| Overfitting | High | Medium | Low | Low | Low | Medium |\n",
        "| Parameters | 81 | 45 | 1 | 1 | 1 | 9 (3 comp) |\n",
        "| Smoothness | - | - | Very smooth | Very smooth | Adjustable | Very flexible |\n",
        "\n",
        "**Recommendation**:\n",
        "- **Best for rotations**: `'periodic'` or `'vonmises'`\n",
        "- **More realistic**: `'matern'` (less smooth than periodic)\n",
        "- **Most flexible**: `'spectral_mixture'` (can learn complex patterns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fedc7dbd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fedc7dbd",
        "outputId": "e600e041-5a58-428f-809d-5dc5313aa199"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üî¨ EXPERIMENT MODE: Interpolation (Train boundaries, test intermediate)\n",
            "============================================================\n",
            "Training views (boundaries):\n",
            "  Index 0: 90L (-90¬∞)\n",
            "  Index 1: 60L (-60¬∞)\n",
            "  Index 3: 30L (-30¬∞)\n",
            "  Index 4: 00F (  0¬∞)\n",
            "  Index 5: 30R (+30¬∞)\n",
            "  Index 7: 60R (+60¬∞)\n",
            "  Index 8: 90R (+90¬∞)\n",
            "\n",
            "Validation views (intermediate):\n",
            "  Index 2: 45L (-45¬∞)\n",
            "  Index 6: 45R (+45¬∞)\n",
            "============================================================\n",
            "\n",
            "üí° Research Question:\n",
            "   Do structured kernels improve interpolation performance?\n",
            "   Expected: Periodic/VonMises/Mat√©rn > FullRank > Legacy\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# VIEW SPLIT CONFIGURATION - For Interpolation Experiment\n",
        "# ============================================================================\n",
        "\n",
        "# Experiment mode\n",
        "VIEW_SPLIT_MODE = 'interpolation'  # 'random' or 'by_view'\n",
        "\n",
        "# View angle mapping (after angular ordering fix):\n",
        "# Index 0: 90L (-90¬∞), 1: 60L (-60¬∞), 2: 45L (-45¬∞), 3: 30L (-30¬∞), 4: 00F (0¬∞),\n",
        "# Index 5: 30R (+30¬∞), 6: 45R (+45¬∞), 7: 60R (+60¬∞), 8: 90R (+90¬∞)\n",
        "\n",
        "if VIEW_SPLIT_MODE == 'interpolation':\n",
        "    # EXPERIMENT 1 (Interpolation): Train on boundaries, test on intermediate views\n",
        "    TRAIN_VIEW_INDICES = [0, 1, 3, 4, 5, 7, 8]  # 90L, 60L, 30L, 00F, 30R, 60R, 90R (boundaries)\n",
        "    VAL_VIEW_INDICES = [2, 6]  # 45L, 45R (intermediate angles)\n",
        "\n",
        "    print(\"üî¨ EXPERIMENT MODE: Interpolation (Train boundaries, test intermediate)\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Training views (boundaries):\")\n",
        "    print(\"  Index 0: 90L (-90¬∞)\")\n",
        "    print(\"  Index 1: 60L (-60¬∞)\")\n",
        "    print(\"  Index 3: 30L (-30¬∞)\")\n",
        "    print(\"  Index 4: 00F (  0¬∞)\")\n",
        "    print(\"  Index 5: 30R (+30¬∞)\")\n",
        "    print(\"  Index 7: 60R (+60¬∞)\")\n",
        "    print(\"  Index 8: 90R (+90¬∞)\")\n",
        "    print(\"\\nValidation views (intermediate):\")\n",
        "    print(\"  Index 2: 45L (-45¬∞)\")\n",
        "    print(\"  Index 6: 45R (+45¬∞)\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"\\nüí° Research Question:\")\n",
        "    print(\"   Do structured kernels improve interpolation performance?\")\n",
        "    print(\"   Expected: Periodic/VonMises/Mat√©rn > FullRank > Legacy\")\n",
        "else:\n",
        "    TRAIN_VIEW_INDICES = None\n",
        "    VAL_VIEW_INDICES = None\n",
        "    print(\"üìä Standard Mode: Random 90/10 train/val split\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c3fdd1f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c3fdd1f",
        "outputId": "6f5120e4-5226-4bc0-b57a-a0625e3ac922"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Kernel Configuration:\n",
            "============================================================\n",
            "Kernel type: spectral_mixture\n",
            "Parameters: {'n_components': 2, 'angle_scale': 'normalized'}\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# KERNEL CONFIGURATION - Choose one option below\n",
        "# ============================================================================\n",
        "\n",
        "# Option 1: Periodic kernel (RECOMMENDED for face rotations)\n",
        "# KERNEL_CONFIG = {\n",
        "#     'view_kernel': 'periodic',\n",
        "#     'kernel_kwargs': {'lengthscale': 1.0}\n",
        "# }\n",
        "\n",
        "# Option 2: Von Mises kernel (RECOMMENDED alternative)\n",
        "# KERNEL_CONFIG = {\n",
        "#     'view_kernel': 'vonmises',\n",
        "#     'kernel_kwargs': {'kappa': 1.0}\n",
        "# }\n",
        "\n",
        "# Option 3: Mat√©rn kernel (realistic, less smooth than periodic)\n",
        "# KERNEL_CONFIG = {\n",
        "#     'view_kernel': 'matern',\n",
        "#     'kernel_kwargs': {'lengthscale': 1.0, 'nu': 1.5}  # nu=1.5 or nu=2.5\n",
        "# }\n",
        "\n",
        "# Option 4: Legacy (original implementation - baseline)\n",
        "# KERNEL_CONFIG = {\n",
        "#     'view_kernel': 'legacy',\n",
        "#     'kernel_kwargs': {}\n",
        "# }\n",
        "\n",
        "# Option 5: Full Rank (flexible, 45 params)\n",
        "# KERNEL_CONFIG = {\n",
        "#     'view_kernel': 'fullrank',\n",
        "#     'kernel_kwargs': {}\n",
        "# }\n",
        "\n",
        "# Option 6: Linear low-rank (original GP-VAE paper)\n",
        "# KERNEL_CONFIG = {\n",
        "#     'view_kernel': 'linear',\n",
        "#     'kernel_kwargs': {'rank': 3}\n",
        "# }\n",
        "\n",
        "# Option 7: RBF (smooth but not periodic)\n",
        "# KERNEL_CONFIG = {\n",
        "#     'view_kernel': 'rbf',\n",
        "#     'kernel_kwargs': {'lengthscale': 1.0, 'angle_scale': 'normalized'}\n",
        "# }\n",
        "\n",
        "# Option 8: Spectral Mixture (flexible frequency-domain kernel)\n",
        "KERNEL_CONFIG = {\n",
        "    'view_kernel': 'spectral_mixture',\n",
        "    'kernel_kwargs': {'n_components': 2, 'angle_scale': 'normalized'}\n",
        "}\n",
        "\n",
        "print(\"Selected Kernel Configuration:\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Kernel type: {KERNEL_CONFIG['view_kernel']}\")\n",
        "if KERNEL_CONFIG['kernel_kwargs']:\n",
        "    print(f\"Parameters: {KERNEL_CONFIG['kernel_kwargs']}\")\n",
        "else:\n",
        "    print(\"Parameters: (default)\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeb82c9c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeb82c9c",
        "outputId": "636cc287-afdf-4cdc-c0ff-fb714f934f3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GP-VAE Training Configuration:\n",
            "============================================================\n",
            "  data                : ./data/faceplace/data_faces.h5\n",
            "  outdir              : ./out/gppvae_colab/spectral_mixture_random_20260116_194111\n",
            "  vae_cfg             : ./out/vae_colab_interpolation/20260103_192743/vae.cfg.p\n",
            "  vae_weights         : ./out/vae_colab_interpolation/20260103_192743/weights/weights.00499.pt\n",
            "  epochs              : 500\n",
            "  batch_size          : 64\n",
            "  vae_lr              : 0.001\n",
            "  gp_lr               : 0.001\n",
            "  xdim                : 64\n",
            "  view_kernel         : spectral_mixture\n",
            "  kernel_kwargs       : {'n_components': 2, 'angle_scale': 'normalized'}\n",
            "  use_angle_encoding  : True\n",
            "  view_split_mode     : interpolation\n",
            "  train_view_indices  : [0, 1, 3, 4, 5, 7, 8]\n",
            "  val_view_indices    : [2, 6]\n",
            "  epoch_cb            : 100\n",
            "  use_wandb           : True\n",
            "  wandb_project       : gppvae\n",
            "  wandb_run_name      : interpolation_spectral_mixture_20260116_194111\n",
            "  seed                : 0\n",
            "============================================================\n",
            "\n",
            "‚úÖ Output will be saved to:\n",
            "   ./out/gppvae_colab/spectral_mixture_random_20260116_194111\n",
            "\n",
            "   Directory name includes kernel type AND experiment mode!\n",
            "\n",
            "üí° Experiment: Interpolation (boundaries ‚Üí intermediate views)\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# GP-VAE Training configuration\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "kernel_name = KERNEL_CONFIG['view_kernel']\n",
        "\n",
        "# Include view split mode in directory name - \"interpolation\" for this experiment\n",
        "view_mode_str = 'interpolation' if VIEW_SPLIT_MODE == 'by_view' else 'random'\n",
        "\n",
        "CONFIG = {\n",
        "    'data': './data/faceplace/data_faces.h5',\n",
        "    # Output directory now includes kernel name AND experiment type\n",
        "    'outdir': f'./out/gppvae_colab/{kernel_name}_{view_mode_str}_{timestamp}',\n",
        "    'vae_cfg': './out/vae_colab_interpolation/20260103_192743/vae.cfg.p',\n",
        "    'vae_weights': './out/vae_colab_interpolation/20260103_192743/weights/weights.00499.pt',\n",
        "\n",
        "    # Training hyperparameters\n",
        "    'epochs': 500,\n",
        "    'batch_size': 64,\n",
        "    'vae_lr': 0.001,\n",
        "    'gp_lr': 0.001,\n",
        "    'xdim': 64,\n",
        "\n",
        "    # Kernel configuration\n",
        "    'view_kernel': KERNEL_CONFIG['view_kernel'],\n",
        "    'kernel_kwargs': KERNEL_CONFIG['kernel_kwargs'],\n",
        "\n",
        "    # Angle encoding (will be determined automatically based on kernel type)\n",
        "    'use_angle_encoding': KERNEL_CONFIG['view_kernel'] in ['rbf', 'matern', 'spectral_mixture'],\n",
        "\n",
        "    # Experiment configuration (NEW)\n",
        "    'view_split_mode': VIEW_SPLIT_MODE,\n",
        "    'train_view_indices': TRAIN_VIEW_INDICES,\n",
        "    'val_view_indices': VAL_VIEW_INDICES,\n",
        "\n",
        "    # Logging\n",
        "    'epoch_cb': 100,\n",
        "    'use_wandb': True,\n",
        "    'wandb_project': 'gppvae',\n",
        "    'wandb_run_name': f'interpolation_{kernel_name}_{timestamp}',\n",
        "    'seed': 0,\n",
        "}\n",
        "\n",
        "print(\"GP-VAE Training Configuration:\")\n",
        "print(\"=\" * 60)\n",
        "for key, value in CONFIG.items():\n",
        "    if key in ['train_view_indices', 'val_view_indices'] and value is not None:\n",
        "        print(f\"  {key:20s}: {value}\")\n",
        "    elif key not in ['train_view_indices', 'val_view_indices']:\n",
        "        print(f\"  {key:20s}: {value}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Verify VAE weights path\n",
        "if not os.path.exists(CONFIG['vae_weights']):\n",
        "    print(f\"\\n‚ö†Ô∏è  WARNING: VAE weights not found at:\")\n",
        "    print(f\"   {CONFIG['vae_weights']}\")\n",
        "\n",
        "print(f\"\\n‚úÖ Output will be saved to:\")\n",
        "print(f\"   {CONFIG['outdir']}\")\n",
        "print(f\"\\n   Directory name includes kernel type AND experiment mode!\")\n",
        "print(f\"\\nüí° Experiment: Interpolation (boundaries ‚Üí intermediate views)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9255bb2",
      "metadata": {
        "id": "f9255bb2"
      },
      "source": [
        "## 9. Import Training Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16ab22b2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16ab22b2",
        "outputId": "e5113324-315e-4005-ba3d-30141e13be98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All modules imported successfully!\n",
            "‚úÖ Using data_parser_interpolation for interpolation experiment\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.join(PROJECT_PATH, 'GPPVAE/pysrc/faceplace'))\n",
        "\n",
        "# Import modules\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from vae import FaceVAE\n",
        "from vmod import Vmodel\n",
        "from gp import GP\n",
        "import h5py\n",
        "import numpy as np\n",
        "import logging\n",
        "import pylab as pl\n",
        "from utils import smartSum, smartAppendDict, smartAppend, export_scripts\n",
        "from callbacks import callback_gppvae\n",
        "import pickle\n",
        "import time\n",
        "import wandb\n",
        "\n",
        "# IMPORTANT: Use interpolation data parser with angle encoding\n",
        "from data_parser_interpolation import read_face_data, FaceDataset\n",
        "\n",
        "print(\"‚úÖ All modules imported successfully!\")\n",
        "print(\"‚úÖ Using data_parser_interpolation for interpolation experiment\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1953910",
      "metadata": {
        "id": "e1953910"
      },
      "source": [
        "## 10. Setup Training Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd715632",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd715632",
        "outputId": "3d368cff-0ee8-49ee-9212-90976f50448a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n",
            "‚úÖ Training environment setup complete!\n",
            "   Outputs will be saved to: ./out/gppvae_colab/spectral_mixture_random_20260116_194111\n"
          ]
        }
      ],
      "source": [
        "# Go back to project root\n",
        "os.chdir(PROJECT_PATH)\n",
        "\n",
        "# Create output directories\n",
        "outdir = CONFIG['outdir']\n",
        "wdir = os.path.join(outdir, \"weights\")\n",
        "fdir = os.path.join(outdir, \"plots\")\n",
        "os.makedirs(wdir, exist_ok=True)\n",
        "os.makedirs(fdir, exist_ok=True)\n",
        "\n",
        "# Setup device (GPU)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Setup logging\n",
        "log_format = \"%(asctime)s %(message)s\"\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=log_format,\n",
        "    datefmt=\"%m/%d %I:%M:%S %p\",\n",
        ")\n",
        "fh = logging.FileHandler(os.path.join(outdir, \"log.txt\"))\n",
        "fh.setFormatter(logging.Formatter(log_format))\n",
        "logging.getLogger().addHandler(fh)\n",
        "\n",
        "# Copy code to output\n",
        "export_scripts(os.path.join(outdir, \"scripts\"))\n",
        "\n",
        "print(\"‚úÖ Training environment setup complete!\")\n",
        "print(f\"   Outputs will be saved to: {outdir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36678b2b",
      "metadata": {
        "id": "36678b2b"
      },
      "source": [
        "## 10. Initialize Models and Data\n",
        "\n",
        "This cell:\n",
        "1. Loads pre-trained VAE\n",
        "2. Creates GP and Vmodel\n",
        "3. Loads dataset\n",
        "4. Sets up optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c7bf143",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9c7bf143",
        "outputId": "01ead7d2-b07f-4a44-901b-87c29a21ee11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üéØ ANGLE ENCODING ENABLED\n",
            "   Kernel 'spectral_mixture' requires continuous angle values\n",
            "   Views will be encoded as normalized angles (e.g., -1.0 to +1.0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260116_194117-953yh8yg</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae/runs/953yh8yg' target=\"_blank\">interpolation_spectral_mixture_20260116_194111</a></strong> to <a href='https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae' target=\"_blank\">https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae/runs/953yh8yg' target=\"_blank\">https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae/runs/953yh8yg</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAE config: {'nf': 32, 'zdim': 256, 'vy': 0.002}\n",
            "\n",
            "Loading pre-trained VAE...\n",
            "‚úÖ VAE loaded from ./out/vae_colab_interpolation/20260103_192743/weights/weights.00499.pt\n",
            "   Total VAE parameters: 553,304\n",
            "\n",
            "Loading dataset with angle_encoding=True...\n",
            "\n",
            "üìÇ Loading data from: ./data/faceplace/data_faces.h5\n",
            "   Split mode: interpolation\n",
            "   Angle encoding: ‚úÖ ENABLED (using actual angles)\n",
            "\n",
            "üîç DEBUG: View encoding from HDF5\n",
            "   Unique Rid values in train: [np.bytes_(b'00F'), np.bytes_(b'30L'), np.bytes_(b'30R'), np.bytes_(b'45L'), np.bytes_(b'45R'), np.bytes_(b'60L'), np.bytes_(b'60R'), np.bytes_(b'90L'), np.bytes_(b'90R')]\n",
            "   uRid (ordered): [b'90L' b'60L' b'45L' b'30L' b'00F' b'30R' b'45R' b'60R' b'90R']\n",
            "   View mapping table_w: {np.bytes_(b'90L'): 0, np.bytes_(b'60L'): 1, np.bytes_(b'45L'): 2, np.bytes_(b'30L'): 3, np.bytes_(b'00F'): 4, np.bytes_(b'30R'): 5, np.bytes_(b'45R'): 6, np.bytes_(b'60R'): 7, np.bytes_(b'90R'): 8}\n",
            "   W['train'] unique values: [np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8)]\n",
            "   W['val'] unique values: []\n",
            "   W['test'] unique values: []\n",
            "\n",
            "‚úÖ View encoding applied:\n",
            "   All view indices converted to normalized angles [-1.0, 1.0]\n",
            "   This preserves geometric relationships between views\n",
            "\n",
            "üî¨ Applying interpolation split:\n",
            "   Train views (boundary): [0, 1, 3, 4, 5, 7, 8]\n",
            "   Val views (intermediate): [2, 6]\n",
            "\n",
            "üîç Filtering identities with complete view coverage (Interpolation)...\n",
            "   Required views: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
            "   Train views (boundary): [0, 1, 3, 4, 5, 7, 8]\n",
            "   Val views (intermediate): [2, 6]\n",
            "   Total identities before filtering: 412\n",
            "   üéØ Using ACTUAL ANGLE VALUES (not indices)\n",
            "   This provides geometric information to structured kernels\n",
            "   üéØ W already contains angles, matching against angle values\n",
            "   Identities with all required views: 412\n",
            "   Filtered out: 0 identities\n",
            "   ‚úÖ Remapped 412 identities to contiguous indices [0..411]\n",
            "   ‚úÖ W already encoded as angles, no conversion needed\n",
            "\n",
            "‚úÖ Interpolation split validation:\n",
            "   Total samples (filtered): 3708\n",
            "   Train samples: 2884 (views: [np.float32(-1.0), np.float32(-0.6666667), np.float32(-0.33333334), np.float32(0.0), np.float32(0.33333334), np.float32(0.6666667), np.float32(1.0)])\n",
            "   Val samples: 824 (views: [np.float32(-0.5), np.float32(0.5)])\n",
            "   Train identities: 412\n",
            "   Val identities: 412\n",
            "   Identity overlap: 412\n",
            "   ‚úÖ All 412 identities present in both train/val!\n",
            "   Train samples per identity: 7.0 (expected: 7.0)\n",
            "   Val samples per identity: 2.0 (expected: 2.0)\n",
            "   ‚úÖ Perfect split verified!\n",
            "\n",
            "üéØ Interpolation task verification:\n",
            "   Training on boundary angles:\n",
            "      Index 0: 90L ‚Üí encoded as -1.000\n",
            "      Index 1: 60L ‚Üí encoded as -0.667\n",
            "      Index 3: 30L ‚Üí encoded as -0.333\n",
            "      Index 4: 00F ‚Üí encoded as 0.000\n",
            "      Index 5: 30R ‚Üí encoded as 0.333\n",
            "      Index 7: 60R ‚Üí encoded as 0.667\n",
            "      Index 8: 90R ‚Üí encoded as 1.000\n",
            "   Testing on intermediate angles:\n",
            "      Index 2: 45L (interpolation target) ‚Üí encoded as -0.500\n",
            "      Index 6: 45R (interpolation target) ‚Üí encoded as 0.500\n",
            "   ‚úÖ 45L is bounded by training views 60L and 30L\n",
            "   ‚úÖ 45R is bounded by training views 30R and 60R\n",
            "\n",
            "   üìê Geometric distances now explicit:\n",
            "      distance(90L, 60L) = |-1.00 - (-0.67)| = 0.33 (30¬∞)\n",
            "      distance(60L, 45L) = |-0.67 - (-0.50)| = 0.17 (15¬∞)\n",
            "      distance(45L, 30L) = |-0.50 - (-0.33)| = 0.17 (15¬∞)\n",
            "   ‚úÖ True angular distances preserved!\n",
            "\n",
            "‚úÖ Interpolation split final validation:\n",
            "   ‚úÖ Train angles correct: [np.float32(-1.0), np.float32(-0.6666667), np.float32(-0.33333334), np.float32(0.0), np.float32(0.33333334), np.float32(0.6666667), np.float32(1.0)]\n",
            "   ‚úÖ Val angles correct: [np.float32(-0.5), np.float32(0.5)]\n",
            "   ‚úÖ No overlap between train/val views\n",
            "\n",
            "üí° Interpolation Task Expectations:\n",
            "   ‚úÖ Using ACTUAL ANGLE VALUES (geometrically correct)\n",
            "   - Structured kernels can directly leverage angular smoothness\n",
            "   - Periodic/VonMises kernels know true distances between views\n",
            "   - Expected: Smoother interpolation from structured kernels\n",
            "   - FullRank must learn geometry from data (more parameters)\n",
            "\n",
            "   Key metric: How smoothly does each kernel interpolate?\n",
            "\n",
            "‚úÖ Final dataset sizes:\n",
            "   test :     0 samples\n",
            "   train:  2884 samples\n",
            "           Unique view angles: 7 [np.float32(-1.0), np.float32(-0.667), np.float32(-0.333), np.float32(0.0), np.float32(0.333), np.float32(0.667), np.float32(1.0)]\n",
            "   val  :   824 samples\n",
            "           Unique view angles: 2 [np.float32(-0.5), np.float32(0.5)]\n",
            "\n",
            "‚úÖ Data loaded:\n",
            "   Training samples: 2884\n",
            "   Validation samples: 824\n",
            "   Train view angles: [-1.    -0.667 -0.333  0.     0.333  0.667  1.   ]\n",
            "   Val view angles: [-0.5  0.5]\n",
            "   Unique train identities: 412\n",
            "   Unique val identities: 412\n",
            "\n",
            "Initializing GP-VAE components...\n",
            "   Objects (people): 412\n",
            "   Views (reference angles): 9\n",
            "   Using continuous angle values\n",
            "\n",
            "üî¨ Initializing view kernel: 'spectral_mixture'\n",
            "   Kernel parameters: {'n_components': 2, 'angle_scale': 'normalized'}\n",
            "‚úÖ GP-VAE components initialized:\n",
            "   Vmodel parameters: 26,374\n",
            "   GP parameters: 2\n",
            "   Total trainable: 579,680\n",
            "\n",
            "‚úÖ Optimizers created:\n",
            "   VAE optimizer: Adam(lr=0.001)\n",
            "   GP optimizer: Adam(lr=0.001)\n"
          ]
        }
      ],
      "source": [
        "# Set random seed\n",
        "torch.manual_seed(CONFIG['seed'])\n",
        "\n",
        "# Determine if we need angle encoding based on kernel choice\n",
        "# RBF, Mat√©rn, and Spectral Mixture kernels work with continuous angles\n",
        "use_angle_encoding = CONFIG['view_kernel'] in ['rbf', 'matern', 'spectral_mixture']\n",
        "\n",
        "if use_angle_encoding:\n",
        "    print(\"\\nüéØ ANGLE ENCODING ENABLED\")\n",
        "    print(f\"   Kernel '{CONFIG['view_kernel']}' requires continuous angle values\")\n",
        "    print(f\"   Views will be encoded as normalized angles (e.g., -1.0 to +1.0)\")\n",
        "else:\n",
        "    print(\"\\nüìç DISCRETE VIEW INDICES MODE\")\n",
        "    print(f\"   Kernel '{CONFIG['view_kernel']}' uses discrete view embeddings\")\n",
        "\n",
        "# Initialize W&B\n",
        "if CONFIG['use_wandb']:\n",
        "    wandb.init(\n",
        "        project=CONFIG['wandb_project'],\n",
        "        name=CONFIG['wandb_run_name'],\n",
        "        config=CONFIG  # CONFIG already contains use_angle_encoding\n",
        "    )\n",
        "\n",
        "# Load VAE configuration\n",
        "vae_cfg = pickle.load(open(CONFIG['vae_cfg'], \"rb\"))\n",
        "print(f\"VAE config: {vae_cfg}\")\n",
        "\n",
        "# Load pre-trained VAE\n",
        "print(\"\\nLoading pre-trained VAE...\")\n",
        "vae = FaceVAE(**vae_cfg).to(device)\n",
        "vae_state = torch.load(CONFIG['vae_weights'], map_location=device)\n",
        "vae.load_state_dict(vae_state)\n",
        "print(f\"‚úÖ VAE loaded from {CONFIG['vae_weights']}\")\n",
        "print(f\"   Total VAE parameters: {sum(p.numel() for p in vae.parameters()):,}\")\n",
        "\n",
        "# Load data with interpolation experiment configuration\n",
        "print(f\"\\nLoading dataset with angle_encoding={use_angle_encoding}...\")\n",
        "img, obj, view = read_face_data(\n",
        "    CONFIG['data'],\n",
        "    use_angle_encoding=use_angle_encoding,\n",
        "    view_split_mode=CONFIG['view_split_mode'],\n",
        "    train_view_indices=CONFIG.get('train_view_indices'),\n",
        "    val_view_indices=CONFIG.get('val_view_indices')\n",
        ")\n",
        "\n",
        "train_data = FaceDataset(img[\"train\"], obj[\"train\"], view[\"train\"])\n",
        "val_data = FaceDataset(img[\"val\"], obj[\"val\"], view[\"val\"])\n",
        "train_queue = DataLoader(train_data, batch_size=CONFIG['batch_size'], shuffle=True)\n",
        "val_queue = DataLoader(val_data, batch_size=CONFIG['batch_size'], shuffle=False)\n",
        "\n",
        "# Enhanced diagnostic logging\n",
        "print(f\"\\n‚úÖ Data loaded:\")\n",
        "print(f\"   Training samples: {len(train_data)}\")\n",
        "print(f\"   Validation samples: {len(val_data)}\")\n",
        "if use_angle_encoding:\n",
        "    print(f\"   Train view angles: {np.unique(view['train'].numpy().round(3))}\")\n",
        "    print(f\"   Val view angles: {np.unique(view['val'].numpy().round(3))}\")\n",
        "else:\n",
        "    print(f\"   Train view indices: {np.unique(view['train'].numpy())}\")\n",
        "    print(f\"   Val view indices: {np.unique(view['val'].numpy())}\")\n",
        "print(f\"   Unique train identities: {len(np.unique(obj['train'].numpy()))}\")\n",
        "print(f\"   Unique val identities: {len(np.unique(obj['val'].numpy()))}\")\n",
        "\n",
        "# Validation checks for interpolation experiment\n",
        "if CONFIG['view_split_mode'] == 'by_view':\n",
        "    print(\"\\nüîç Interpolation Experiment Validation Checks:\")\n",
        "\n",
        "    if use_angle_encoding:\n",
        "        # With angle encoding, views are continuous floats\n",
        "        # Need to check against expected angle values\n",
        "        from data_parser_interpolation import encode_view_angles\n",
        "        train_angles_expected = encode_view_angles(\n",
        "            np.array(CONFIG['train_view_indices']),\n",
        "            encoding='normalized'\n",
        "        ).numpy().round(6)\n",
        "        val_angles_expected = encode_view_angles(\n",
        "            np.array(CONFIG['val_view_indices']),\n",
        "            encoding='normalized'\n",
        "        ).numpy().round(6)\n",
        "\n",
        "        train_angles_actual = np.round(np.unique(view['train'].numpy().flatten()), 6)\n",
        "        val_angles_actual = np.round(np.unique(view['val'].numpy().flatten()), 6)\n",
        "\n",
        "        assert set(train_angles_actual) == set(train_angles_expected), \"Train angles mismatch!\"\n",
        "        assert set(val_angles_actual) == set(val_angles_expected), \"Val angles mismatch!\"\n",
        "        print(\"   ‚úÖ View angles verified correctly!\")\n",
        "    else:\n",
        "        # Check 1: View split correctness with discrete indices\n",
        "        train_views_set = set(np.unique(view['train'].numpy().flatten()).astype(int))\n",
        "        val_views_set = set(np.unique(view['val'].numpy().flatten()).astype(int))\n",
        "\n",
        "        assert train_views_set == set(CONFIG['train_view_indices']), f\"Train views mismatch!\"\n",
        "        assert val_views_set == set(CONFIG['val_view_indices']), f\"Val views mismatch!\"\n",
        "        assert len(train_views_set & val_views_set) == 0, \"Train and val views overlap!\"\n",
        "        print(\"   ‚úÖ View split verified correctly!\")\n",
        "\n",
        "    # Check 2: Identity coverage\n",
        "    train_ids = set(np.unique(obj['train'].numpy()))\n",
        "    val_ids = set(np.unique(obj['val'].numpy()))\n",
        "    assert train_ids == val_ids, \"Identity sets don't match between train/val!\"\n",
        "    print(f\"   ‚úÖ All {len(train_ids)} identities present in both train/val!\")\n",
        "\n",
        "    # Check 3: Sample distribution\n",
        "    train_samples_per_id = len(img['train']) / len(train_ids)\n",
        "    val_samples_per_id = len(img['val']) / len(val_ids)\n",
        "    print(f\"   ‚úÖ Train samples per identity: {train_samples_per_id:.1f} (expected: {len(CONFIG['train_view_indices'])}.0)\")\n",
        "    print(f\"   ‚úÖ Val samples per identity: {val_samples_per_id:.1f} (expected: {len(CONFIG['val_view_indices'])}.0)\")\n",
        "\n",
        "# Create object and view variables for GP\n",
        "Dt = Variable(obj[\"train\"][:, 0].long(), requires_grad=False).cuda()\n",
        "Dv = Variable(obj[\"val\"][:, 0].long(), requires_grad=False).cuda()\n",
        "\n",
        "# Keep view as float if using angle encoding, otherwise convert to long\n",
        "if use_angle_encoding:\n",
        "    Wt = Variable(view[\"train\"][:, 0], requires_grad=False).cuda()  # Float angles\n",
        "    Wv = Variable(view[\"val\"][:, 0], requires_grad=False).cuda()  # Float angles\n",
        "else:\n",
        "    Wt = Variable(view[\"train\"][:, 0].long(), requires_grad=False).cuda()  # Integer indices\n",
        "    Wv = Variable(view[\"val\"][:, 0].long(), requires_grad=False).cuda()  # Integer indices\n",
        "\n",
        "# Initialize GP and Vmodel\n",
        "print(\"\\nInitializing GP-VAE components...\")\n",
        "\n",
        "# Count unique identities and views\n",
        "all_identities = np.unique(np.concatenate([obj[\"train\"].numpy(), obj[\"val\"].numpy()]))\n",
        "\n",
        "if use_angle_encoding:\n",
        "    # With angle encoding, Q is still the number of reference angles (9 views)\n",
        "    Q = 9\n",
        "    P = len(all_identities)\n",
        "    print(f\"   Objects (people): {P}\")\n",
        "    print(f\"   Views (reference angles): {Q}\")\n",
        "    print(f\"   Using continuous angle values\")\n",
        "else:\n",
        "    # With discrete indices, count unique view indices\n",
        "    all_views = np.unique(np.concatenate([view[\"train\"].numpy(), view[\"val\"].numpy()]))\n",
        "    Q = len(all_views)\n",
        "    P = len(all_identities)\n",
        "    print(f\"   Objects (people): {P}\")\n",
        "    print(f\"   Views (discrete): {Q}\")\n",
        "    print(f\"   Train views: {sorted(np.unique(view['train'].numpy()).astype(int).tolist())}\")\n",
        "    print(f\"   Val views: {sorted(np.unique(view['val'].numpy()).astype(int).tolist())}\")\n",
        "\n",
        "# Initialize Vmodel with standard discrete view indices\n",
        "vm = Vmodel(\n",
        "    P, Q,\n",
        "    p=CONFIG['xdim'],\n",
        "    q=Q,  # For legacy, q=Q\n",
        "    view_kernel=CONFIG['view_kernel'],\n",
        "    **CONFIG['kernel_kwargs']\n",
        ").cuda()\n",
        "\n",
        "print(f\"\\nüî¨ Initializing view kernel: '{CONFIG['view_kernel']}'\")\n",
        "if CONFIG['kernel_kwargs']:\n",
        "    print(f\"   Kernel parameters: {CONFIG['kernel_kwargs']}\")\n",
        "else:\n",
        "    print(f\"   Kernel parameters: (default)\")\n",
        "\n",
        "gp = GP(n_rand_effs=1).to(device)\n",
        "\n",
        "# Combine GP parameters (Vmodel + GP)\n",
        "gp_params = nn.ParameterList()\n",
        "gp_params.extend(vm.parameters())\n",
        "gp_params.extend(gp.parameters())\n",
        "\n",
        "print(f\"‚úÖ GP-VAE components initialized:\")\n",
        "print(f\"   Vmodel parameters: {sum(p.numel() for p in vm.parameters()):,}\")\n",
        "print(f\"   GP parameters: {sum(p.numel() for p in gp.parameters()):,}\")\n",
        "print(f\"   Total trainable: {sum(p.numel() for p in vae.parameters()) + sum(p.numel() for p in gp_params):,}\")\n",
        "\n",
        "# Create optimizers (separate for VAE and GP)\n",
        "vae_optimizer = optim.Adam(vae.parameters(), lr=CONFIG['vae_lr'])\n",
        "gp_optimizer = optim.Adam(gp_params, lr=CONFIG['gp_lr'])\n",
        "print(f\"\\n‚úÖ Optimizers created:\")\n",
        "print(f\"   VAE optimizer: Adam(lr={CONFIG['vae_lr']})\")\n",
        "print(f\"   GP optimizer: Adam(lr={CONFIG['gp_lr']})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9082858",
      "metadata": {
        "id": "b9082858"
      },
      "source": [
        "## 11. Define Training Functions\n",
        "\n",
        "These functions handle the complex GP-VAE training loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfa7bebf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfa7bebf",
        "outputId": "3cd637e1-4c0f-4d1f-f741-285938cae4bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Training functions defined with per-view metrics for interpolation\n",
            "‚úÖ Diverse identity sampling now collects from entire validation set\n"
          ]
        }
      ],
      "source": [
        "def encode_Y(vae, train_queue):\n",
        "    \"\"\"Encode all training images to get latent codes\"\"\"\n",
        "    vae.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        n = train_queue.dataset.Y.shape[0]\n",
        "        Zm = Variable(torch.zeros(n, vae_cfg[\"zdim\"]), requires_grad=False).cuda()\n",
        "        Zs = Variable(torch.zeros(n, vae_cfg[\"zdim\"]), requires_grad=False).cuda()\n",
        "\n",
        "        for batch_i, data in enumerate(train_queue):\n",
        "            y = data[0].cuda()\n",
        "            idxs = data[-1].cuda()\n",
        "            zm, zs = vae.encode(y)\n",
        "            Zm[idxs], Zs[idxs] = zm.detach(), zs.detach()\n",
        "\n",
        "    return Zm, Zs\n",
        "\n",
        "\n",
        "def eval_step(vae, gp, vm, val_queue, Zm, Vt, Vv, Wv, use_angle_encoding=False):\n",
        "    \"\"\"Enhanced evaluation with per-view metrics for Interpolation Experiment\"\"\"\n",
        "    rv = {}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _X = vm.x().data.cpu().numpy()\n",
        "        _W = vm.v().data.cpu().numpy()\n",
        "        covs = {\"XX\": np.dot(_X, _X.T), \"WW\": np.dot(_W, _W.T)}\n",
        "        rv[\"vars\"] = gp.get_vs().data.cpu().numpy()\n",
        "\n",
        "        # Out-of-sample prediction\n",
        "        vs = gp.get_vs()\n",
        "        U, UBi, _ = gp.U_UBi_Shb([Vt], vs)\n",
        "        Kiz = gp.solve(Zm, U, UBi, vs)\n",
        "        Zo = vs[0] * Vv.mm(Vt.transpose(0, 1).mm(Kiz))\n",
        "\n",
        "        mse_out = Variable(torch.zeros(Vv.shape[0], 1), requires_grad=False).cuda()\n",
        "        mse_val = Variable(torch.zeros(Vv.shape[0], 1), requires_grad=False).cuda()\n",
        "\n",
        "        # Collect ALL validation samples first for diverse sampling\n",
        "        all_Yv = []\n",
        "        all_Yr = []\n",
        "        all_Yo = []\n",
        "\n",
        "        for batch_i, data in enumerate(val_queue):\n",
        "            idxs = data[-1].cuda()\n",
        "            Yv = data[0].cuda()\n",
        "            Zv = vae.encode(Yv)[0].detach()\n",
        "            Yr = vae.decode(Zv)\n",
        "            Yo = vae.decode(Zo[idxs])\n",
        "            mse_out[idxs] = ((Yv - Yo) ** 2).view(Yv.shape[0], -1).mean(1)[:, None].detach()\n",
        "            mse_val[idxs] = ((Yv - Yr) ** 2).view(Yv.shape[0], -1).mean(1)[:, None].detach()\n",
        "\n",
        "            # Collect all samples for diverse visualization\n",
        "            all_Yv.append(Yv.data.cpu().numpy().transpose(0, 2, 3, 1))\n",
        "            all_Yr.append(Yr.data.cpu().numpy().transpose(0, 2, 3, 1))\n",
        "            all_Yo.append(Yo.data.cpu().numpy().transpose(0, 2, 3, 1))\n",
        "\n",
        "        # Concatenate all validation samples\n",
        "        all_Yv = np.concatenate(all_Yv, axis=0)\n",
        "        all_Yr = np.concatenate(all_Yr, axis=0)\n",
        "        all_Yo = np.concatenate(all_Yo, axis=0)\n",
        "\n",
        "        # Sample diverse identities across the validation set (evenly spaced)\n",
        "        n_total = all_Yv.shape[0]\n",
        "        if n_total >= 24:\n",
        "            sample_stride = max(1, n_total // 24)\n",
        "            sample_indices = np.arange(0, n_total, sample_stride)[:24]\n",
        "        else:\n",
        "            sample_indices = np.arange(min(24, n_total))\n",
        "\n",
        "        imgs = {}\n",
        "        imgs[\"Yv\"] = all_Yv[sample_indices]\n",
        "        imgs[\"Yr\"] = all_Yr[sample_indices]\n",
        "        imgs[\"Yo\"] = all_Yo[sample_indices]\n",
        "\n",
        "        rv[\"mse_out\"] = float(mse_out.data.mean().cpu())\n",
        "        rv[\"mse_val\"] = float(mse_val.data.mean().cpu())\n",
        "\n",
        "        # NEW: Per-view metrics for Interpolation Experiment\n",
        "        # Need to handle both continuous angles and discrete indices\n",
        "        if use_angle_encoding:\n",
        "            # With angle encoding, need to map angles back to view indices\n",
        "            from data_parser_interpolation import encode_view_angles\n",
        "            # Create mapping from angles to indices for validation views\n",
        "            val_indices = np.array(CONFIG['val_view_indices'])\n",
        "            val_angles = encode_view_angles(val_indices, encoding='normalized').numpy()\n",
        "\n",
        "            # Map each unique angle back to its index\n",
        "            mse_val_per_view = {}\n",
        "            mse_out_per_view = {}\n",
        "\n",
        "            for idx, angle in zip(val_indices, val_angles):\n",
        "                # Find samples with this angle (with small tolerance for floating point)\n",
        "                view_mask = np.abs(Wv.cpu().numpy().flatten() - angle) < 1e-5\n",
        "                if view_mask.sum() > 0:\n",
        "                    mse_val_per_view[int(idx)] = float(mse_val.cpu().numpy()[view_mask].mean())\n",
        "                    mse_out_per_view[int(idx)] = float(mse_out.cpu().numpy()[view_mask].mean())\n",
        "        else:\n",
        "            # With discrete indices, use them directly\n",
        "            unique_views = torch.unique(Wv).cpu().numpy()\n",
        "            mse_val_per_view = {}\n",
        "            mse_out_per_view = {}\n",
        "\n",
        "            for view_idx in unique_views:\n",
        "                view_mask = (Wv.cpu().numpy().flatten() == view_idx)\n",
        "                if view_mask.sum() > 0:\n",
        "                    mse_val_per_view[int(view_idx)] = float(mse_val.cpu().numpy()[view_mask].mean())\n",
        "                    mse_out_per_view[int(view_idx)] = float(mse_out.cpu().numpy()[view_mask].mean())\n",
        "\n",
        "        rv['mse_val_per_view'] = mse_val_per_view\n",
        "        rv['mse_out_per_view'] = mse_out_per_view\n",
        "\n",
        "    return rv, imgs, covs\n",
        "\n",
        "\n",
        "def backprop_and_update(vae, gp, vm, train_queue, Dt, Wt, Eps, Zb, Vbs, vbs, vae_optimizer, gp_optimizer):\n",
        "    \"\"\"Joint optimization of VAE and GP\"\"\"\n",
        "    rv = {}\n",
        "\n",
        "    vae_optimizer.zero_grad()\n",
        "    gp_optimizer.zero_grad()\n",
        "    vae.train()\n",
        "    gp.train()\n",
        "    vm.train()\n",
        "\n",
        "    for batch_i, data in enumerate(train_queue):\n",
        "        # Get batch data\n",
        "        y = data[0].cuda()\n",
        "        eps = Eps[data[-1]]\n",
        "        _d = Dt[data[-1]]\n",
        "        _w = Wt[data[-1]]\n",
        "        _Zb = Zb[data[-1]]\n",
        "        _Vbs = [Vbs[0][data[-1]]]\n",
        "\n",
        "        # Forward through VAE\n",
        "        zm, zs = vae.encode(y)\n",
        "        z = zm + zs * eps\n",
        "        yr = vae.decode(z)\n",
        "        recon_term, mse = vae.nll(y, yr)\n",
        "\n",
        "        # Forward through GP\n",
        "        _Vs = [vm(_d, _w)]\n",
        "        gp_nll_fo = gp.taylor_expansion(z, _Vs, _Zb, _Vbs, vbs) / vae.K\n",
        "\n",
        "        # Penalization term\n",
        "        pen_term = -0.5 * zs.sum(1)[:, None] / vae.K\n",
        "\n",
        "        # Joint loss and backward\n",
        "        loss = (recon_term + gp_nll_fo + pen_term).sum()\n",
        "        loss.backward()\n",
        "\n",
        "        # Accumulate metrics\n",
        "        _n = train_queue.dataset.Y.shape[0]\n",
        "        smartSum(rv, \"mse\", float(mse.data.sum().cpu()) / _n)\n",
        "        smartSum(rv, \"recon_term\", float(recon_term.data.sum().cpu()) / _n)\n",
        "        smartSum(rv, \"pen_term\", float(pen_term.data.sum().cpu()) / _n)\n",
        "\n",
        "    # Update both optimizers\n",
        "    vae_optimizer.step()\n",
        "    gp_optimizer.step()\n",
        "\n",
        "    return rv\n",
        "\n",
        "\n",
        "print(\"‚úÖ Training functions defined with per-view metrics for interpolation\")\n",
        "print(\"‚úÖ Diverse identity sampling now collects from entire validation set\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c869fdf",
      "metadata": {
        "id": "4c869fdf"
      },
      "source": [
        "## 12. Train GP-VAE Model üöÄ\n",
        "\n",
        "**This is joint optimization!** Both VAE and GP are updated together each iteration.\n",
        "\n",
        "Training process per epoch:\n",
        "1. Encode images to latent codes (VAE)\n",
        "2. Compute GP prior likelihood on latents\n",
        "3. Backpropagate through joint loss\n",
        "4. Update VAE, GP, and Vmodel simultaneously"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f6f1485",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2f6f1485",
        "outputId": "115f7d3e-80c6-43ef-8004-483df36b824e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Starting GP-VAE Interpolation Experiment training for 500 epochs...\n",
            "================================================================================\n",
            "Training mode: JOINT OPTIMIZATION (VAE + GP updated together)\n",
            "Experiment: Interpolation (boundaries ‚Üí intermediate)\n",
            "  Training views: [0, 1, 3, 4, 5, 7, 8]\n",
            "  Validation views: [2, 6]\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/gppvae/GPPVAE/pysrc/faceplace/vae.py:46: UserWarning: `nn.functional.upsample` is deprecated. Use `nn.functional.interpolate` instead.\n",
            "  x = F.upsample(x, scale_factor=2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/500 | MSE train: 0.002526 | MSE val: 0.003971 | MSE out: 0.065513 | GP NLL: 0.0020 | Gap(T-V): -0.001445 | Gap(V-O): 0.061542 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.500 | Time: 4.9s\n",
            "  ‚úì Checkpoint saved at epoch 0\n",
            "Epoch    5/500 | MSE train: 0.009799 | MSE val: 0.010512 | MSE out: 0.062352 | GP NLL: 0.0021 | Gap(T-V): -0.000713 | Gap(V-O): 0.051840 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.497 | Time: 1.9s\n",
            "Epoch   10/500 | MSE train: 0.006924 | MSE val: 0.007777 | MSE out: 0.049706 | GP NLL: 0.0034 | Gap(T-V): -0.000853 | Gap(V-O): 0.041929 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.495 | Time: 1.8s\n",
            "Epoch   15/500 | MSE train: 0.005426 | MSE val: 0.006319 | MSE out: 0.047286 | GP NLL: 0.0024 | Gap(T-V): -0.000893 | Gap(V-O): 0.040967 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.492 | Time: 1.9s\n",
            "Epoch   20/500 | MSE train: 0.004499 | MSE val: 0.005366 | MSE out: 0.043305 | GP NLL: 0.0020 | Gap(T-V): -0.000867 | Gap(V-O): 0.037939 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.490 | Time: 1.8s\n",
            "Epoch   25/500 | MSE train: 0.003981 | MSE val: 0.004969 | MSE out: 0.040760 | GP NLL: 0.0018 | Gap(T-V): -0.000988 | Gap(V-O): 0.035791 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.489 | Time: 1.8s\n",
            "Epoch   30/500 | MSE train: 0.003591 | MSE val: 0.004633 | MSE out: 0.039958 | GP NLL: 0.0014 | Gap(T-V): -0.001042 | Gap(V-O): 0.035324 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.487 | Time: 1.8s\n",
            "Epoch   35/500 | MSE train: 0.003288 | MSE val: 0.004407 | MSE out: 0.038277 | GP NLL: 0.0014 | Gap(T-V): -0.001119 | Gap(V-O): 0.033870 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.486 | Time: 1.9s\n",
            "Epoch   40/500 | MSE train: 0.003042 | MSE val: 0.004201 | MSE out: 0.037963 | GP NLL: 0.0012 | Gap(T-V): -0.001159 | Gap(V-O): 0.033762 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.486 | Time: 1.8s\n",
            "Epoch   45/500 | MSE train: 0.002893 | MSE val: 0.004113 | MSE out: 0.037335 | GP NLL: 0.0011 | Gap(T-V): -0.001220 | Gap(V-O): 0.033222 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.486 | Time: 1.8s\n",
            "Epoch   50/500 | MSE train: 0.002763 | MSE val: 0.004022 | MSE out: 0.036832 | GP NLL: 0.0010 | Gap(T-V): -0.001258 | Gap(V-O): 0.032811 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.487 | Time: 1.8s\n",
            "Epoch   55/500 | MSE train: 0.002655 | MSE val: 0.003947 | MSE out: 0.036558 | GP NLL: 0.0009 | Gap(T-V): -0.001291 | Gap(V-O): 0.032612 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.488 | Time: 1.8s\n",
            "Epoch   60/500 | MSE train: 0.002574 | MSE val: 0.003895 | MSE out: 0.036149 | GP NLL: 0.0008 | Gap(T-V): -0.001321 | Gap(V-O): 0.032254 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.490 | Time: 1.8s\n",
            "Epoch   65/500 | MSE train: 0.002510 | MSE val: 0.003856 | MSE out: 0.035742 | GP NLL: 0.0007 | Gap(T-V): -0.001346 | Gap(V-O): 0.031886 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.491 | Time: 1.8s\n",
            "Epoch   70/500 | MSE train: 0.002456 | MSE val: 0.003827 | MSE out: 0.035526 | GP NLL: 0.0006 | Gap(T-V): -0.001371 | Gap(V-O): 0.031698 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.493 | Time: 1.9s\n",
            "Epoch   75/500 | MSE train: 0.002412 | MSE val: 0.003802 | MSE out: 0.035441 | GP NLL: 0.0006 | Gap(T-V): -0.001390 | Gap(V-O): 0.031639 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.496 | Time: 1.8s\n",
            "Epoch   80/500 | MSE train: 0.002374 | MSE val: 0.003781 | MSE out: 0.035255 | GP NLL: 0.0005 | Gap(T-V): -0.001407 | Gap(V-O): 0.031474 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.498 | Time: 1.8s\n",
            "Epoch   85/500 | MSE train: 0.002342 | MSE val: 0.003760 | MSE out: 0.035084 | GP NLL: 0.0005 | Gap(T-V): -0.001418 | Gap(V-O): 0.031324 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.501 | Time: 1.9s\n",
            "Epoch   90/500 | MSE train: 0.002314 | MSE val: 0.003744 | MSE out: 0.034955 | GP NLL: 0.0004 | Gap(T-V): -0.001430 | Gap(V-O): 0.031211 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.503 | Time: 1.8s\n",
            "Epoch   95/500 | MSE train: 0.002289 | MSE val: 0.003729 | MSE out: 0.034846 | GP NLL: 0.0004 | Gap(T-V): -0.001440 | Gap(V-O): 0.031116 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.506 | Time: 1.8s\n",
            "Epoch  100/500 | MSE train: 0.002267 | MSE val: 0.003716 | MSE out: 0.034729 | GP NLL: 0.0004 | Gap(T-V): -0.001449 | Gap(V-O): 0.031013 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.509 | Time: 1.8s\n",
            "  ‚úì Checkpoint saved at epoch 100\n",
            "Epoch  105/500 | MSE train: 0.002248 | MSE val: 0.003706 | MSE out: 0.034658 | GP NLL: 0.0003 | Gap(T-V): -0.001458 | Gap(V-O): 0.030953 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.512 | Time: 1.8s\n",
            "Epoch  110/500 | MSE train: 0.002230 | MSE val: 0.003697 | MSE out: 0.034590 | GP NLL: 0.0003 | Gap(T-V): -0.001466 | Gap(V-O): 0.030893 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.515 | Time: 1.8s\n",
            "Epoch  115/500 | MSE train: 0.002215 | MSE val: 0.003688 | MSE out: 0.034475 | GP NLL: 0.0003 | Gap(T-V): -0.001473 | Gap(V-O): 0.030787 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.518 | Time: 1.8s\n",
            "Epoch  120/500 | MSE train: 0.002200 | MSE val: 0.003680 | MSE out: 0.034384 | GP NLL: 0.0002 | Gap(T-V): -0.001480 | Gap(V-O): 0.030703 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.521 | Time: 1.9s\n",
            "Epoch  125/500 | MSE train: 0.002188 | MSE val: 0.003673 | MSE out: 0.034308 | GP NLL: 0.0002 | Gap(T-V): -0.001485 | Gap(V-O): 0.030635 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.524 | Time: 1.9s\n",
            "Epoch  130/500 | MSE train: 0.002176 | MSE val: 0.003666 | MSE out: 0.034267 | GP NLL: 0.0002 | Gap(T-V): -0.001491 | Gap(V-O): 0.030601 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.527 | Time: 1.9s\n",
            "Epoch  135/500 | MSE train: 0.002165 | MSE val: 0.003660 | MSE out: 0.034191 | GP NLL: 0.0002 | Gap(T-V): -0.001495 | Gap(V-O): 0.030530 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.530 | Time: 1.8s\n",
            "Epoch  140/500 | MSE train: 0.002155 | MSE val: 0.003655 | MSE out: 0.034149 | GP NLL: 0.0001 | Gap(T-V): -0.001500 | Gap(V-O): 0.030493 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.533 | Time: 1.8s\n",
            "Epoch  145/500 | MSE train: 0.002146 | MSE val: 0.003651 | MSE out: 0.034044 | GP NLL: 0.0001 | Gap(T-V): -0.001504 | Gap(V-O): 0.030393 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.536 | Time: 1.8s\n",
            "Epoch  150/500 | MSE train: 0.002138 | MSE val: 0.003646 | MSE out: 0.033983 | GP NLL: 0.0001 | Gap(T-V): -0.001508 | Gap(V-O): 0.030337 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.539 | Time: 1.8s\n",
            "Epoch  155/500 | MSE train: 0.002130 | MSE val: 0.003642 | MSE out: 0.033904 | GP NLL: 0.0001 | Gap(T-V): -0.001512 | Gap(V-O): 0.030262 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.542 | Time: 1.8s\n",
            "Epoch  160/500 | MSE train: 0.002123 | MSE val: 0.003639 | MSE out: 0.033828 | GP NLL: 0.0001 | Gap(T-V): -0.001516 | Gap(V-O): 0.030190 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.545 | Time: 1.9s\n",
            "Epoch  165/500 | MSE train: 0.002116 | MSE val: 0.003635 | MSE out: 0.033725 | GP NLL: 0.0000 | Gap(T-V): -0.001519 | Gap(V-O): 0.030090 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.548 | Time: 1.9s\n",
            "Epoch  170/500 | MSE train: 0.002110 | MSE val: 0.003632 | MSE out: 0.033678 | GP NLL: 0.0000 | Gap(T-V): -0.001522 | Gap(V-O): 0.030046 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.551 | Time: 1.8s\n",
            "Epoch  175/500 | MSE train: 0.002105 | MSE val: 0.003630 | MSE out: 0.033615 | GP NLL: 0.0000 | Gap(T-V): -0.001525 | Gap(V-O): 0.029985 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.554 | Time: 1.8s\n",
            "Epoch  180/500 | MSE train: 0.002099 | MSE val: 0.003627 | MSE out: 0.033540 | GP NLL: -0.0000 | Gap(T-V): -0.001528 | Gap(V-O): 0.029913 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.557 | Time: 1.8s\n",
            "Epoch  185/500 | MSE train: 0.002094 | MSE val: 0.003625 | MSE out: 0.033461 | GP NLL: -0.0000 | Gap(T-V): -0.001531 | Gap(V-O): 0.029836 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.560 | Time: 1.9s\n",
            "Epoch  190/500 | MSE train: 0.002089 | MSE val: 0.003623 | MSE out: 0.033400 | GP NLL: -0.0000 | Gap(T-V): -0.001534 | Gap(V-O): 0.029777 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.563 | Time: 1.8s\n",
            "Epoch  195/500 | MSE train: 0.002085 | MSE val: 0.003621 | MSE out: 0.033277 | GP NLL: -0.0000 | Gap(T-V): -0.001536 | Gap(V-O): 0.029656 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.565 | Time: 1.8s\n",
            "Epoch  200/500 | MSE train: 0.002081 | MSE val: 0.003619 | MSE out: 0.033245 | GP NLL: -0.0001 | Gap(T-V): -0.001538 | Gap(V-O): 0.029626 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.568 | Time: 1.8s\n",
            "  ‚úì Checkpoint saved at epoch 200\n",
            "Epoch  205/500 | MSE train: 0.002077 | MSE val: 0.003618 | MSE out: 0.033167 | GP NLL: -0.0001 | Gap(T-V): -0.001541 | Gap(V-O): 0.029548 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.571 | Time: 1.9s\n",
            "Epoch  210/500 | MSE train: 0.002073 | MSE val: 0.003617 | MSE out: 0.033006 | GP NLL: -0.0001 | Gap(T-V): -0.001544 | Gap(V-O): 0.029390 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.574 | Time: 1.8s\n",
            "Epoch  215/500 | MSE train: 0.002069 | MSE val: 0.003615 | MSE out: 0.032982 | GP NLL: -0.0001 | Gap(T-V): -0.001546 | Gap(V-O): 0.029367 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.577 | Time: 1.9s\n",
            "Epoch  220/500 | MSE train: 0.002066 | MSE val: 0.003614 | MSE out: 0.032831 | GP NLL: -0.0001 | Gap(T-V): -0.001548 | Gap(V-O): 0.029217 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.580 | Time: 1.8s\n",
            "Epoch  225/500 | MSE train: 0.002063 | MSE val: 0.003613 | MSE out: 0.032758 | GP NLL: -0.0001 | Gap(T-V): -0.001550 | Gap(V-O): 0.029145 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.582 | Time: 1.8s\n",
            "Epoch  230/500 | MSE train: 0.002060 | MSE val: 0.003612 | MSE out: 0.032684 | GP NLL: -0.0001 | Gap(T-V): -0.001553 | Gap(V-O): 0.029071 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.585 | Time: 1.8s\n",
            "Epoch  235/500 | MSE train: 0.002057 | MSE val: 0.003612 | MSE out: 0.032579 | GP NLL: -0.0001 | Gap(T-V): -0.001555 | Gap(V-O): 0.028967 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.588 | Time: 1.9s\n",
            "Epoch  240/500 | MSE train: 0.002054 | MSE val: 0.003611 | MSE out: 0.032471 | GP NLL: -0.0002 | Gap(T-V): -0.001557 | Gap(V-O): 0.028860 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.591 | Time: 1.8s\n",
            "Epoch  245/500 | MSE train: 0.002051 | MSE val: 0.003611 | MSE out: 0.032381 | GP NLL: -0.0002 | Gap(T-V): -0.001559 | Gap(V-O): 0.028770 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.593 | Time: 1.8s\n",
            "Epoch  250/500 | MSE train: 0.002049 | MSE val: 0.003610 | MSE out: 0.032317 | GP NLL: -0.0002 | Gap(T-V): -0.001561 | Gap(V-O): 0.028707 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.596 | Time: 1.8s\n",
            "Epoch  255/500 | MSE train: 0.002046 | MSE val: 0.003608 | MSE out: 0.032209 | GP NLL: -0.0002 | Gap(T-V): -0.001562 | Gap(V-O): 0.028601 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.599 | Time: 1.9s\n",
            "Epoch  260/500 | MSE train: 0.002044 | MSE val: 0.003608 | MSE out: 0.032109 | GP NLL: -0.0002 | Gap(T-V): -0.001564 | Gap(V-O): 0.028501 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.601 | Time: 1.8s\n",
            "Epoch  265/500 | MSE train: 0.002041 | MSE val: 0.003608 | MSE out: 0.032004 | GP NLL: -0.0002 | Gap(T-V): -0.001567 | Gap(V-O): 0.028396 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.604 | Time: 1.8s\n",
            "Epoch  270/500 | MSE train: 0.002039 | MSE val: 0.003608 | MSE out: 0.031897 | GP NLL: -0.0002 | Gap(T-V): -0.001568 | Gap(V-O): 0.028289 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.607 | Time: 1.9s\n",
            "Epoch  275/500 | MSE train: 0.002037 | MSE val: 0.003607 | MSE out: 0.031760 | GP NLL: -0.0002 | Gap(T-V): -0.001570 | Gap(V-O): 0.028152 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.609 | Time: 1.9s\n",
            "Epoch  280/500 | MSE train: 0.002035 | MSE val: 0.003607 | MSE out: 0.031785 | GP NLL: -0.0002 | Gap(T-V): -0.001572 | Gap(V-O): 0.028178 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.612 | Time: 1.9s\n",
            "Epoch  285/500 | MSE train: 0.002033 | MSE val: 0.003607 | MSE out: 0.031657 | GP NLL: -0.0002 | Gap(T-V): -0.001574 | Gap(V-O): 0.028050 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.615 | Time: 1.8s\n",
            "Epoch  290/500 | MSE train: 0.002031 | MSE val: 0.003606 | MSE out: 0.031620 | GP NLL: -0.0003 | Gap(T-V): -0.001575 | Gap(V-O): 0.028014 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.617 | Time: 1.8s\n",
            "Epoch  295/500 | MSE train: 0.002029 | MSE val: 0.003606 | MSE out: 0.031481 | GP NLL: -0.0003 | Gap(T-V): -0.001577 | Gap(V-O): 0.027875 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.620 | Time: 1.9s\n",
            "Epoch  300/500 | MSE train: 0.002030 | MSE val: 0.003609 | MSE out: 0.031379 | GP NLL: -0.0003 | Gap(T-V): -0.001579 | Gap(V-O): 0.027770 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.622 | Time: 1.8s\n",
            "  ‚úì Checkpoint saved at epoch 300\n",
            "Epoch  305/500 | MSE train: 0.002046 | MSE val: 0.003622 | MSE out: 0.031285 | GP NLL: -0.0003 | Gap(T-V): -0.001577 | Gap(V-O): 0.027663 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.625 | Time: 1.8s\n",
            "Epoch  310/500 | MSE train: 0.002073 | MSE val: 0.003653 | MSE out: 0.031245 | GP NLL: -0.0003 | Gap(T-V): -0.001580 | Gap(V-O): 0.027592 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.627 | Time: 1.9s\n",
            "Epoch  315/500 | MSE train: 0.002023 | MSE val: 0.003605 | MSE out: 0.031138 | GP NLL: -0.0003 | Gap(T-V): -0.001583 | Gap(V-O): 0.027532 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.630 | Time: 1.9s\n",
            "Epoch  320/500 | MSE train: 0.002042 | MSE val: 0.003624 | MSE out: 0.031038 | GP NLL: -0.0003 | Gap(T-V): -0.001582 | Gap(V-O): 0.027414 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.632 | Time: 1.8s\n",
            "Epoch  325/500 | MSE train: 0.002022 | MSE val: 0.003610 | MSE out: 0.031042 | GP NLL: -0.0003 | Gap(T-V): -0.001588 | Gap(V-O): 0.027432 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.634 | Time: 1.9s\n",
            "Epoch  330/500 | MSE train: 0.002022 | MSE val: 0.003612 | MSE out: 0.030954 | GP NLL: -0.0003 | Gap(T-V): -0.001590 | Gap(V-O): 0.027343 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.637 | Time: 1.8s\n",
            "Epoch  335/500 | MSE train: 0.002025 | MSE val: 0.003613 | MSE out: 0.030810 | GP NLL: -0.0003 | Gap(T-V): -0.001588 | Gap(V-O): 0.027197 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.639 | Time: 1.8s\n",
            "Epoch  340/500 | MSE train: 0.002020 | MSE val: 0.003612 | MSE out: 0.030781 | GP NLL: -0.0003 | Gap(T-V): -0.001592 | Gap(V-O): 0.027168 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.642 | Time: 1.8s\n",
            "Epoch  345/500 | MSE train: 0.002018 | MSE val: 0.003610 | MSE out: 0.030702 | GP NLL: -0.0004 | Gap(T-V): -0.001591 | Gap(V-O): 0.027093 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.644 | Time: 1.9s\n",
            "Epoch  350/500 | MSE train: 0.002029 | MSE val: 0.003624 | MSE out: 0.030617 | GP NLL: -0.0004 | Gap(T-V): -0.001595 | Gap(V-O): 0.026993 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.646 | Time: 1.9s\n",
            "Epoch  355/500 | MSE train: 0.002071 | MSE val: 0.003658 | MSE out: 0.030421 | GP NLL: -0.0004 | Gap(T-V): -0.001587 | Gap(V-O): 0.026763 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.649 | Time: 1.9s\n",
            "Epoch  360/500 | MSE train: 0.002029 | MSE val: 0.003626 | MSE out: 0.030497 | GP NLL: -0.0004 | Gap(T-V): -0.001597 | Gap(V-O): 0.026871 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.651 | Time: 1.8s\n",
            "Epoch  365/500 | MSE train: 0.002027 | MSE val: 0.003627 | MSE out: 0.030316 | GP NLL: -0.0004 | Gap(T-V): -0.001600 | Gap(V-O): 0.026689 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.653 | Time: 1.9s\n",
            "Epoch  370/500 | MSE train: 0.002023 | MSE val: 0.003620 | MSE out: 0.030309 | GP NLL: -0.0004 | Gap(T-V): -0.001597 | Gap(V-O): 0.026688 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.655 | Time: 1.8s\n",
            "Epoch  375/500 | MSE train: 0.002009 | MSE val: 0.003611 | MSE out: 0.030293 | GP NLL: -0.0004 | Gap(T-V): -0.001601 | Gap(V-O): 0.026683 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.658 | Time: 1.8s\n",
            "Epoch  380/500 | MSE train: 0.002019 | MSE val: 0.003623 | MSE out: 0.030199 | GP NLL: -0.0004 | Gap(T-V): -0.001604 | Gap(V-O): 0.026576 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.660 | Time: 1.9s\n",
            "Epoch  385/500 | MSE train: 0.002008 | MSE val: 0.003610 | MSE out: 0.030145 | GP NLL: -0.0004 | Gap(T-V): -0.001602 | Gap(V-O): 0.026535 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.662 | Time: 1.8s\n",
            "Epoch  390/500 | MSE train: 0.002003 | MSE val: 0.003608 | MSE out: 0.030038 | GP NLL: -0.0004 | Gap(T-V): -0.001605 | Gap(V-O): 0.026430 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.664 | Time: 1.8s\n",
            "Epoch  395/500 | MSE train: 0.002017 | MSE val: 0.003624 | MSE out: 0.030054 | GP NLL: -0.0004 | Gap(T-V): -0.001607 | Gap(V-O): 0.026430 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.666 | Time: 1.8s\n",
            "Epoch  400/500 | MSE train: 0.002061 | MSE val: 0.003660 | MSE out: 0.029905 | GP NLL: -0.0004 | Gap(T-V): -0.001599 | Gap(V-O): 0.026245 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.668 | Time: 1.9s\n",
            "  ‚úì Checkpoint saved at epoch 400\n",
            "Epoch  405/500 | MSE train: 0.002032 | MSE val: 0.003640 | MSE out: 0.029859 | GP NLL: -0.0004 | Gap(T-V): -0.001608 | Gap(V-O): 0.026219 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.671 | Time: 1.8s\n",
            "Epoch  410/500 | MSE train: 0.002014 | MSE val: 0.003626 | MSE out: 0.029834 | GP NLL: -0.0004 | Gap(T-V): -0.001612 | Gap(V-O): 0.026208 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.673 | Time: 1.8s\n",
            "Epoch  415/500 | MSE train: 0.002020 | MSE val: 0.003631 | MSE out: 0.029709 | GP NLL: -0.0004 | Gap(T-V): -0.001610 | Gap(V-O): 0.026078 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.675 | Time: 1.8s\n",
            "Epoch  420/500 | MSE train: 0.001995 | MSE val: 0.003610 | MSE out: 0.029681 | GP NLL: -0.0005 | Gap(T-V): -0.001615 | Gap(V-O): 0.026071 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.677 | Time: 1.8s\n",
            "Epoch  425/500 | MSE train: 0.002010 | MSE val: 0.003625 | MSE out: 0.029645 | GP NLL: -0.0005 | Gap(T-V): -0.001615 | Gap(V-O): 0.026020 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.679 | Time: 1.9s\n",
            "Epoch  430/500 | MSE train: 0.002031 | MSE val: 0.003640 | MSE out: 0.029684 | GP NLL: -0.0005 | Gap(T-V): -0.001609 | Gap(V-O): 0.026043 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.681 | Time: 1.8s\n",
            "Epoch  435/500 | MSE train: 0.002040 | MSE val: 0.003654 | MSE out: 0.029562 | GP NLL: -0.0005 | Gap(T-V): -0.001614 | Gap(V-O): 0.025908 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.683 | Time: 1.8s\n",
            "Epoch  440/500 | MSE train: 0.001999 | MSE val: 0.003619 | MSE out: 0.029540 | GP NLL: -0.0005 | Gap(T-V): -0.001619 | Gap(V-O): 0.025922 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.685 | Time: 1.9s\n",
            "Epoch  445/500 | MSE train: 0.001996 | MSE val: 0.003615 | MSE out: 0.029442 | GP NLL: -0.0005 | Gap(T-V): -0.001619 | Gap(V-O): 0.025827 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.687 | Time: 1.8s\n",
            "Epoch  450/500 | MSE train: 0.002030 | MSE val: 0.003651 | MSE out: 0.029480 | GP NLL: -0.0005 | Gap(T-V): -0.001621 | Gap(V-O): 0.025829 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.689 | Time: 1.8s\n",
            "Epoch  455/500 | MSE train: 0.002074 | MSE val: 0.003684 | MSE out: 0.029375 | GP NLL: -0.0005 | Gap(T-V): -0.001610 | Gap(V-O): 0.025691 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.691 | Time: 1.8s\n",
            "Epoch  460/500 | MSE train: 0.001996 | MSE val: 0.003617 | MSE out: 0.029275 | GP NLL: -0.0005 | Gap(T-V): -0.001621 | Gap(V-O): 0.025659 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.692 | Time: 1.8s\n",
            "Epoch  465/500 | MSE train: 0.002026 | MSE val: 0.003651 | MSE out: 0.029339 | GP NLL: -0.0005 | Gap(T-V): -0.001625 | Gap(V-O): 0.025688 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.694 | Time: 1.8s\n",
            "Epoch  470/500 | MSE train: 0.001985 | MSE val: 0.003610 | MSE out: 0.029204 | GP NLL: -0.0005 | Gap(T-V): -0.001625 | Gap(V-O): 0.025594 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.696 | Time: 1.8s\n",
            "Epoch  475/500 | MSE train: 0.002004 | MSE val: 0.003628 | MSE out: 0.029188 | GP NLL: -0.0005 | Gap(T-V): -0.001624 | Gap(V-O): 0.025560 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.698 | Time: 1.8s\n",
            "Epoch  480/500 | MSE train: 0.001990 | MSE val: 0.003618 | MSE out: 0.029149 | GP NLL: -0.0005 | Gap(T-V): -0.001628 | Gap(V-O): 0.025531 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.700 | Time: 1.8s\n",
            "Epoch  485/500 | MSE train: 0.001997 | MSE val: 0.003625 | MSE out: 0.029002 | GP NLL: -0.0005 | Gap(T-V): -0.001628 | Gap(V-O): 0.025377 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.702 | Time: 1.8s\n",
            "Epoch  490/500 | MSE train: 0.002009 | MSE val: 0.003638 | MSE out: 0.029184 | GP NLL: -0.0005 | Gap(T-V): -0.001629 | Gap(V-O): 0.025546 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.703 | Time: 1.8s\n",
            "Epoch  495/500 | MSE train: 0.001994 | MSE val: 0.003627 | MSE out: 0.028996 | GP NLL: -0.0006 | Gap(T-V): -0.001632 | Gap(V-O): 0.025369 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.705 | Time: 1.8s\n",
            "Epoch  499/500 | MSE train: 0.002020 | MSE val: 0.003648 | MSE out: 0.029011 | GP NLL: -0.0006 | Gap(T-V): -0.001627 | Gap(V-O): 0.025364 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.706 | Time: 1.8s\n",
            "  ‚úì Checkpoint saved at epoch 499\n",
            "\n",
            "================================================================================\n",
            "‚úÖ GP-VAE Interpolation Experiment training complete!\n",
            "   Total time: 15.5 minutes (0.26 hours)\n",
            "   Average time per epoch: 1.9 seconds\n",
            "   Final training MSE: 0.002020\n",
            "   Final validation MSE: 0.003648\n",
            "   Final out-of-sample MSE: 0.029011\n",
            "   Final GP NLL: -0.0006\n",
            "\n",
            "üî¨ Final Diagnostics:\n",
            "   Train-Val Gap: -0.001627 (lower = less overfitting)\n",
            "   Val-Out Gap: 0.025364 (CRITICAL for interpolation quality)\n",
            "   Variance Ratio: 0.706 (higher = more structure learned)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>diagnostics/gap_train_val</td><td>‚ñÇ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>diagnostics/gap_val_out</td><td>‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>diagnostics/variance_ratio</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà</td></tr><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>gp_nll</td><td>‚ñà‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>loss</td><td>‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>mse_out</td><td>‚ñà‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>mse_out_per_view/45L</td><td>‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>mse_out_per_view/45R</td><td>‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>mse_train</td><td>‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>+8</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>diagnostics/gap_train_val</td><td>-0.00163</td></tr><tr><td>diagnostics/gap_val_out</td><td>0.02536</td></tr><tr><td>diagnostics/variance_ratio</td><td>0.70644</td></tr><tr><td>epoch</td><td>499</td></tr><tr><td>gp_nll</td><td>-0.00056</td></tr><tr><td>loss</td><td>-2.60281</td></tr><tr><td>mse_out</td><td>0.02901</td></tr><tr><td>mse_out_per_view/45L</td><td>0.02869</td></tr><tr><td>mse_out_per_view/45R</td><td>0.02934</td></tr><tr><td>mse_train</td><td>0.00202</td></tr><tr><td>+9</td><td>...</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">interpolation_spectral_mixture_20260116_194111</strong> at: <a href='https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae/runs/953yh8yg' target=\"_blank\">https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae/runs/953yh8yg</a><br> View project at: <a href='https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae' target=\"_blank\">https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae</a><br>Synced 5 W&B file(s), 12 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>/content/wandb/run-20260116_194117-953yh8yg/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîó View detailed results in W&B dashboard\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "history = {}\n",
        "start_time = time.time()\n",
        "\n",
        "print(f\"üöÄ Starting GP-VAE Interpolation Experiment training for {CONFIG['epochs']} epochs...\")\n",
        "print(\"=\" * 80)\n",
        "print(\"Training mode: JOINT OPTIMIZATION (VAE + GP updated together)\")\n",
        "print(f\"Experiment: Interpolation (boundaries ‚Üí intermediate)\")\n",
        "print(f\"  Training views: {CONFIG.get('train_view_indices', 'all')}\")\n",
        "print(f\"  Validation views: {CONFIG.get('val_view_indices', 'all')}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for epoch in range(CONFIG['epochs']):\n",
        "    epoch_start = time.time()\n",
        "\n",
        "    # 1. Encode all training images\n",
        "    Zm, Zs = encode_Y(vae, train_queue)\n",
        "\n",
        "    # 2. Sample latent codes\n",
        "    Eps = Variable(torch.randn(*Zs.shape), requires_grad=False).cuda()\n",
        "    Z = Zm + Eps * Zs\n",
        "\n",
        "    # 3. Compute variance matrices\n",
        "    Vt = vm(Dt, Wt).detach()\n",
        "    Vv = vm(Dv, Wv).detach()\n",
        "\n",
        "    # 4. Evaluate on validation set (with per-view metrics)\n",
        "    rv_eval, imgs, covs = eval_step(vae, gp, vm, val_queue, Zm, Vt, Vv, Wv, use_angle_encoding=use_angle_encoding)\n",
        "\n",
        "    # 5. Compute GP Taylor expansion coefficients\n",
        "    Zb, Vbs, vbs, gp_nll = gp.taylor_coeff(Z, [Vt])\n",
        "    rv_eval[\"gp_nll\"] = float(gp_nll.data.mean().cpu()) / vae.K\n",
        "\n",
        "    # 6. Joint training step (VAE + GP)\n",
        "    rv_back = backprop_and_update(\n",
        "        vae, gp, vm, train_queue, Dt, Wt, Eps,\n",
        "        Zb, Vbs, vbs, vae_optimizer, gp_optimizer\n",
        "    )\n",
        "    rv_back[\"loss\"] = rv_back[\"recon_term\"] + rv_eval[\"gp_nll\"] + rv_back[\"pen_term\"]\n",
        "\n",
        "    # Store history\n",
        "    smartAppendDict(history, rv_eval)\n",
        "    smartAppendDict(history, rv_back)\n",
        "    smartAppend(history, \"vs\", gp.get_vs().data.cpu().numpy())\n",
        "\n",
        "    epoch_time = time.time() - epoch_start\n",
        "    total_time = time.time() - start_time\n",
        "\n",
        "    # üî¨ Compute diagnostic metrics\n",
        "    train_val_gap = rv_back[\"mse\"] - rv_eval[\"mse_val\"]\n",
        "    val_out_gap = rv_eval[\"mse_out\"] - rv_eval[\"mse_val\"]\n",
        "\n",
        "    vs = gp.get_vs().data.cpu().numpy()\n",
        "    variance_ratio = vs[0] / (vs[0] + vs[1])\n",
        "\n",
        "    # Check if kernel has learnable lengthscale\n",
        "    learned_lengthscale = None\n",
        "    if hasattr(vm, 'view_kernel') and hasattr(vm.view_kernel, 'log_lengthscale'):\n",
        "        learned_lengthscale = torch.exp(vm.view_kernel.log_lengthscale).item()\n",
        "\n",
        "    # Print progress\n",
        "    if epoch % 5 == 0 or epoch == CONFIG['epochs'] - 1:\n",
        "        print(f\"Epoch {epoch:4d}/{CONFIG['epochs']} | \"\n",
        "              f\"MSE train: {rv_back['mse']:.6f} | \"\n",
        "              f\"MSE val: {rv_eval['mse_val']:.6f} | \"\n",
        "              f\"MSE out: {rv_eval['mse_out']:.6f} | \"\n",
        "              f\"GP NLL: {rv_eval['gp_nll']:.4f} | \"\n",
        "              f\"Gap(T-V): {train_val_gap:.6f} | \"\n",
        "              f\"Gap(V-O): {val_out_gap:.6f} | \"\n",
        "              f\"v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): {variance_ratio:.3f}\" +\n",
        "              (f\" | ‚Ñì: {learned_lengthscale:.3f}\" if learned_lengthscale else \"\") +\n",
        "              f\" | Time: {epoch_time:.1f}s\")\n",
        "\n",
        "        # Print per-view breakdown (Interpolation specific)\n",
        "        if CONFIG['view_split_mode'] == 'by_view' and epoch % 10 == 0:\n",
        "            if 'mse_out_per_view' in rv_eval and rv_eval['mse_out_per_view']:\n",
        "                print(\"   Per-view MSE_out (intermediate views):\")\n",
        "                # Map view indices to names\n",
        "                view_names = {0: \"90L\", 1: \"60L\", 2: \"45L\", 3: \"30L\", 4: \"00F\",\n",
        "                             5: \"30R\", 6: \"45R\", 7: \"60R\", 8: \"90R\"}\n",
        "                for view_idx in sorted(rv_eval['mse_out_per_view'].keys()):\n",
        "                    mse = rv_eval['mse_out_per_view'][view_idx]\n",
        "                    view_name = view_names.get(view_idx, f\"V{view_idx}\")\n",
        "                    print(f\"      {view_name}: {mse:.6f}\")\n",
        "\n",
        "    # Log to W&B\n",
        "    if CONFIG['use_wandb']:\n",
        "        log_dict = {\n",
        "            \"epoch\": epoch,\n",
        "            \"mse_train\": rv_back[\"mse\"],\n",
        "            \"mse_val\": rv_eval[\"mse_val\"],\n",
        "            \"mse_out\": rv_eval[\"mse_out\"],\n",
        "            \"gp_nll\": rv_eval[\"gp_nll\"],\n",
        "            \"recon_term\": rv_back[\"recon_term\"],\n",
        "            \"pen_term\": rv_back[\"pen_term\"],\n",
        "            \"loss\": rv_back[\"loss\"],\n",
        "            \"vars\": rv_eval[\"vars\"],\n",
        "            \"time/epoch_seconds\": epoch_time,\n",
        "            # üî¨ Diagnostic metrics\n",
        "            \"diagnostics/gap_train_val\": train_val_gap,\n",
        "            \"diagnostics/gap_val_out\": val_out_gap,\n",
        "            \"diagnostics/variance_ratio\": variance_ratio,\n",
        "            \"vars/v0_object\": vs[0],\n",
        "            \"vars/v1_noise\": vs[1],\n",
        "        }\n",
        "\n",
        "        # Add lengthscale if available\n",
        "        if learned_lengthscale is not None:\n",
        "            log_dict[\"kernel/lengthscale\"] = learned_lengthscale\n",
        "\n",
        "        # Add per-view metrics (Interpolation specific)\n",
        "        if 'mse_val_per_view' in rv_eval:\n",
        "            view_names = {0: \"90L\", 1: \"60L\", 2: \"45L\", 3: \"30L\", 4: \"00F\",\n",
        "                         5: \"30R\", 6: \"45R\", 7: \"60R\", 8: \"90R\"}\n",
        "            for view_idx, mse in rv_eval['mse_val_per_view'].items():\n",
        "                view_name = view_names.get(view_idx, f\"V{view_idx}\")\n",
        "                log_dict[f\"mse_val_per_view/{view_name}\"] = mse\n",
        "\n",
        "        if 'mse_out_per_view' in rv_eval:\n",
        "            view_names = {0: \"90L\", 1: \"60L\", 2: \"45L\", 3: \"30L\", 4: \"00F\",\n",
        "                         5: \"30R\", 6: \"45R\", 7: \"60R\", 8: \"90R\"}\n",
        "            for view_idx, mse in rv_eval['mse_out_per_view'].items():\n",
        "                view_name = view_names.get(view_idx, f\"V{view_idx}\")\n",
        "                log_dict[f\"mse_out_per_view/{view_name}\"] = mse\n",
        "\n",
        "        wandb.log(log_dict)\n",
        "\n",
        "    # Save checkpoint\n",
        "    if epoch % CONFIG['epoch_cb'] == 0 or epoch == CONFIG['epochs'] - 1:\n",
        "        logging.info(f\"Epoch {epoch} - saving checkpoint\")\n",
        "\n",
        "        # Save VAE weights\n",
        "        vae_file = os.path.join(wdir, f\"vae_weights.{epoch:05d}.pt\")\n",
        "        torch.save(vae.state_dict(), vae_file)\n",
        "\n",
        "        # Save GP weights\n",
        "        gp_file = os.path.join(wdir, f\"gp_weights.{epoch:05d}.pt\")\n",
        "        torch.save({\n",
        "            'gp_state': gp.state_dict(),\n",
        "            'vm_state': vm.state_dict(),\n",
        "            'gp_params': gp_params.state_dict(),\n",
        "        }, gp_file)\n",
        "\n",
        "        # Save visualization\n",
        "        ffile = os.path.join(fdir, f\"plot.{epoch:05d}.png\")\n",
        "        callback_gppvae(epoch, history, covs, imgs, ffile)\n",
        "\n",
        "        if CONFIG['use_wandb']:\n",
        "            wandb.log({\n",
        "                \"reconstructions\": wandb.Image(ffile),\n",
        "                \"covariances/XX\": wandb.Image(ffile),\n",
        "            })\n",
        "\n",
        "        print(f\"  ‚úì Checkpoint saved at epoch {epoch}\")\n",
        "\n",
        "# At the end, enhanced summary with per-view breakdown\n",
        "total_time = time.time() - start_time\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(f\"‚úÖ GP-VAE Interpolation Experiment training complete!\")\n",
        "print(f\"   Total time: {total_time/60:.1f} minutes ({total_time/3600:.2f} hours)\")\n",
        "print(f\"   Average time per epoch: {total_time/CONFIG['epochs']:.1f} seconds\")\n",
        "print(f\"   Final training MSE: {rv_back['mse']:.6f}\")\n",
        "print(f\"   Final validation MSE: {rv_eval['mse_val']:.6f}\")\n",
        "print(f\"   Final out-of-sample MSE: {rv_eval['mse_out']:.6f}\")\n",
        "print(f\"   Final GP NLL: {rv_eval['gp_nll']:.4f}\")\n",
        "\n",
        "print(f\"\\nüî¨ Final Diagnostics:\")\n",
        "print(f\"   Train-Val Gap: {train_val_gap:.6f} (lower = less overfitting)\")\n",
        "print(f\"   Val-Out Gap: {val_out_gap:.6f} (CRITICAL for interpolation quality)\")\n",
        "print(f\"   Variance Ratio: {variance_ratio:.3f} (higher = more structure learned)\")\n",
        "if learned_lengthscale is not None:\n",
        "    print(f\"   Learned Lengthscale: {learned_lengthscale:.3f}\")\n",
        "\n",
        "# Interpolation specific: Per-view breakdown\n",
        "if CONFIG['view_split_mode'] == 'by_view' and 'mse_out_per_view' in rv_eval:\n",
        "    print(f\"\\nüìä Final Per-View MSE_out (Interpolation Test):\")\n",
        "\n",
        "    view_names = {0: \"90L (-90¬∞)\", 1: \"60L (-60¬∞)\", 2: \"45L (-45¬∞)\", 3: \"30L (-30¬∞)\",\n",
        "                 4: \"00F (0¬∞)\", 5: \"30R (+30¬∞)\", 6: \"45R (+45¬∞)\", 7: \"60R (+60¬∞)\", 8: \"90R (+90¬∞)\"}\n",
        "\n",
        "    # Separate training and validation views\n",
        "    train_view_indices = CONFIG.get('train_view_indices', [])\n",
        "    val_view_indices = CONFIG.get('val_view_indices', [])\n",
        "\n",
        "    if rv_eval['mse_out_per_view']:\n",
        "        print(\"   INTERMEDIATE VIEWS (held-out, interpolation targets):\")\n",
        "        interp_mses = []\n",
        "        for view_idx in sorted(rv_eval['mse_out_per_view'].keys()):\n",
        "            if view_idx in val_view_indices:\n",
        "                mse = rv_eval['mse_out_per_view'][view_idx]\n",
        "                interp_mses.append(mse)\n",
        "                view_name = view_names.get(view_idx, f\"V{view_idx}\")\n",
        "                print(f\"      {view_name:15s}: {mse:.6f}\")\n",
        "\n",
        "        if interp_mses:\n",
        "            avg_interp = np.mean(interp_mses)\n",
        "            print(f\"\\n   Average MSE on intermediate views: {avg_interp:.6f}\")\n",
        "            print(f\"   Overall MSE_out: {rv_eval['mse_out']:.6f}\")\n",
        "            print(f\"\\nüí° Lower MSE_out on intermediate views = better interpolation!\")\n",
        "\n",
        "if CONFIG['use_wandb']:\n",
        "    wandb.finish()\n",
        "    print(\"\\nüîó View detailed results in W&B dashboard\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a98f4bc",
      "metadata": {
        "id": "9a98f4bc"
      },
      "source": [
        "## 13. Download Results\n",
        "\n",
        "Download the trained model and visualizations to your computer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "337a096a",
      "metadata": {
        "id": "337a096a"
      },
      "outputs": [],
      "source": [
        "# Compress output folder\n",
        "output_zip = '/content/gppvae_output.zip'\n",
        "!zip -r {output_zip} {CONFIG['outdir']}\n",
        "\n",
        "# Download\n",
        "from google.colab import files\n",
        "print(\"Preparing download...\")\n",
        "files.download(output_zip)\n",
        "print(\"\\n‚úÖ Download started! Extract the zip on your local machine.\")\n",
        "print(f\"\\nContents include:\")\n",
        "print(f\"  - Trained VAE weights (fine-tuned)\")\n",
        "print(f\"  - GP + Vmodel weights\")\n",
        "print(f\"  - Visualization plots\")\n",
        "print(f\"  - Training logs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f397bbc",
      "metadata": {
        "id": "7f397bbc"
      },
      "source": [
        "## 14. Visualize Results\n",
        "\n",
        "View the latest reconstruction and covariance plots:"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}