{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f8a173e",
   "metadata": {
    "id": "0f8a173e"
   },
   "source": [
    "# GP-VAE Training on Google Colab\n",
    "\n",
    "This notebook trains the **GP-VAE (Gaussian Process Variational Autoencoder)** model using Google Colab's free GPU.\n",
    "\n",
    "## What is GP-VAE?\n",
    "GP-VAE adds a **Gaussian Process prior** to the VAE latent space to model structured correlations:\n",
    "- **VAE**: Learns image ‚Üî latent code mapping\n",
    "- **GP Prior**: Models correlations between latent codes based on:\n",
    "  - Object identity (same person's face)\n",
    "  - View angle (front, side, profile)\n",
    "  - Other factors of variation\n",
    "\n",
    "## Prerequisites ‚ö†Ô∏è\n",
    "**You MUST have trained VAE weights first!** This model loads pre-trained VAE and fine-tunes it jointly with the GP.\n",
    "\n",
    "Required files:\n",
    "- ‚úÖ `out/vae_colab/YYYYMMDD_HHMMSS/vae.cfg.p` - VAE configuration\n",
    "- ‚úÖ `out/vae_colab/YYYYMMDD_HHMMSS/weights/weights.00000.pt` - Trained VAE weights\n",
    "\n",
    "## Output Directory Structure:\n",
    "\n",
    "Each training run creates a **timestamped directory** to avoid overwriting previous runs:\n",
    "- Format: `./out/gppvae_colab/YYYYMMDD_HHMMSS/`\n",
    "- Example: `./out/gppvae_colab/20251224_143530/weights/weights.00100.pt`\n",
    "- This allows you to compare different training runs and keep a history!\n",
    "\n",
    "Cell 6 below will automatically find your latest VAE training run.\n",
    "\n",
    "## Setup Instructions:\n",
    "\n",
    "1. **Open this notebook in VS Code**\n",
    "2. **Connect to Colab**: Click kernel picker ‚Üí \"Connect to Colab\" ‚Üí Choose **GPU runtime (T4)**\n",
    "3. **Important**: When prompted with \"Alias your server\", press Enter\n",
    "4. **Run cell 2** - it will automatically detect your project location\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d4d88e",
   "metadata": {
    "id": "a7d4d88e"
   },
   "source": [
    "## 1. Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9450aba9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9450aba9",
    "outputId": "45a03af5-8d1c-4a6b-f77a-f20455bbcffd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.0+cu126\n",
      "CUDA available: True\n",
      "GPU Device: NVIDIA A100-SXM4-40GB\n",
      "GPU Memory: 42.47 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è WARNING: GPU not detected! Go to Runtime ‚Üí Change runtime type ‚Üí GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a792140f",
   "metadata": {
    "id": "a792140f"
   },
   "source": [
    "## 2. Auto-Detect Project Path\n",
    "\n",
    "This automatically finds your project files on the Colab runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33fa06a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33fa06a0",
    "outputId": "972a9868-bd7b-4614-eaf8-29e5c3a9e8ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìç Current directory: /content/drive/MyDrive/gppvae\n",
      "üíª Using project path: /content/drive/MyDrive/gppvae\n",
      "\n",
      "üìÅ Contents of /content/drive/MyDrive/gppvae:\n",
      "   üìÇ GPPVAE/\n",
      "   üìÇ data/\n",
      "   üìÑ environment.yml\n",
      "   üìÇ notebooks/\n",
      "   üìÇ out/\n",
      "\n",
      "üîç Checking required files:\n",
      "   ‚úÖ GPPVAE code\n",
      "   ‚úÖ data/faceplace\n",
      "   ‚úÖ data_faces.h5\n",
      "   ‚úÖ VAE config\n",
      "   ‚úÖ VAE weights\n",
      "\n",
      "üì¶ Found 3 VAE training run(s):\n",
      "   1. 20251224_171841/ (11 checkpoints)\n",
      "      Latest: weights.00099.pt\n",
      "   2. 20251224_171753/ (0 checkpoints)\n",
      "   3. 20251224_120136/ (16 checkpoints)\n",
      "      Latest: weights.00140.pt\n",
      "\n",
      "üí° Cell 6 below will help you choose which run to use\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Get current directory\n",
    "current_dir = os.getcwd()\n",
    "print(f\"üìç Current directory: {current_dir}\")\n",
    "\n",
    "# Check if on Colab and need to mount Drive\n",
    "if current_dir == '/content':\n",
    "    print(\"\\nüîÑ Mounting Google Drive...\")\n",
    "\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "\n",
    "        # Check for project in Drive\n",
    "        drive_path = '/content/drive/MyDrive/gppvae'\n",
    "        if os.path.exists(drive_path):\n",
    "            PROJECT_PATH = drive_path\n",
    "            print(f\"‚úÖ Found project in Google Drive: {PROJECT_PATH}\")\n",
    "        else:\n",
    "            print(f\"\\n‚ö†Ô∏è  Project not found at: {drive_path}\")\n",
    "            print(\"\\nPlease upload your gppvae folder to Google Drive!\")\n",
    "            print(\"Required structure:\")\n",
    "            print(\"  MyDrive/gppvae/\")\n",
    "            print(\"    ‚îú‚îÄ‚îÄ GPPVAE/\")\n",
    "            print(\"    ‚îú‚îÄ‚îÄ data/faceplace/data_faces.h5\")\n",
    "            print(\"    ‚îî‚îÄ‚îÄ out/vae_colab/YYYYMMDD_HHMMSS/\")\n",
    "            print(\"        ‚îú‚îÄ‚îÄ vae.cfg.p\")\n",
    "            print(\"        ‚îî‚îÄ‚îÄ weights/weights.00000.pt\")\n",
    "            PROJECT_PATH = '/content'\n",
    "    except Exception as e:\n",
    "        print(f\"Could not mount Drive: {e}\")\n",
    "        PROJECT_PATH = '/content'\n",
    "else:\n",
    "    # Running via VS Code sync\n",
    "    if 'notebooks' in current_dir:\n",
    "        PROJECT_PATH = os.path.dirname(current_dir)\n",
    "    else:\n",
    "        PROJECT_PATH = current_dir\n",
    "    print(f\"üíª Using project path: {PROJECT_PATH}\")\n",
    "\n",
    "# Verify structure\n",
    "print(f\"\\nüìÅ Contents of {PROJECT_PATH}:\")\n",
    "if os.path.exists(PROJECT_PATH):\n",
    "    items = os.listdir(PROJECT_PATH)\n",
    "    for item in sorted(items)[:15]:\n",
    "        item_path = os.path.join(PROJECT_PATH, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            print(f\"   üìÇ {item}/\")\n",
    "        else:\n",
    "            print(f\"   üìÑ {item}\")\n",
    "\n",
    "    # Check required files (with timestamped directory structure)\n",
    "    print(f\"\\nüîç Checking required files:\")\n",
    "    required = {\n",
    "        'GPPVAE code': os.path.exists(os.path.join(PROJECT_PATH, 'GPPVAE')),\n",
    "        'data/faceplace': os.path.exists(os.path.join(PROJECT_PATH, 'data/faceplace')),\n",
    "        'data_faces.h5': os.path.exists(os.path.join(PROJECT_PATH, 'data/faceplace/data_faces.h5')),\n",
    "    }\n",
    "\n",
    "    # Check for VAE runs (timestamped subdirectories)\n",
    "    vae_base_dir = os.path.join(PROJECT_PATH, 'out/vae_colab')\n",
    "    vae_run_found = False\n",
    "    vae_weights_found = False\n",
    "\n",
    "    if os.path.exists(vae_base_dir):\n",
    "        # Look for timestamped subdirectories\n",
    "        potential_runs = [d for d in os.listdir(vae_base_dir)\n",
    "                         if os.path.isdir(os.path.join(vae_base_dir, d)) and d[0].isdigit()]\n",
    "\n",
    "        for run_dir in potential_runs:\n",
    "            run_path = os.path.join(vae_base_dir, run_dir)\n",
    "            cfg_path = os.path.join(run_path, 'vae.cfg.p')\n",
    "            weights_dir = os.path.join(run_path, 'weights')\n",
    "\n",
    "            if os.path.exists(cfg_path):\n",
    "                vae_run_found = True\n",
    "\n",
    "            if os.path.exists(weights_dir):\n",
    "                weight_files = [f for f in os.listdir(weights_dir) if f.endswith('.pt')]\n",
    "                if weight_files:\n",
    "                    vae_weights_found = True\n",
    "                    break\n",
    "\n",
    "    required['VAE config'] = vae_run_found\n",
    "    required['VAE weights'] = vae_weights_found\n",
    "\n",
    "    for name, exists in required.items():\n",
    "        status = \"‚úÖ\" if exists else \"‚ùå\"\n",
    "        print(f\"   {status} {name}\")\n",
    "\n",
    "    # Show VAE runs if they exist\n",
    "    if os.path.exists(vae_base_dir):\n",
    "        potential_runs = sorted([d for d in os.listdir(vae_base_dir)\n",
    "                                if os.path.isdir(os.path.join(vae_base_dir, d)) and d[0].isdigit()],\n",
    "                               reverse=True)\n",
    "\n",
    "        if potential_runs:\n",
    "            print(f\"\\nüì¶ Found {len(potential_runs)} VAE training run(s):\")\n",
    "            for i, run_dir in enumerate(potential_runs[:3], 1):  # Show latest 3\n",
    "                run_path = os.path.join(vae_base_dir, run_dir)\n",
    "                weights_dir = os.path.join(run_path, 'weights')\n",
    "\n",
    "                if os.path.exists(weights_dir):\n",
    "                    weight_files = sorted([f for f in os.listdir(weights_dir) if f.endswith('.pt')])\n",
    "                    print(f\"   {i}. {run_dir}/ ({len(weight_files)} checkpoints)\")\n",
    "                    if weight_files:\n",
    "                        print(f\"      Latest: {weight_files[-1]}\")\n",
    "\n",
    "            if len(potential_runs) > 3:\n",
    "                print(f\"   ... and {len(potential_runs) - 3} more\")\n",
    "\n",
    "            print(f\"\\nüí° Cell 6 below will help you choose which run to use\")\n",
    "\n",
    "    if not all(required.values()):\n",
    "        print(f\"\\n‚ö†Ô∏è  Missing required files!\")\n",
    "        if not required['VAE weights']:\n",
    "            print(\"\\nüö® CRITICAL: No trained VAE weights found!\")\n",
    "            print(\"   You must train VAE first before running GP-VAE\")\n",
    "            print(\"   Use the train_vae_colab.ipynb notebook\")\n",
    "else:\n",
    "    print(f\"‚ùå Path doesn't exist: {PROJECT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd61ed4d",
   "metadata": {
    "id": "dd61ed4d"
   },
   "source": [
    "## 3. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5eb3366a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5eb3366a",
    "outputId": "53e1dbb8-df75-4ff6-cbe6-6c6210191a6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m√ó\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m√ó\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "‚úÖ All dependencies installed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install -q wandb==0.12.21 imageio==2.15.0 pyyaml\n",
    "\n",
    "# Verify installations\n",
    "import wandb\n",
    "import imageio\n",
    "import yaml\n",
    "import numpy as np\n",
    "print(\"‚úÖ All dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428e2eb3",
   "metadata": {
    "id": "428e2eb3"
   },
   "source": [
    "## 4. Login to Weights & Biases (Optional)\n",
    "\n",
    "Track your experiments with W&B for better monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a116fb79",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a116fb79",
    "outputId": "bcf538de-f9b9-4ede-889c-3d06b7f6c8e9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "# Or run offline without W&B:\n",
    "# import os\n",
    "# os.environ['WANDB_MODE'] = 'offline'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064cf6ef",
   "metadata": {
    "id": "064cf6ef"
   },
   "source": [
    "## 5. Navigate to Project Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9ddd5a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9ddd5a1",
    "outputId": "df103d8f-bbc5-495f-8a08-5f8fa3d5c038"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /content/drive/MyDrive/gppvae\n",
      "\n",
      "Project structure:\n",
      "total 17\n",
      "drwx------ 3 root root 4096 Dec 23 14:09 data\n",
      "-rw------- 1 root root  258 Dec 23 11:40 environment.yml\n",
      "drwx------ 3 root root 4096 Dec 23 14:09 GPPVAE\n",
      "drwx------ 2 root root 4096 Dec 23 14:09 notebooks\n",
      "drwx------ 5 root root 4096 Dec 23 14:21 out\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir(PROJECT_PATH)\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "\n",
    "# Add to Python path\n",
    "sys.path.insert(0, os.path.join(PROJECT_PATH, 'GPPVAE/pysrc/faceplace'))\n",
    "\n",
    "print(\"\\nProject structure:\")\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638c36f7",
   "metadata": {
    "id": "638c36f7"
   },
   "source": [
    "## 6. Verify VAE Weights\n",
    "\n",
    "**Critical check:** Make sure you have trained VAE weights!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26a9a8de",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "26a9a8de",
    "outputId": "00dfc09e-8ca7-4699-a06f-5f8b20579741"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 4 VAE training run(s):\n",
      "\n",
      "Run 1: 20260103_192743\n",
      "   Config: zdim=256, nf=32\n",
      "   Checkpoints: 11 files\n",
      "      üì¶ weights.00000.pt ... weights.00499.pt\n",
      "\n",
      "Run 2: 20260103_191647\n",
      "   Config: zdim=256, nf=32\n",
      "   Checkpoints: 2 files\n",
      "      üì¶ weights.00000.pt\n",
      "      üì¶ weights.00050.pt\n",
      "\n",
      "Run 3: 20260103_190918\n",
      "   Config: zdim=256, nf=32\n",
      "   Checkpoints: 2 files\n",
      "      üì¶ weights.00000.pt\n",
      "      üì¶ weights.00050.pt\n",
      "\n",
      "Run 4: 20260103_184756\n",
      "   Config: zdim=256, nf=32\n",
      "   Checkpoints: 5 files\n",
      "      üì¶ weights.00000.pt ... weights.00200.pt\n",
      "\n",
      "üí° Recommendation:\n",
      "   Use latest run: 20260103_192743\n",
      "   Latest checkpoint: weights.00499.pt\n",
      "   \n",
      "   Set in next cell:\n",
      "   CONFIG['vae_cfg'] = './out/vae_colab_interpolation/20260103_192743/vae.cfg.p'\n",
      "   CONFIG['vae_weights'] = './out/vae_colab_interpolation/20260103_192743/weights/weights.00499.pt'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "# Check for VAE runs (may be in timestamped subdirectories)\n",
    "vae_base_dir = './out/vae_colab_interpolation'\n",
    "vae_runs = []\n",
    "\n",
    "if os.path.exists(vae_base_dir):\n",
    "    # Look for timestamped subdirectories\n",
    "    potential_runs = [d for d in os.listdir(vae_base_dir) if os.path.isdir(os.path.join(vae_base_dir, d))]\n",
    "    for run_dir in sorted(potential_runs, reverse=True):  # Most recent first\n",
    "        run_path = os.path.join(vae_base_dir, run_dir)\n",
    "        cfg_path = os.path.join(run_path, 'vae.cfg.p')\n",
    "        weights_dir = os.path.join(run_path, 'weights')\n",
    "\n",
    "        if os.path.exists(cfg_path) and os.path.exists(weights_dir):\n",
    "            weight_files = sorted([f for f in os.listdir(weights_dir) if f.endswith('.pt')])\n",
    "            if weight_files:\n",
    "                vae_runs.append({\n",
    "                    'run_dir': run_dir,\n",
    "                    'cfg_path': cfg_path,\n",
    "                    'weights_dir': weights_dir,\n",
    "                    'weight_files': weight_files\n",
    "                })\n",
    "\n",
    "if vae_runs:\n",
    "    print(f\"‚úÖ Found {len(vae_runs)} VAE training run(s):\\n\")\n",
    "\n",
    "    for i, run in enumerate(vae_runs, 1):\n",
    "        print(f\"Run {i}: {run['run_dir']}\")\n",
    "\n",
    "        # Load and show config\n",
    "        vae_cfg = pickle.load(open(run['cfg_path'], 'rb'))\n",
    "        print(f\"   Config: zdim={vae_cfg.get('zdim', 'N/A')}, nf={vae_cfg.get('nf', 'N/A')}\")\n",
    "\n",
    "        # Show checkpoints\n",
    "        print(f\"   Checkpoints: {len(run['weight_files'])} files\")\n",
    "        if len(run['weight_files']) <= 3:\n",
    "            for wf in run['weight_files']:\n",
    "                print(f\"      üì¶ {wf}\")\n",
    "        else:\n",
    "            print(f\"      üì¶ {run['weight_files'][0]} ... {run['weight_files'][-1]}\")\n",
    "        print()\n",
    "\n",
    "    # Recommendation\n",
    "    latest_run = vae_runs[0]\n",
    "    latest_weight = latest_run['weight_files'][-1]\n",
    "    recommended_path = os.path.join(latest_run['weights_dir'], latest_weight)\n",
    "\n",
    "    print(f\"üí° Recommendation:\")\n",
    "    print(f\"   Use latest run: {latest_run['run_dir']}\")\n",
    "    print(f\"   Latest checkpoint: {latest_weight}\")\n",
    "    print(f\"   \\n   Set in next cell:\")\n",
    "    print(f\"   CONFIG['vae_cfg'] = '{latest_run['cfg_path']}'\")\n",
    "    print(f\"   CONFIG['vae_weights'] = '{recommended_path}'\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No trained VAE runs found!\")\n",
    "    print(\"\\n   Please train VAE first using train_vae_colab.ipynb\")\n",
    "    print(f\"   Expected location: {vae_base_dir}/YYYYMMDD_HHMMSS/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fa53f3",
   "metadata": {
    "id": "10fa53f3"
   },
   "source": [
    "## 8. Configure GP-VAE Training\n",
    "\n",
    "Adjust these parameters as needed:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70721bf",
   "metadata": {
    "id": "d70721bf"
   },
   "source": [
    "## 7. Choose View Kernel üî¨\n",
    "\n",
    "**NEW: Kernel Selection for View Correlations**\n",
    "\n",
    "The view kernel models how correlations between face angles (0¬∞, 15¬∞, 30¬∞, ..., 90¬∞) are structured.\n",
    "\n",
    "### Available Kernels:\n",
    "\n",
    "1. **`'legacy'`** - Original implementation (normalized embeddings, 81 params)\n",
    "   - Most flexible but can overfit\n",
    "   - Good baseline for comparison\n",
    "\n",
    "2. **`'fullrank'`** - Direct full-rank covariance (45 params)\n",
    "   - Flexible but still many parameters\n",
    "   - Better than legacy due to fewer constraints\n",
    "\n",
    "3. **`'periodic'`** ‚≠ê **RECOMMENDED** - Periodic kernel (1 param: lengthscale)\n",
    "   - Knows that 0¬∞ = 360¬∞ (periodicity!)\n",
    "   - Smooth correlations between nearby angles\n",
    "   - Massive regularization (only 1 parameter)\n",
    "   - Best for rotation data\n",
    "\n",
    "4. **`'vonmises'`** ‚≠ê **RECOMMENDED** - Von Mises kernel (1 param: kappa)\n",
    "   - Designed specifically for circular/angular data\n",
    "   - Similar to Periodic but different parameterization\n",
    "   - Also best for rotation data\n",
    "\n",
    "5. **`'matern'`** - Mat√©rn kernel (1 param: lengthscale)\n",
    "   - More realistic than RBF, less smooth\n",
    "   - Good for modeling realistic correlations\n",
    "   - Can choose smoothness: nu=1.5 or nu=2.5\n",
    "\n",
    "6. **`'linear'`** - Low-rank linear (rank√ó9 params)\n",
    "   - Original GP-VAE kernel from Casale et al. (2018)\n",
    "   - Good middle-ground\n",
    "\n",
    "7. **`'rbf'`** - RBF/Gaussian (1 param: lengthscale)\n",
    "   - Smooth but NOT periodic\n",
    "   - Use only if views don't wrap around\n",
    "\n",
    "8. **`'spectral_mixture'`** ‚≠ê **NEW** - Spectral Mixture kernel (3√ó3 params)\n",
    "   - Learns mixture of frequencies in the spectral domain\n",
    "   - Very flexible - can model periodic AND non-periodic patterns\n",
    "   - Each component has: weight, mean frequency, lengthscale\n",
    "   - Good for complex correlation structures\n",
    "   - Requires continuous angle encoding\n",
    "\n",
    "### Expected Performance:\n",
    "\n",
    "| Metric | Legacy | FullRank | Periodic | VonMises | Mat√©rn | Spectral |\n",
    "|--------|--------|----------|----------|----------|--------|----------|\n",
    "| Val MSE | Medium | Medium | **Best** | **Best** | Good | **Excellent** |\n",
    "| Out-of-sample | Worst | Bad | **Best** | **Best** | Good | **Excellent** |\n",
    "| Overfitting | High | Medium | Low | Low | Low | Medium |\n",
    "| Parameters | 81 | 45 | 1 | 1 | 1 | 9 (3 comp) |\n",
    "| Smoothness | - | - | Very smooth | Very smooth | Adjustable | Very flexible |\n",
    "\n",
    "**Recommendation**:\n",
    "- **Best for rotations**: `'periodic'` or `'vonmises'`\n",
    "- **More realistic**: `'matern'` (less smooth than periodic)\n",
    "- **Most flexible**: `'spectral_mixture'` (can learn complex patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fedc7dbd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fedc7dbd",
    "outputId": "66492d22-6453-417c-8b92-dab3bdaa9836"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ EXPERIMENT MODE: Interpolation (Train boundaries, test intermediate)\n",
      "============================================================\n",
      "Training views (boundaries):\n",
      "  Index 0: 90L (-90¬∞)\n",
      "  Index 1: 60L (-60¬∞)\n",
      "  Index 3: 30L (-30¬∞)\n",
      "  Index 4: 00F (  0¬∞)\n",
      "  Index 5: 30R (+30¬∞)\n",
      "  Index 7: 60R (+60¬∞)\n",
      "  Index 8: 90R (+90¬∞)\n",
      "\n",
      "Validation views (intermediate):\n",
      "  Index 2: 45L (-45¬∞)\n",
      "  Index 6: 45R (+45¬∞)\n",
      "============================================================\n",
      "\n",
      "üí° Research Question:\n",
      "   Do structured kernels improve interpolation performance?\n",
      "   Expected: Periodic/VonMises/Mat√©rn > FullRank > Legacy\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# VIEW SPLIT CONFIGURATION - For Interpolation Experiment\n",
    "# ============================================================================\n",
    "\n",
    "# Experiment mode\n",
    "VIEW_SPLIT_MODE = 'interpolation'  # 'random' or 'by_view'\n",
    "\n",
    "# View angle mapping (after angular ordering fix):\n",
    "# Index 0: 90L (-90¬∞), 1: 60L (-60¬∞), 2: 45L (-45¬∞), 3: 30L (-30¬∞), 4: 00F (0¬∞),\n",
    "# Index 5: 30R (+30¬∞), 6: 45R (+45¬∞), 7: 60R (+60¬∞), 8: 90R (+90¬∞)\n",
    "\n",
    "if VIEW_SPLIT_MODE == 'interpolation':\n",
    "    # EXPERIMENT 1 (Interpolation): Train on boundaries, test on intermediate views\n",
    "    TRAIN_VIEW_INDICES = [0, 1, 3, 4, 5, 7, 8]  # 90L, 60L, 30L, 00F, 30R, 60R, 90R (boundaries)\n",
    "    VAL_VIEW_INDICES = [2, 6]  # 45L, 45R (intermediate angles)\n",
    "\n",
    "    print(\"üî¨ EXPERIMENT MODE: Interpolation (Train boundaries, test intermediate)\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Training views (boundaries):\")\n",
    "    print(\"  Index 0: 90L (-90¬∞)\")\n",
    "    print(\"  Index 1: 60L (-60¬∞)\")\n",
    "    print(\"  Index 3: 30L (-30¬∞)\")\n",
    "    print(\"  Index 4: 00F (  0¬∞)\")\n",
    "    print(\"  Index 5: 30R (+30¬∞)\")\n",
    "    print(\"  Index 7: 60R (+60¬∞)\")\n",
    "    print(\"  Index 8: 90R (+90¬∞)\")\n",
    "    print(\"\\nValidation views (intermediate):\")\n",
    "    print(\"  Index 2: 45L (-45¬∞)\")\n",
    "    print(\"  Index 6: 45R (+45¬∞)\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\nüí° Research Question:\")\n",
    "    print(\"   Do structured kernels improve interpolation performance?\")\n",
    "    print(\"   Expected: Periodic/VonMises/Mat√©rn > FullRank > Legacy\")\n",
    "else:\n",
    "    TRAIN_VIEW_INDICES = None\n",
    "    VAL_VIEW_INDICES = None\n",
    "    print(\"üìä Standard Mode: Random 90/10 train/val split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3fdd1f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6c3fdd1f",
    "outputId": "9e07a560-e862-443a-9485-ec7c377bcd70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Kernel Configuration:\n",
      "============================================================\n",
      "Kernel type: rbf\n",
      "Parameters: {'lengthscale': 1.0, 'angle_scale': 'normalized'}\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# KERNEL CONFIGURATION - Choose one option below\n",
    "# ============================================================================\n",
    "\n",
    "# Option 1: Periodic kernel (RECOMMENDED for face rotations)\n",
    "# KERNEL_CONFIG = {\n",
    "#     'view_kernel': 'periodic',\n",
    "#     'kernel_kwargs': {'lengthscale': 1.0}\n",
    "# }\n",
    "\n",
    "# Option 2: Von Mises kernel (RECOMMENDED alternative)\n",
    "# KERNEL_CONFIG = {\n",
    "#     'view_kernel': 'vonmises',\n",
    "#     'kernel_kwargs': {'kappa': 1.0}\n",
    "# }\n",
    "\n",
    "# Option 3: Mat√©rn kernel (realistic, less smooth than periodic)\n",
    "# KERNEL_CONFIG = {\n",
    "#     'view_kernel': 'matern',\n",
    "#     'kernel_kwargs': {'lengthscale': 1.0, 'nu': 1.5}  # nu=1.5 or nu=2.5\n",
    "# }\n",
    "\n",
    "# Option 4: Legacy (original implementation - baseline)\n",
    "# KERNEL_CONFIG = {\n",
    "#     'view_kernel': 'legacy',\n",
    "#     'kernel_kwargs': {}\n",
    "# }\n",
    "\n",
    "# Option 5: Full Rank (flexible, 45 params)\n",
    "# KERNEL_CONFIG = {\n",
    "#     'view_kernel': 'fullrank',\n",
    "#     'kernel_kwargs': {}\n",
    "# }\n",
    "\n",
    "# Option 6: Linear low-rank (original GP-VAE paper)\n",
    "# KERNEL_CONFIG = {\n",
    "#     'view_kernel': 'linear',\n",
    "#     'kernel_kwargs': {'rank': 3}\n",
    "# }\n",
    "\n",
    "# Option 7: RBF (smooth but not periodic)\n",
    "# KERNEL_CONFIG = {\n",
    "#     'view_kernel': 'rbf',\n",
    "#     'kernel_kwargs': {'lengthscale': 1.0, 'angle_scale': 'normalized'}\n",
    "# }\n",
    "\n",
    "# Option 8: Spectral Mixture (flexible frequency-domain kernel)\n",
    "KERNEL_CONFIG = {\n",
    "    'view_kernel': 'spectral_mixture',\n",
    "    'kernel_kwargs': {'n_components': 2, 'angle_scale': 'normalized'}\n",
    "}\n",
    "\n",
    "print(\"Selected Kernel Configuration:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Kernel type: {KERNEL_CONFIG['view_kernel']}\")\n",
    "if KERNEL_CONFIG['kernel_kwargs']:\n",
    "    print(f\"Parameters: {KERNEL_CONFIG['kernel_kwargs']}\")\n",
    "else:\n",
    "    print(\"Parameters: (default)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb82c9c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aeb82c9c",
    "outputId": "cfbb5604-d813-46de-ca1f-773389df8703"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GP-VAE Training Configuration:\n",
      "============================================================\n",
      "  data                : ./data/faceplace/data_faces.h5\n",
      "  outdir              : ./out/gppvae_colab/rbf_random_20260116_185111\n",
      "  vae_cfg             : ./out/vae_colab_interpolation/20260103_192743/vae.cfg.p\n",
      "  vae_weights         : ./out/vae_colab_interpolation/20260103_192743/weights/weights.00499.pt\n",
      "  epochs              : 1000\n",
      "  batch_size          : 64\n",
      "  vae_lr              : 0.001\n",
      "  gp_lr               : 0.001\n",
      "  xdim                : 64\n",
      "  view_kernel         : rbf\n",
      "  kernel_kwargs       : {'lengthscale': 1.0, 'angle_scale': 'normalized'}\n",
      "  view_split_mode     : interpolation\n",
      "  train_view_indices  : [0, 1, 3, 4, 5, 7, 8]\n",
      "  val_view_indices    : [2, 6]\n",
      "  epoch_cb            : 100\n",
      "  use_wandb           : True\n",
      "  wandb_project       : gppvae\n",
      "  wandb_run_name      : interpolation_rbf_20260116_185111\n",
      "  seed                : 0\n",
      "============================================================\n",
      "\n",
      "‚úÖ Output will be saved to:\n",
      "   ./out/gppvae_colab/rbf_random_20260116_185111\n",
      "\n",
      "   Directory name includes kernel type AND experiment mode!\n",
      "\n",
      "üí° Experiment: Interpolation (boundaries ‚Üí intermediate views)\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# GP-VAE Training configuration\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "kernel_name = KERNEL_CONFIG['view_kernel']\n",
    "\n",
    "# Include view split mode in directory name - \"interpolation\" for this experiment\n",
    "view_mode_str = 'interpolation' if VIEW_SPLIT_MODE == 'by_view' else 'random'\n",
    "\n",
    "CONFIG = {\n",
    "    'data': './data/faceplace/data_faces.h5',\n",
    "    # Output directory now includes kernel name AND experiment type\n",
    "    'outdir': f'./out/gppvae_colab/{kernel_name}_{view_mode_str}_{timestamp}',\n",
    "    'vae_cfg': './out/vae_colab_interpolation/20260103_192743/vae.cfg.p',\n",
    "    'vae_weights': './out/vae_colab_interpolation/20260103_192743/weights/weights.00499.pt',\n",
    "\n",
    "    # Training hyperparameters\n",
    "    'epochs': 500,\n",
    "    'batch_size': 64,\n",
    "    'vae_lr': 0.001,\n",
    "    'gp_lr': 0.001,\n",
    "    'xdim': 64,\n",
    "\n",
    "    # Kernel configuration\n",
    "    'view_kernel': KERNEL_CONFIG['view_kernel'],\n",
    "    'kernel_kwargs': KERNEL_CONFIG['kernel_kwargs'],\n",
    "    \n",
    "    # Angle encoding (will be determined automatically based on kernel type)\n",
    "    'use_angle_encoding': KERNEL_CONFIG['view_kernel'] in ['rbf', 'matern', 'spectral_mixture'],\n",
    "\n",
    "    # Experiment configuration (NEW)\n",
    "    'view_split_mode': VIEW_SPLIT_MODE,\n",
    "    'train_view_indices': TRAIN_VIEW_INDICES,\n",
    "    'val_view_indices': VAL_VIEW_INDICES,\n",
    "\n",
    "    # Logging\n",
    "    'epoch_cb': 100,\n",
    "    'use_wandb': True,\n",
    "    'wandb_project': 'gppvae',\n",
    "    'wandb_run_name': f'interpolation_{kernel_name}_{timestamp}',\n",
    "    'seed': 0,\n",
    "}\n",
    "\n",
    "print(\"GP-VAE Training Configuration:\")\n",
    "print(\"=\" * 60)\n",
    "for key, value in CONFIG.items():\n",
    "    if key in ['train_view_indices', 'val_view_indices'] and value is not None:\n",
    "        print(f\"  {key:20s}: {value}\")\n",
    "    elif key not in ['train_view_indices', 'val_view_indices']:\n",
    "        print(f\"  {key:20s}: {value}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Verify VAE weights path\n",
    "if not os.path.exists(CONFIG['vae_weights']):\n",
    "    print(f\"\\n‚ö†Ô∏è  WARNING: VAE weights not found at:\")\n",
    "    print(f\"   {CONFIG['vae_weights']}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Output will be saved to:\")\n",
    "print(f\"   {CONFIG['outdir']}\")\n",
    "print(f\"\\n   Directory name includes kernel type AND experiment mode!\")\n",
    "print(f\"\\nüí° Experiment: Interpolation (boundaries ‚Üí intermediate views)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9255bb2",
   "metadata": {
    "id": "f9255bb2"
   },
   "source": [
    "## 9. Import Training Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16ab22b2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "16ab22b2",
    "outputId": "847df807-52c7-4317-de46-5d3e4fd34efa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All modules imported successfully!\n",
      "‚úÖ Using data_parser_interpolation for interpolation experiment\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.join(PROJECT_PATH, 'GPPVAE/pysrc/faceplace'))\n",
    "\n",
    "# Import modules\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from vae import FaceVAE\n",
    "from vmod import Vmodel\n",
    "from gp import GP\n",
    "import h5py\n",
    "import numpy as np\n",
    "import logging\n",
    "import pylab as pl\n",
    "from utils import smartSum, smartAppendDict, smartAppend, export_scripts\n",
    "from callbacks import callback_gppvae\n",
    "import pickle\n",
    "import time\n",
    "import wandb\n",
    "\n",
    "# IMPORTANT: Use interpolation data parser with angle encoding\n",
    "from data_parser_interpolation import read_face_data, FaceDataset\n",
    "\n",
    "print(\"‚úÖ All modules imported successfully!\")\n",
    "print(\"‚úÖ Using data_parser_interpolation for interpolation experiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1953910",
   "metadata": {
    "id": "e1953910"
   },
   "source": [
    "## 10. Setup Training Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd715632",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dd715632",
    "outputId": "6de4582d-6cbc-4bc2-f2ee-f2db17548352"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "‚úÖ Training environment setup complete!\n",
      "   Outputs will be saved to: ./out/gppvae_colab/rbf_random_20260116_185111\n"
     ]
    }
   ],
   "source": [
    "# Go back to project root\n",
    "os.chdir(PROJECT_PATH)\n",
    "\n",
    "# Create output directories\n",
    "outdir = CONFIG['outdir']\n",
    "wdir = os.path.join(outdir, \"weights\")\n",
    "fdir = os.path.join(outdir, \"plots\")\n",
    "os.makedirs(wdir, exist_ok=True)\n",
    "os.makedirs(fdir, exist_ok=True)\n",
    "\n",
    "# Setup device (GPU)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Setup logging\n",
    "log_format = \"%(asctime)s %(message)s\"\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=log_format,\n",
    "    datefmt=\"%m/%d %I:%M:%S %p\",\n",
    ")\n",
    "fh = logging.FileHandler(os.path.join(outdir, \"log.txt\"))\n",
    "fh.setFormatter(logging.Formatter(log_format))\n",
    "logging.getLogger().addHandler(fh)\n",
    "\n",
    "# Copy code to output\n",
    "export_scripts(os.path.join(outdir, \"scripts\"))\n",
    "\n",
    "print(\"‚úÖ Training environment setup complete!\")\n",
    "print(f\"   Outputs will be saved to: {outdir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36678b2b",
   "metadata": {
    "id": "36678b2b"
   },
   "source": [
    "## 10. Initialize Models and Data\n",
    "\n",
    "This cell:\n",
    "1. Loads pre-trained VAE\n",
    "2. Creates GP and Vmodel\n",
    "3. Loads dataset\n",
    "4. Sets up optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7bf143",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9c7bf143",
    "outputId": "404b87d6-2ebd-4434-b6eb-4329f8bbb088"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>diagnostics/gap_train_val</td><td>‚ñÅ‚ñÑ‚ñÑ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÉ‚ñÖ‚ñÑ</td></tr><tr><td>diagnostics/gap_val_out</td><td>‚ñà‚ñá‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ</td></tr><tr><td>diagnostics/variance_ratio</td><td>‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ</td></tr><tr><td>epoch</td><td>‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà</td></tr><tr><td>gp_nll</td><td>‚ñÉ‚ñá‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñá‚ñà</td></tr><tr><td>loss</td><td>‚ñÅ‚ñà‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ</td></tr><tr><td>mse_out</td><td>‚ñÉ‚ñà‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ</td></tr><tr><td>mse_out_per_view/45L</td><td>‚ñÉ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ</td></tr><tr><td>mse_out_per_view/45R</td><td>‚ñÉ‚ñà‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ</td></tr><tr><td>mse_train</td><td>‚ñÅ‚ñà‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ</td></tr><tr><td>+8</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>diagnostics/gap_train_val</td><td>-0.00071</td></tr><tr><td>diagnostics/gap_val_out</td><td>0.03981</td></tr><tr><td>diagnostics/variance_ratio</td><td>0.49539</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>gp_nll</td><td>0.0032</td></tr><tr><td>loss</td><td>-1.47101</td></tr><tr><td>mse_out</td><td>0.04705</td></tr><tr><td>mse_out_per_view/45L</td><td>0.04662</td></tr><tr><td>mse_out_per_view/45R</td><td>0.04747</td></tr><tr><td>mse_train</td><td>0.00653</td></tr><tr><td>+9</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">interpolation_rbf_20260116_185111</strong> at: <a href='https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae/runs/3ircx7l7' target=\"_blank\">https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae/runs/3ircx7l7</a><br> View project at: <a href='https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae' target=\"_blank\">https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae</a><br>Synced 5 W&B file(s), 2 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/content/wandb/run-20260116_185127-3ircx7l7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20260116_185514-fr3qjkte</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae/runs/fr3qjkte' target=\"_blank\">interpolation_rbf_20260116_185111</a></strong> to <a href='https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae' target=\"_blank\">https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae/runs/fr3qjkte' target=\"_blank\">https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae/runs/fr3qjkte</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE config: {'nf': 32, 'zdim': 256, 'vy': 0.002}\n",
      "\n",
      "Loading pre-trained VAE...\n",
      "‚úÖ VAE loaded from ./out/vae_colab_interpolation/20260103_192743/weights/weights.00499.pt\n",
      "   Total VAE parameters: 553,304\n",
      "\n",
      "Loading dataset WITHOUT angle encoding (will use view indices)...\n",
      "\n",
      "üìÇ Loading data from: ./data/faceplace/data_faces.h5\n",
      "   Split mode: interpolation\n",
      "   Angle encoding: ‚úÖ ENABLED (using actual angles)\n",
      "\n",
      "üîç DEBUG: View encoding from HDF5\n",
      "   Unique Rid values in train: [np.bytes_(b'00F'), np.bytes_(b'30L'), np.bytes_(b'30R'), np.bytes_(b'45L'), np.bytes_(b'45R'), np.bytes_(b'60L'), np.bytes_(b'60R'), np.bytes_(b'90L'), np.bytes_(b'90R')]\n",
      "   uRid (ordered): [b'90L' b'60L' b'45L' b'30L' b'00F' b'30R' b'45R' b'60R' b'90R']\n",
      "   View mapping table_w: {np.bytes_(b'90L'): 0, np.bytes_(b'60L'): 1, np.bytes_(b'45L'): 2, np.bytes_(b'30L'): 3, np.bytes_(b'00F'): 4, np.bytes_(b'30R'): 5, np.bytes_(b'45R'): 6, np.bytes_(b'60R'): 7, np.bytes_(b'90R'): 8}\n",
      "   W['train'] unique values: [np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8)]\n",
      "   W['val'] unique values: []\n",
      "   W['test'] unique values: []\n",
      "\n",
      "‚úÖ View encoding applied:\n",
      "   All view indices converted to normalized angles [-1.0, 1.0]\n",
      "   This preserves geometric relationships between views\n",
      "\n",
      "üî¨ Applying interpolation split:\n",
      "   Train views (boundary): [0, 1, 3, 4, 5, 7, 8]\n",
      "   Val views (intermediate): [2, 6]\n",
      "\n",
      "üîç Filtering identities with complete view coverage (Interpolation)...\n",
      "   Required views: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "   Train views (boundary): [0, 1, 3, 4, 5, 7, 8]\n",
      "   Val views (intermediate): [2, 6]\n",
      "   Total identities before filtering: 412\n",
      "   üéØ Using ACTUAL ANGLE VALUES (not indices)\n",
      "   This provides geometric information to structured kernels\n",
      "   üéØ W already contains angles, matching against angle values\n",
      "   Identities with all required views: 412\n",
      "   Filtered out: 0 identities\n",
      "   ‚úÖ Remapped 412 identities to contiguous indices [0..411]\n",
      "   ‚úÖ W already encoded as angles, no conversion needed\n",
      "\n",
      "‚úÖ Interpolation split validation:\n",
      "   Total samples (filtered): 3708\n",
      "   Train samples: 2884 (views: [np.float32(-1.0), np.float32(-0.6666667), np.float32(-0.33333334), np.float32(0.0), np.float32(0.33333334), np.float32(0.6666667), np.float32(1.0)])\n",
      "   Val samples: 824 (views: [np.float32(-0.5), np.float32(0.5)])\n",
      "   Train identities: 412\n",
      "   Val identities: 412\n",
      "   Identity overlap: 412\n",
      "   ‚úÖ All 412 identities present in both train/val!\n",
      "   Train samples per identity: 7.0 (expected: 7.0)\n",
      "   Val samples per identity: 2.0 (expected: 2.0)\n",
      "   ‚úÖ Perfect split verified!\n",
      "\n",
      "üéØ Interpolation task verification:\n",
      "   Training on boundary angles:\n",
      "      Index 0: 90L ‚Üí encoded as -1.000\n",
      "      Index 1: 60L ‚Üí encoded as -0.667\n",
      "      Index 3: 30L ‚Üí encoded as -0.333\n",
      "      Index 4: 00F ‚Üí encoded as 0.000\n",
      "      Index 5: 30R ‚Üí encoded as 0.333\n",
      "      Index 7: 60R ‚Üí encoded as 0.667\n",
      "      Index 8: 90R ‚Üí encoded as 1.000\n",
      "   Testing on intermediate angles:\n",
      "      Index 2: 45L (interpolation target) ‚Üí encoded as -0.500\n",
      "      Index 6: 45R (interpolation target) ‚Üí encoded as 0.500\n",
      "   ‚úÖ 45L is bounded by training views 60L and 30L\n",
      "   ‚úÖ 45R is bounded by training views 30R and 60R\n",
      "\n",
      "   üìê Geometric distances now explicit:\n",
      "      distance(90L, 60L) = |-1.00 - (-0.67)| = 0.33 (30¬∞)\n",
      "      distance(60L, 45L) = |-0.67 - (-0.50)| = 0.17 (15¬∞)\n",
      "      distance(45L, 30L) = |-0.50 - (-0.33)| = 0.17 (15¬∞)\n",
      "   ‚úÖ True angular distances preserved!\n",
      "\n",
      "‚úÖ Interpolation split final validation:\n",
      "   ‚úÖ Train angles correct: [np.float32(-1.0), np.float32(-0.6666667), np.float32(-0.33333334), np.float32(0.0), np.float32(0.33333334), np.float32(0.6666667), np.float32(1.0)]\n",
      "   ‚úÖ Val angles correct: [np.float32(-0.5), np.float32(0.5)]\n",
      "   ‚úÖ No overlap between train/val views\n",
      "\n",
      "üí° Interpolation Task Expectations:\n",
      "   ‚úÖ Using ACTUAL ANGLE VALUES (geometrically correct)\n",
      "   - Structured kernels can directly leverage angular smoothness\n",
      "   - Periodic/VonMises kernels know true distances between views\n",
      "   - Expected: Smoother interpolation from structured kernels\n",
      "   - FullRank must learn geometry from data (more parameters)\n",
      "\n",
      "   Key metric: How smoothly does each kernel interpolate?\n",
      "\n",
      "‚úÖ Final dataset sizes:\n",
      "   test :     0 samples\n",
      "   train:  2884 samples\n",
      "           Unique view angles: 7 [np.float32(-1.0), np.float32(-0.667), np.float32(-0.333), np.float32(0.0), np.float32(0.333), np.float32(0.667), np.float32(1.0)]\n",
      "   val  :   824 samples\n",
      "           Unique view angles: 2 [np.float32(-0.5), np.float32(0.5)]\n",
      "\n",
      "‚úÖ Data loaded:\n",
      "   Training samples: 2884\n",
      "   Validation samples: 824\n",
      "   Train view indices: [-1.         -0.6666667  -0.33333334  0.          0.33333334  0.6666667\n",
      "  1.        ]\n",
      "   Val view indices: [-0.5  0.5]\n",
      "   Unique train identities: 412\n",
      "   Unique val identities: 412\n",
      "\n",
      "Initializing GP-VAE components...\n",
      "   Objects (people): 412\n",
      "   Views (angles): 9\n",
      "   Train views: [-1, 0, 0, 0, 0, 0, 1]\n",
      "   Val views: [0, 0]\n",
      "\n",
      "üî¨ Initializing view kernel: 'rbf'\n",
      "   Kernel parameters: {'lengthscale': 1.0, 'angle_scale': 'normalized'}\n",
      "‚úÖ GP-VAE components initialized:\n",
      "   Vmodel parameters: 26,369\n",
      "   GP parameters: 2\n",
      "   Total trainable: 579,675\n",
      "\n",
      "‚úÖ Optimizers created:\n",
      "   VAE optimizer: Adam(lr=0.001)\n",
      "   GP optimizer: Adam(lr=0.001)\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "torch.manual_seed(CONFIG['seed'])\n",
    "\n",
    "# Determine if we need angle encoding based on kernel choice\n",
    "# RBF, Mat√©rn, and Spectral Mixture kernels work with continuous angles\n",
    "use_angle_encoding = CONFIG['view_kernel'] in ['rbf', 'matern', 'spectral_mixture']\n",
    "\n",
    "if use_angle_encoding:\n",
    "    print(\"\\nüéØ ANGLE ENCODING ENABLED\")\n",
    "    print(f\"   Kernel '{CONFIG['view_kernel']}' requires continuous angle values\")\n",
    "    print(f\"   Views will be encoded as normalized angles (e.g., -1.0 to +1.0)\")\n",
    "else:\n",
    "    print(\"\\nüìç DISCRETE VIEW INDICES MODE\")\n",
    "    print(f\"   Kernel '{CONFIG['view_kernel']}' uses discrete view embeddings\")\n",
    "\n",
    "# Initialize W&B\n",
    "if CONFIG['use_wandb']:\n",
    "    wandb.init(\n",
    "        project=CONFIG['wandb_project'],\n",
    "        name=CONFIG['wandb_run_name'],\n",
    "        config=CONFIG  # CONFIG already contains use_angle_encoding\n",
    "    )\n",
    "\n",
    "# Load VAE configuration\n",
    "vae_cfg = pickle.load(open(CONFIG['vae_cfg'], \"rb\"))\n",
    "print(f\"VAE config: {vae_cfg}\")\n",
    "\n",
    "# Load pre-trained VAE\n",
    "print(\"\\nLoading pre-trained VAE...\")\n",
    "vae = FaceVAE(**vae_cfg).to(device)\n",
    "vae_state = torch.load(CONFIG['vae_weights'], map_location=device)\n",
    "vae.load_state_dict(vae_state)\n",
    "print(f\"‚úÖ VAE loaded from {CONFIG['vae_weights']}\")\n",
    "print(f\"   Total VAE parameters: {sum(p.numel() for p in vae.parameters()):,}\")\n",
    "\n",
    "# Load data with interpolation experiment configuration\n",
    "print(f\"\\nLoading dataset with angle_encoding={use_angle_encoding}...\")\n",
    "img, obj, view = read_face_data(\n",
    "    CONFIG['data'],\n",
    "    use_angle_encoding=use_angle_encoding,\n",
    "    view_split_mode=CONFIG['view_split_mode'],\n",
    "    train_view_indices=CONFIG.get('train_view_indices'),\n",
    "    val_view_indices=CONFIG.get('val_view_indices')\n",
    ")\n",
    "\n",
    "train_data = FaceDataset(img[\"train\"], obj[\"train\"], view[\"train\"])\n",
    "val_data = FaceDataset(img[\"val\"], obj[\"val\"], view[\"val\"])\n",
    "train_queue = DataLoader(train_data, batch_size=CONFIG['batch_size'], shuffle=True)\n",
    "val_queue = DataLoader(val_data, batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "\n",
    "# Enhanced diagnostic logging\n",
    "print(f\"\\n‚úÖ Data loaded:\")\n",
    "print(f\"   Training samples: {len(train_data)}\")\n",
    "print(f\"   Validation samples: {len(val_data)}\")\n",
    "if use_angle_encoding:\n",
    "    print(f\"   Train view angles: {np.unique(view['train'].numpy().round(3))}\")\n",
    "    print(f\"   Val view angles: {np.unique(view['val'].numpy().round(3))}\")\n",
    "else:\n",
    "    print(f\"   Train view indices: {np.unique(view['train'].numpy())}\")\n",
    "    print(f\"   Val view indices: {np.unique(view['val'].numpy())}\")\n",
    "print(f\"   Unique train identities: {len(np.unique(obj['train'].numpy()))}\")\n",
    "print(f\"   Unique val identities: {len(np.unique(obj['val'].numpy()))}\")\n",
    "\n",
    "# Validation checks for interpolation experiment\n",
    "if CONFIG['view_split_mode'] == 'by_view':\n",
    "    print(\"\\nüîç Interpolation Experiment Validation Checks:\")\n",
    "\n",
    "    if use_angle_encoding:\n",
    "        # With angle encoding, views are continuous floats\n",
    "        # Need to check against expected angle values\n",
    "        from data_parser_interpolation import encode_view_angles\n",
    "        train_angles_expected = encode_view_angles(\n",
    "            np.array(CONFIG['train_view_indices']), \n",
    "            encoding='normalized'\n",
    "        ).numpy().round(6)\n",
    "        val_angles_expected = encode_view_angles(\n",
    "            np.array(CONFIG['val_view_indices']), \n",
    "            encoding='normalized'\n",
    "        ).numpy().round(6)\n",
    "        \n",
    "        train_angles_actual = np.round(np.unique(view['train'].numpy().flatten()), 6)\n",
    "        val_angles_actual = np.round(np.unique(view['val'].numpy().flatten()), 6)\n",
    "        \n",
    "        assert set(train_angles_actual) == set(train_angles_expected), \"Train angles mismatch!\"\n",
    "        assert set(val_angles_actual) == set(val_angles_expected), \"Val angles mismatch!\"\n",
    "        print(\"   ‚úÖ View angles verified correctly!\")\n",
    "    else:\n",
    "        # Check 1: View split correctness with discrete indices\n",
    "        train_views_set = set(np.unique(view['train'].numpy().flatten()).astype(int))\n",
    "        val_views_set = set(np.unique(view['val'].numpy().flatten()).astype(int))\n",
    "\n",
    "        assert train_views_set == set(CONFIG['train_view_indices']), f\"Train views mismatch!\"\n",
    "        assert val_views_set == set(CONFIG['val_view_indices']), f\"Val views mismatch!\"\n",
    "        assert len(train_views_set & val_views_set) == 0, \"Train and val views overlap!\"\n",
    "        print(\"   ‚úÖ View split verified correctly!\")\n",
    "\n",
    "    # Check 2: Identity coverage\n",
    "    train_ids = set(np.unique(obj['train'].numpy()))\n",
    "    val_ids = set(np.unique(obj['val'].numpy()))\n",
    "    assert train_ids == val_ids, \"Identity sets don't match between train/val!\"\n",
    "    print(f\"   ‚úÖ All {len(train_ids)} identities present in both train/val!\")\n",
    "\n",
    "    # Check 3: Sample distribution\n",
    "    train_samples_per_id = len(img['train']) / len(train_ids)\n",
    "    val_samples_per_id = len(img['val']) / len(val_ids)\n",
    "    print(f\"   ‚úÖ Train samples per identity: {train_samples_per_id:.1f} (expected: {len(CONFIG['train_view_indices'])}.0)\")\n",
    "    print(f\"   ‚úÖ Val samples per identity: {val_samples_per_id:.1f} (expected: {len(CONFIG['val_view_indices'])}.0)\")\n",
    "\n",
    "# Create object and view variables for GP\n",
    "Dt = Variable(obj[\"train\"][:, 0].long(), requires_grad=False).cuda()\n",
    "Dv = Variable(obj[\"val\"][:, 0].long(), requires_grad=False).cuda()\n",
    "\n",
    "# Keep view as float if using angle encoding, otherwise convert to long\n",
    "if use_angle_encoding:\n",
    "    Wt = Variable(view[\"train\"][:, 0], requires_grad=False).cuda()  # Float angles\n",
    "    Wv = Variable(view[\"val\"][:, 0], requires_grad=False).cuda()  # Float angles\n",
    "else:\n",
    "    Wt = Variable(view[\"train\"][:, 0].long(), requires_grad=False).cuda()  # Integer indices\n",
    "    Wv = Variable(view[\"val\"][:, 0].long(), requires_grad=False).cuda()  # Integer indices\n",
    "\n",
    "# Initialize GP and Vmodel\n",
    "print(\"\\nInitializing GP-VAE components...\")\n",
    "\n",
    "# Count unique identities and views\n",
    "all_identities = np.unique(np.concatenate([obj[\"train\"].numpy(), obj[\"val\"].numpy()]))\n",
    "\n",
    "if use_angle_encoding:\n",
    "    # With angle encoding, Q is still the number of reference angles (9 views)\n",
    "    Q = 9\n",
    "    P = len(all_identities)\n",
    "    print(f\"   Objects (people): {P}\")\n",
    "    print(f\"   Views (reference angles): {Q}\")\n",
    "    print(f\"   Using continuous angle values\")\n",
    "else:\n",
    "    # With discrete indices, count unique view indices\n",
    "    all_views = np.unique(np.concatenate([view[\"train\"].numpy(), view[\"val\"].numpy()]))\n",
    "    Q = len(all_views)\n",
    "    P = len(all_identities)\n",
    "    print(f\"   Objects (people): {P}\")\n",
    "    print(f\"   Views (discrete): {Q}\")\n",
    "    print(f\"   Train views: {sorted(np.unique(view['train'].numpy()).astype(int).tolist())}\")\n",
    "    print(f\"   Val views: {sorted(np.unique(view['val'].numpy()).astype(int).tolist())}\")\n",
    "\n",
    "# Initialize Vmodel with standard discrete view indices\n",
    "vm = Vmodel(\n",
    "    P, Q,\n",
    "    p=CONFIG['xdim'],\n",
    "    q=Q,  # For legacy, q=Q\n",
    "    view_kernel=CONFIG['view_kernel'],\n",
    "    **CONFIG['kernel_kwargs']\n",
    ").cuda()\n",
    "\n",
    "print(f\"\\nüî¨ Initializing view kernel: '{CONFIG['view_kernel']}'\")\n",
    "if CONFIG['kernel_kwargs']:\n",
    "    print(f\"   Kernel parameters: {CONFIG['kernel_kwargs']}\")\n",
    "else:\n",
    "    print(f\"   Kernel parameters: (default)\")\n",
    "\n",
    "gp = GP(n_rand_effs=1).to(device)\n",
    "\n",
    "# Combine GP parameters (Vmodel + GP)\n",
    "gp_params = nn.ParameterList()\n",
    "gp_params.extend(vm.parameters())\n",
    "gp_params.extend(gp.parameters())\n",
    "\n",
    "print(f\"‚úÖ GP-VAE components initialized:\")\n",
    "print(f\"   Vmodel parameters: {sum(p.numel() for p in vm.parameters()):,}\")\n",
    "print(f\"   GP parameters: {sum(p.numel() for p in gp.parameters()):,}\")\n",
    "print(f\"   Total trainable: {sum(p.numel() for p in vae.parameters()) + sum(p.numel() for p in gp_params):,}\")\n",
    "\n",
    "# Create optimizers (separate for VAE and GP)\n",
    "vae_optimizer = optim.Adam(vae.parameters(), lr=CONFIG['vae_lr'])\n",
    "gp_optimizer = optim.Adam(gp_params, lr=CONFIG['gp_lr'])\n",
    "print(f\"\\n‚úÖ Optimizers created:\")\n",
    "print(f\"   VAE optimizer: Adam(lr={CONFIG['vae_lr']})\")\n",
    "print(f\"   GP optimizer: Adam(lr={CONFIG['gp_lr']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9082858",
   "metadata": {
    "id": "b9082858"
   },
   "source": [
    "## 11. Define Training Functions\n",
    "\n",
    "These functions handle the complex GP-VAE training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa7bebf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dfa7bebf",
    "outputId": "8f956261-4a00-4a62-9d0e-d58dfb5b1861"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training functions defined with per-view metrics for interpolation\n",
      "‚úÖ Diverse identity sampling now collects from entire validation set\n"
     ]
    }
   ],
   "source": [
    "def encode_Y(vae, train_queue):\n",
    "    \"\"\"Encode all training images to get latent codes\"\"\"\n",
    "    vae.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        n = train_queue.dataset.Y.shape[0]\n",
    "        Zm = Variable(torch.zeros(n, vae_cfg[\"zdim\"]), requires_grad=False).cuda()\n",
    "        Zs = Variable(torch.zeros(n, vae_cfg[\"zdim\"]), requires_grad=False).cuda()\n",
    "\n",
    "        for batch_i, data in enumerate(train_queue):\n",
    "            y = data[0].cuda()\n",
    "            idxs = data[-1].cuda()\n",
    "            zm, zs = vae.encode(y)\n",
    "            Zm[idxs], Zs[idxs] = zm.detach(), zs.detach()\n",
    "\n",
    "    return Zm, Zs\n",
    "\n",
    "\n",
    "def eval_step(vae, gp, vm, val_queue, Zm, Vt, Vv, Wv, use_angle_encoding=False):\n",
    "    \"\"\"Enhanced evaluation with per-view metrics for Interpolation Experiment\"\"\"\n",
    "    rv = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _X = vm.x().data.cpu().numpy()\n",
    "        _W = vm.v().data.cpu().numpy()\n",
    "        covs = {\"XX\": np.dot(_X, _X.T), \"WW\": np.dot(_W, _W.T)}\n",
    "        rv[\"vars\"] = gp.get_vs().data.cpu().numpy()\n",
    "\n",
    "        # Out-of-sample prediction\n",
    "        vs = gp.get_vs()\n",
    "        U, UBi, _ = gp.U_UBi_Shb([Vt], vs)\n",
    "        Kiz = gp.solve(Zm, U, UBi, vs)\n",
    "        Zo = vs[0] * Vv.mm(Vt.transpose(0, 1).mm(Kiz))\n",
    "\n",
    "        mse_out = Variable(torch.zeros(Vv.shape[0], 1), requires_grad=False).cuda()\n",
    "        mse_val = Variable(torch.zeros(Vv.shape[0], 1), requires_grad=False).cuda()\n",
    "\n",
    "        # Collect ALL validation samples first for diverse sampling\n",
    "        all_Yv = []\n",
    "        all_Yr = []\n",
    "        all_Yo = []\n",
    "\n",
    "        for batch_i, data in enumerate(val_queue):\n",
    "            idxs = data[-1].cuda()\n",
    "            Yv = data[0].cuda()\n",
    "            Zv = vae.encode(Yv)[0].detach()\n",
    "            Yr = vae.decode(Zv)\n",
    "            Yo = vae.decode(Zo[idxs])\n",
    "            mse_out[idxs] = ((Yv - Yo) ** 2).view(Yv.shape[0], -1).mean(1)[:, None].detach()\n",
    "            mse_val[idxs] = ((Yv - Yr) ** 2).view(Yv.shape[0], -1).mean(1)[:, None].detach()\n",
    "\n",
    "            # Collect all samples for diverse visualization\n",
    "            all_Yv.append(Yv.data.cpu().numpy().transpose(0, 2, 3, 1))\n",
    "            all_Yr.append(Yr.data.cpu().numpy().transpose(0, 2, 3, 1))\n",
    "            all_Yo.append(Yo.data.cpu().numpy().transpose(0, 2, 3, 1))\n",
    "\n",
    "        # Concatenate all validation samples\n",
    "        all_Yv = np.concatenate(all_Yv, axis=0)\n",
    "        all_Yr = np.concatenate(all_Yr, axis=0)\n",
    "        all_Yo = np.concatenate(all_Yo, axis=0)\n",
    "\n",
    "        # Sample diverse identities across the validation set (evenly spaced)\n",
    "        n_total = all_Yv.shape[0]\n",
    "        if n_total >= 24:\n",
    "            sample_stride = max(1, n_total // 24)\n",
    "            sample_indices = np.arange(0, n_total, sample_stride)[:24]\n",
    "        else:\n",
    "            sample_indices = np.arange(min(24, n_total))\n",
    "\n",
    "        imgs = {}\n",
    "        imgs[\"Yv\"] = all_Yv[sample_indices]\n",
    "        imgs[\"Yr\"] = all_Yr[sample_indices]\n",
    "        imgs[\"Yo\"] = all_Yo[sample_indices]\n",
    "\n",
    "        rv[\"mse_out\"] = float(mse_out.data.mean().cpu())\n",
    "        rv[\"mse_val\"] = float(mse_val.data.mean().cpu())\n",
    "\n",
    "        # NEW: Per-view metrics for Interpolation Experiment\n",
    "        # Need to handle both continuous angles and discrete indices\n",
    "        if use_angle_encoding:\n",
    "            # With angle encoding, need to map angles back to view indices\n",
    "            from data_parser_interpolation import encode_view_angles\n",
    "            # Create mapping from angles to indices for validation views\n",
    "            val_indices = np.array(CONFIG['val_view_indices'])\n",
    "            val_angles = encode_view_angles(val_indices, encoding='normalized').numpy()\n",
    "            \n",
    "            # Map each unique angle back to its index\n",
    "            mse_val_per_view = {}\n",
    "            mse_out_per_view = {}\n",
    "            \n",
    "            for idx, angle in zip(val_indices, val_angles):\n",
    "                # Find samples with this angle (with small tolerance for floating point)\n",
    "                view_mask = np.abs(Wv.cpu().numpy().flatten() - angle) < 1e-5\n",
    "                if view_mask.sum() > 0:\n",
    "                    mse_val_per_view[int(idx)] = float(mse_val.cpu().numpy()[view_mask].mean())\n",
    "                    mse_out_per_view[int(idx)] = float(mse_out.cpu().numpy()[view_mask].mean())\n",
    "        else:\n",
    "            # With discrete indices, use them directly\n",
    "            unique_views = torch.unique(Wv).cpu().numpy()\n",
    "            mse_val_per_view = {}\n",
    "            mse_out_per_view = {}\n",
    "            \n",
    "            for view_idx in unique_views:\n",
    "                view_mask = (Wv.cpu().numpy().flatten() == view_idx)\n",
    "                if view_mask.sum() > 0:\n",
    "                    mse_val_per_view[int(view_idx)] = float(mse_val.cpu().numpy()[view_mask].mean())\n",
    "                    mse_out_per_view[int(view_idx)] = float(mse_out.cpu().numpy()[view_mask].mean())\n",
    "\n",
    "        rv['mse_val_per_view'] = mse_val_per_view\n",
    "        rv['mse_out_per_view'] = mse_out_per_view\n",
    "\n",
    "    return rv, imgs, covs\n",
    "\n",
    "\n",
    "def backprop_and_update(vae, gp, vm, train_queue, Dt, Wt, Eps, Zb, Vbs, vbs, vae_optimizer, gp_optimizer):\n",
    "    \"\"\"Joint optimization of VAE and GP\"\"\"\n",
    "    rv = {}\n",
    "\n",
    "    vae_optimizer.zero_grad()\n",
    "    gp_optimizer.zero_grad()\n",
    "    vae.train()\n",
    "    gp.train()\n",
    "    vm.train()\n",
    "\n",
    "    for batch_i, data in enumerate(train_queue):\n",
    "        # Get batch data\n",
    "        y = data[0].cuda()\n",
    "        eps = Eps[data[-1]]\n",
    "        _d = Dt[data[-1]]\n",
    "        _w = Wt[data[-1]]\n",
    "        _Zb = Zb[data[-1]]\n",
    "        _Vbs = [Vbs[0][data[-1]]]\n",
    "\n",
    "        # Forward through VAE\n",
    "        zm, zs = vae.encode(y)\n",
    "        z = zm + zs * eps\n",
    "        yr = vae.decode(z)\n",
    "        recon_term, mse = vae.nll(y, yr)\n",
    "\n",
    "        # Forward through GP\n",
    "        _Vs = [vm(_d, _w)]\n",
    "        gp_nll_fo = gp.taylor_expansion(z, _Vs, _Zb, _Vbs, vbs) / vae.K\n",
    "\n",
    "        # Penalization term\n",
    "        pen_term = -0.5 * zs.sum(1)[:, None] / vae.K\n",
    "\n",
    "        # Joint loss and backward\n",
    "        loss = (recon_term + gp_nll_fo + pen_term).sum()\n",
    "        loss.backward()\n",
    "\n",
    "        # Accumulate metrics\n",
    "        _n = train_queue.dataset.Y.shape[0]\n",
    "        smartSum(rv, \"mse\", float(mse.data.sum().cpu()) / _n)\n",
    "        smartSum(rv, \"recon_term\", float(recon_term.data.sum().cpu()) / _n)\n",
    "        smartSum(rv, \"pen_term\", float(pen_term.data.sum().cpu()) / _n)\n",
    "\n",
    "    # Update both optimizers\n",
    "    vae_optimizer.step()\n",
    "    gp_optimizer.step()\n",
    "\n",
    "    return rv\n",
    "\n",
    "\n",
    "print(\"‚úÖ Training functions defined with per-view metrics for interpolation\")\n",
    "print(\"‚úÖ Diverse identity sampling now collects from entire validation set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c869fdf",
   "metadata": {
    "id": "4c869fdf"
   },
   "source": [
    "## 12. Train GP-VAE Model üöÄ\n",
    "\n",
    "**This is joint optimization!** Both VAE and GP are updated together each iteration.\n",
    "\n",
    "Training process per epoch:\n",
    "1. Encode images to latent codes (VAE)\n",
    "2. Compute GP prior likelihood on latents\n",
    "3. Backpropagate through joint loss\n",
    "4. Update VAE, GP, and Vmodel simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6f1485",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 673
    },
    "id": "2f6f1485",
    "outputId": "7a5c4356-23b6-4e6b-d052-2da61eaee5b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting GP-VAE Interpolation Experiment training for 1000 epochs...\n",
      "================================================================================\n",
      "Training mode: JOINT OPTIMIZATION (VAE + GP updated together)\n",
      "Experiment: Interpolation (boundaries ‚Üí intermediate)\n",
      "  Training views: [0, 1, 3, 4, 5, 7, 8]\n",
      "  Validation views: [2, 6]\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "AcceleratorError",
     "evalue": "CUDA error: device-side assert triggered\nSearch for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAcceleratorError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/content/drive/MyDrive/gppvae/GPPVAE/pysrc/faceplace/vmod.py\u001b[0m in \u001b[0;36mv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAcceleratorError\u001b[0m: CUDA error: device-side assert triggered\nSearch for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAcceleratorError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-350811431.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# 3. Compute variance matrices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mVt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mVv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# 4. Evaluate on validation set (with per-view metrics)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/drive/MyDrive/gppvae/GPPVAE/pysrc/faceplace/vmod.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, d, w)\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0;31m# Discrete indices: use embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                 \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [N, Q]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                 \u001b[0;31m# Continuous angles: compute kernel matrix on the fly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/drive/MyDrive/gppvae/GPPVAE/pysrc/faceplace/vmod.py\u001b[0m in \u001b[0;36mv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0;31m# If Cholesky fails, use eigendecomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                 \u001b[0meigvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meigvecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meigh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m                 \u001b[0meigvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meigvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meigvecs\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meigvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAcceleratorError\u001b[0m: CUDA error: device-side assert triggered\nSearch for `cudaErrorAssert' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "history = {}\n",
    "start_time = time.time()\n",
    "\n",
    "print(f\"üöÄ Starting GP-VAE Interpolation Experiment training for {CONFIG['epochs']} epochs...\")\n",
    "print(\"=\" * 80)\n",
    "print(\"Training mode: JOINT OPTIMIZATION (VAE + GP updated together)\")\n",
    "print(f\"Experiment: Interpolation (boundaries ‚Üí intermediate)\")\n",
    "print(f\"  Training views: {CONFIG.get('train_view_indices', 'all')}\")\n",
    "print(f\"  Validation views: {CONFIG.get('val_view_indices', 'all')}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for epoch in range(CONFIG['epochs']):\n",
    "    epoch_start = time.time()\n",
    "\n",
    "    # 1. Encode all training images\n",
    "    Zm, Zs = encode_Y(vae, train_queue)\n",
    "\n",
    "    # 2. Sample latent codes\n",
    "    Eps = Variable(torch.randn(*Zs.shape), requires_grad=False).cuda()\n",
    "    Z = Zm + Eps * Zs\n",
    "\n",
    "    # 3. Compute variance matrices\n",
    "    Vt = vm(Dt, Wt).detach()\n",
    "    Vv = vm(Dv, Wv).detach()\n",
    "\n",
    "    # 4. Evaluate on validation set (with per-view metrics)\n",
    "    rv_eval, imgs, covs = eval_step(vae, gp, vm, val_queue, Zm, Vt, Vv, Wv, use_angle_encoding=use_angle_encoding)\n",
    "\n",
    "    # 5. Compute GP Taylor expansion coefficients\n",
    "    Zb, Vbs, vbs, gp_nll = gp.taylor_coeff(Z, [Vt])\n",
    "    rv_eval[\"gp_nll\"] = float(gp_nll.data.mean().cpu()) / vae.K\n",
    "\n",
    "    # 6. Joint training step (VAE + GP)\n",
    "    rv_back = backprop_and_update(\n",
    "        vae, gp, vm, train_queue, Dt, Wt, Eps,\n",
    "        Zb, Vbs, vbs, vae_optimizer, gp_optimizer\n",
    "    )\n",
    "    rv_back[\"loss\"] = rv_back[\"recon_term\"] + rv_eval[\"gp_nll\"] + rv_back[\"pen_term\"]\n",
    "\n",
    "    # Store history\n",
    "    smartAppendDict(history, rv_eval)\n",
    "    smartAppendDict(history, rv_back)\n",
    "    smartAppend(history, \"vs\", gp.get_vs().data.cpu().numpy())\n",
    "\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    total_time = time.time() - start_time\n",
    "\n",
    "    # üî¨ Compute diagnostic metrics\n",
    "    train_val_gap = rv_back[\"mse\"] - rv_eval[\"mse_val\"]\n",
    "    val_out_gap = rv_eval[\"mse_out\"] - rv_eval[\"mse_val\"]\n",
    "\n",
    "    vs = gp.get_vs().data.cpu().numpy()\n",
    "    variance_ratio = vs[0] / (vs[0] + vs[1])\n",
    "\n",
    "    # Check if kernel has learnable lengthscale\n",
    "    learned_lengthscale = None\n",
    "    if hasattr(vm, 'view_kernel') and hasattr(vm.view_kernel, 'log_lengthscale'):\n",
    "        learned_lengthscale = torch.exp(vm.view_kernel.log_lengthscale).item()\n",
    "\n",
    "    # Print progress\n",
    "    if epoch % 5 == 0 or epoch == CONFIG['epochs'] - 1:\n",
    "        print(f\"Epoch {epoch:4d}/{CONFIG['epochs']} | \"\n",
    "              f\"MSE train: {rv_back['mse']:.6f} | \"\n",
    "              f\"MSE val: {rv_eval['mse_val']:.6f} | \"\n",
    "              f\"MSE out: {rv_eval['mse_out']:.6f} | \"\n",
    "              f\"GP NLL: {rv_eval['gp_nll']:.4f} | \"\n",
    "              f\"Gap(T-V): {train_val_gap:.6f} | \"\n",
    "              f\"Gap(V-O): {val_out_gap:.6f} | \"\n",
    "              f\"v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): {variance_ratio:.3f}\" +\n",
    "              (f\" | ‚Ñì: {learned_lengthscale:.3f}\" if learned_lengthscale else \"\") +\n",
    "              f\" | Time: {epoch_time:.1f}s\")\n",
    "\n",
    "        # Print per-view breakdown (Interpolation specific)\n",
    "        if CONFIG['view_split_mode'] == 'by_view' and epoch % 10 == 0:\n",
    "            if 'mse_out_per_view' in rv_eval and rv_eval['mse_out_per_view']:\n",
    "                print(\"   Per-view MSE_out (intermediate views):\")\n",
    "                # Map view indices to names\n",
    "                view_names = {0: \"90L\", 1: \"60L\", 2: \"45L\", 3: \"30L\", 4: \"00F\",\n",
    "                             5: \"30R\", 6: \"45R\", 7: \"60R\", 8: \"90R\"}\n",
    "                for view_idx in sorted(rv_eval['mse_out_per_view'].keys()):\n",
    "                    mse = rv_eval['mse_out_per_view'][view_idx]\n",
    "                    view_name = view_names.get(view_idx, f\"V{view_idx}\")\n",
    "                    print(f\"      {view_name}: {mse:.6f}\")\n",
    "\n",
    "    # Log to W&B\n",
    "    if CONFIG['use_wandb']:\n",
    "        log_dict = {\n",
    "            \"epoch\": epoch,\n",
    "            \"mse_train\": rv_back[\"mse\"],\n",
    "            \"mse_val\": rv_eval[\"mse_val\"],\n",
    "            \"mse_out\": rv_eval[\"mse_out\"],\n",
    "            \"gp_nll\": rv_eval[\"gp_nll\"],\n",
    "            \"recon_term\": rv_back[\"recon_term\"],\n",
    "            \"pen_term\": rv_back[\"pen_term\"],\n",
    "            \"loss\": rv_back[\"loss\"],\n",
    "            \"vars\": rv_eval[\"vars\"],\n",
    "            \"time/epoch_seconds\": epoch_time,\n",
    "            # üî¨ Diagnostic metrics\n",
    "            \"diagnostics/gap_train_val\": train_val_gap,\n",
    "            \"diagnostics/gap_val_out\": val_out_gap,\n",
    "            \"diagnostics/variance_ratio\": variance_ratio,\n",
    "            \"vars/v0_object\": vs[0],\n",
    "            \"vars/v1_noise\": vs[1],\n",
    "        }\n",
    "\n",
    "        # Add lengthscale if available\n",
    "        if learned_lengthscale is not None:\n",
    "            log_dict[\"kernel/lengthscale\"] = learned_lengthscale\n",
    "\n",
    "        # Add per-view metrics (Interpolation specific)\n",
    "        if 'mse_val_per_view' in rv_eval:\n",
    "            view_names = {0: \"90L\", 1: \"60L\", 2: \"45L\", 3: \"30L\", 4: \"00F\",\n",
    "                         5: \"30R\", 6: \"45R\", 7: \"60R\", 8: \"90R\"}\n",
    "            for view_idx, mse in rv_eval['mse_val_per_view'].items():\n",
    "                view_name = view_names.get(view_idx, f\"V{view_idx}\")\n",
    "                log_dict[f\"mse_val_per_view/{view_name}\"] = mse\n",
    "\n",
    "        if 'mse_out_per_view' in rv_eval:\n",
    "            view_names = {0: \"90L\", 1: \"60L\", 2: \"45L\", 3: \"30L\", 4: \"00F\",\n",
    "                         5: \"30R\", 6: \"45R\", 7: \"60R\", 8: \"90R\"}\n",
    "            for view_idx, mse in rv_eval['mse_out_per_view'].items():\n",
    "                view_name = view_names.get(view_idx, f\"V{view_idx}\")\n",
    "                log_dict[f\"mse_out_per_view/{view_name}\"] = mse\n",
    "\n",
    "        wandb.log(log_dict)\n",
    "\n",
    "    # Save checkpoint\n",
    "    if epoch % CONFIG['epoch_cb'] == 0 or epoch == CONFIG['epochs'] - 1:\n",
    "        logging.info(f\"Epoch {epoch} - saving checkpoint\")\n",
    "\n",
    "        # Save VAE weights\n",
    "        vae_file = os.path.join(wdir, f\"vae_weights.{epoch:05d}.pt\")\n",
    "        torch.save(vae.state_dict(), vae_file)\n",
    "\n",
    "        # Save GP weights\n",
    "        gp_file = os.path.join(wdir, f\"gp_weights.{epoch:05d}.pt\")\n",
    "        torch.save({\n",
    "            'gp_state': gp.state_dict(),\n",
    "            'vm_state': vm.state_dict(),\n",
    "            'gp_params': gp_params.state_dict(),\n",
    "        }, gp_file)\n",
    "\n",
    "        # Save visualization\n",
    "        ffile = os.path.join(fdir, f\"plot.{epoch:05d}.png\")\n",
    "        callback_gppvae(epoch, history, covs, imgs, ffile)\n",
    "\n",
    "        if CONFIG['use_wandb']:\n",
    "            wandb.log({\n",
    "                \"reconstructions\": wandb.Image(ffile),\n",
    "                \"covariances/XX\": wandb.Image(ffile),\n",
    "            })\n",
    "\n",
    "        print(f\"  ‚úì Checkpoint saved at epoch {epoch}\")\n",
    "\n",
    "# At the end, enhanced summary with per-view breakdown\n",
    "total_time = time.time() - start_time\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"‚úÖ GP-VAE Interpolation Experiment training complete!\")\n",
    "print(f\"   Total time: {total_time/60:.1f} minutes ({total_time/3600:.2f} hours)\")\n",
    "print(f\"   Average time per epoch: {total_time/CONFIG['epochs']:.1f} seconds\")\n",
    "print(f\"   Final training MSE: {rv_back['mse']:.6f}\")\n",
    "print(f\"   Final validation MSE: {rv_eval['mse_val']:.6f}\")\n",
    "print(f\"   Final out-of-sample MSE: {rv_eval['mse_out']:.6f}\")\n",
    "print(f\"   Final GP NLL: {rv_eval['gp_nll']:.4f}\")\n",
    "\n",
    "print(f\"\\nüî¨ Final Diagnostics:\")\n",
    "print(f\"   Train-Val Gap: {train_val_gap:.6f} (lower = less overfitting)\")\n",
    "print(f\"   Val-Out Gap: {val_out_gap:.6f} (CRITICAL for interpolation quality)\")\n",
    "print(f\"   Variance Ratio: {variance_ratio:.3f} (higher = more structure learned)\")\n",
    "if learned_lengthscale is not None:\n",
    "    print(f\"   Learned Lengthscale: {learned_lengthscale:.3f}\")\n",
    "\n",
    "# Interpolation specific: Per-view breakdown\n",
    "if CONFIG['view_split_mode'] == 'by_view' and 'mse_out_per_view' in rv_eval:\n",
    "    print(f\"\\nüìä Final Per-View MSE_out (Interpolation Test):\")\n",
    "\n",
    "    view_names = {0: \"90L (-90¬∞)\", 1: \"60L (-60¬∞)\", 2: \"45L (-45¬∞)\", 3: \"30L (-30¬∞)\",\n",
    "                 4: \"00F (0¬∞)\", 5: \"30R (+30¬∞)\", 6: \"45R (+45¬∞)\", 7: \"60R (+60¬∞)\", 8: \"90R (+90¬∞)\"}\n",
    "\n",
    "    # Separate training and validation views\n",
    "    train_view_indices = CONFIG.get('train_view_indices', [])\n",
    "    val_view_indices = CONFIG.get('val_view_indices', [])\n",
    "\n",
    "    if rv_eval['mse_out_per_view']:\n",
    "        print(\"   INTERMEDIATE VIEWS (held-out, interpolation targets):\")\n",
    "        interp_mses = []\n",
    "        for view_idx in sorted(rv_eval['mse_out_per_view'].keys()):\n",
    "            if view_idx in val_view_indices:\n",
    "                mse = rv_eval['mse_out_per_view'][view_idx]\n",
    "                interp_mses.append(mse)\n",
    "                view_name = view_names.get(view_idx, f\"V{view_idx}\")\n",
    "                print(f\"      {view_name:15s}: {mse:.6f}\")\n",
    "\n",
    "        if interp_mses:\n",
    "            avg_interp = np.mean(interp_mses)\n",
    "            print(f\"\\n   Average MSE on intermediate views: {avg_interp:.6f}\")\n",
    "            print(f\"   Overall MSE_out: {rv_eval['mse_out']:.6f}\")\n",
    "            print(f\"\\nüí° Lower MSE_out on intermediate views = better interpolation!\")\n",
    "\n",
    "if CONFIG['use_wandb']:\n",
    "    wandb.finish()\n",
    "    print(\"\\nüîó View detailed results in W&B dashboard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a98f4bc",
   "metadata": {
    "id": "9a98f4bc"
   },
   "source": [
    "## 13. Download Results\n",
    "\n",
    "Download the trained model and visualizations to your computer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337a096a",
   "metadata": {
    "id": "337a096a"
   },
   "outputs": [],
   "source": [
    "# Compress output folder\n",
    "output_zip = '/content/gppvae_output.zip'\n",
    "!zip -r {output_zip} {CONFIG['outdir']}\n",
    "\n",
    "# Download\n",
    "from google.colab import files\n",
    "print(\"Preparing download...\")\n",
    "files.download(output_zip)\n",
    "print(\"\\n‚úÖ Download started! Extract the zip on your local machine.\")\n",
    "print(f\"\\nContents include:\")\n",
    "print(f\"  - Trained VAE weights (fine-tuned)\")\n",
    "print(f\"  - GP + Vmodel weights\")\n",
    "print(f\"  - Visualization plots\")\n",
    "print(f\"  - Training logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f397bbc",
   "metadata": {
    "id": "7f397bbc"
   },
   "source": [
    "## 14. Visualize Results\n",
    "\n",
    "View the latest reconstruction and covariance plots:"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
