{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "471f6118",
   "metadata": {},
   "source": [
    "# GP-VAE Training on COIL-100 (Standard Task) - RBF-Circle Kernel\n",
    "\n",
    "This notebook trains **GP-VAE** on COIL-100 dataset using the **RBF-Circle kernel**.\n",
    "\n",
    "## Kernel: RBF-Circle\n",
    "- **RBF kernel with wrapped lag distance** for circular data\n",
    "- d(Œ∏, Œ∏') = min(|Œ∏ - Œ∏'|, 360 - |Œ∏ - Œ∏'|) ‚Äî respects circular geometry\n",
    "- k(Œ∏, Œ∏') = variance √ó exp(-d¬≤ / (2 √ó lengthscale¬≤))\n",
    "- **Parameters**: 2 learnable (lengthscale, variance)\n",
    "- **Best for**: Smooth correlations that respect rotation geometry\n",
    "\n",
    "## Dataset Info:\n",
    "- **COIL-100**: 100 objects √ó 18 views (every 20¬∞: 0¬∞, 20¬∞, ..., 340¬∞)\n",
    "- **Image size**: 128√ó128√ó3 RGB\n",
    "- **Task**: Standard split (random train/val/test)\n",
    "\n",
    "## Prerequisites:\n",
    "- ‚úÖ Trained VAE weights from `train_vae_colab_standard.ipynb`\n",
    "- ‚úÖ COIL-100 data file: `data/coil100/coil100_task1_standard.h5`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c673419b",
   "metadata": {},
   "source": [
    "## 1. Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f20587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è WARNING: GPU not detected!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c330c74f",
   "metadata": {},
   "source": [
    "## 2. Auto-Detect Project Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6eb92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "print(f\"üìç Current directory: {current_dir}\")\n",
    "\n",
    "# Task configuration\n",
    "DATA_TASK = \"task1_standard\"\n",
    "KERNEL_TYPE = \"rbf_circle\"\n",
    "\n",
    "if current_dir == '/content':\n",
    "    print(\"\\nüîÑ Mounting Google Drive...\")\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        drive_path = '/content/drive/MyDrive/gppvae'\n",
    "        if os.path.exists(drive_path):\n",
    "            PROJECT_PATH = drive_path\n",
    "            print(f\"‚úÖ Found project in Google Drive: {PROJECT_PATH}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Project not found at: {drive_path}\")\n",
    "            PROJECT_PATH = '/content'\n",
    "    except Exception as e:\n",
    "        print(f\"Could not mount Drive: {e}\")\n",
    "        PROJECT_PATH = '/content'\n",
    "else:\n",
    "    if 'notebooks' in current_dir:\n",
    "        PROJECT_PATH = os.path.dirname(current_dir)\n",
    "    else:\n",
    "        PROJECT_PATH = current_dir\n",
    "    print(f\"üíª Using project path: {PROJECT_PATH}\")\n",
    "\n",
    "# Check required files\n",
    "print(f\"\\nüîç Checking required files:\")\n",
    "data_path = os.path.join(PROJECT_PATH, f'data/coil100/coil100_{DATA_TASK}.h5')\n",
    "required = {\n",
    "    'GPPVAE code': os.path.exists(os.path.join(PROJECT_PATH, 'GPPVAE')),\n",
    "    'COIL-100 data': os.path.exists(data_path),\n",
    "}\n",
    "\n",
    "vae_base_dir = os.path.join(PROJECT_PATH, f'out/vae_colab_{DATA_TASK}_standard')\n",
    "vae_run_found = False\n",
    "if os.path.exists(vae_base_dir):\n",
    "    runs = [d for d in os.listdir(vae_base_dir) if os.path.isdir(os.path.join(vae_base_dir, d))]\n",
    "    for run in runs:\n",
    "        weights_dir = os.path.join(vae_base_dir, run, 'weights')\n",
    "        if os.path.exists(weights_dir) and any(f.endswith('.pt') for f in os.listdir(weights_dir)):\n",
    "            vae_run_found = True\n",
    "            break\n",
    "required['VAE weights'] = vae_run_found\n",
    "\n",
    "for name, exists in required.items():\n",
    "    status = \"‚úÖ\" if exists else \"‚ùå\"\n",
    "    print(f\"   {status} {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f55e9f9",
   "metadata": {},
   "source": [
    "## 3. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d5a302",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q wandb==0.12.21 imageio==2.15.0 pyyaml\n",
    "\n",
    "import wandb\n",
    "import numpy as np\n",
    "print(\"‚úÖ All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6aec456",
   "metadata": {},
   "source": [
    "## 4. Login to W&B (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6735b383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e764752",
   "metadata": {},
   "source": [
    "## 5. Navigate to Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73ee6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir(PROJECT_PATH)\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "\n",
    "sys.path.insert(0, os.path.join(PROJECT_PATH, 'GPPVAE/pysrc/coil100'))\n",
    "sys.path.insert(0, os.path.join(PROJECT_PATH, 'GPPVAE/pysrc/faceplace'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2c46b8",
   "metadata": {},
   "source": [
    "## 6. Find VAE Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a0b94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "vae_base_dir = f'./out/vae_colab_{DATA_TASK}_standard'\n",
    "vae_runs = []\n",
    "\n",
    "if os.path.exists(vae_base_dir):\n",
    "    for run_dir in sorted(os.listdir(vae_base_dir), reverse=True):\n",
    "        run_path = os.path.join(vae_base_dir, run_dir)\n",
    "        cfg_path = os.path.join(run_path, 'vae.cfg.p')\n",
    "        weights_dir = os.path.join(run_path, 'weights')\n",
    "        \n",
    "        if os.path.exists(cfg_path) and os.path.exists(weights_dir):\n",
    "            weight_files = sorted([f for f in os.listdir(weights_dir) if f.endswith('.pt')])\n",
    "            if weight_files:\n",
    "                vae_runs.append({\n",
    "                    'run_dir': run_dir,\n",
    "                    'cfg_path': cfg_path,\n",
    "                    'weights_dir': weights_dir,\n",
    "                    'weight_files': weight_files\n",
    "                })\n",
    "\n",
    "if vae_runs:\n",
    "    print(f\"‚úÖ Found {len(vae_runs)} VAE run(s)\")\n",
    "    latest = vae_runs[0]\n",
    "    print(f\"\\nüí° Latest: {latest['run_dir']}\")\n",
    "    print(f\"   VAE_CFG = '{latest['cfg_path']}'\")\n",
    "    print(f\"   VAE_WEIGHTS = '{os.path.join(latest['weights_dir'], latest['weight_files'][-1])}'\")\n",
    "else:\n",
    "    print(\"‚ùå No VAE runs found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6efd54",
   "metadata": {},
   "source": [
    "## 7. Configure Training\n",
    "\n",
    "**RBF-Circle Kernel Parameters:**\n",
    "- `lengthscale`: Controls smoothness (larger = smoother). Default: 30¬∞ (1.5 steps)\n",
    "- `variance`: Signal variance. Default: 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ec62eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# ============================================================================\n",
    "# UPDATE THESE PATHS!\n",
    "# ============================================================================\n",
    "VAE_CFG = './out/vae_colab_task1_standard_standard/YYYYMMDD_HHMMSS/vae.cfg.p'  # UPDATE\n",
    "VAE_WEIGHTS = './out/vae_colab_task1_standard_standard/YYYYMMDD_HHMMSS/weights/weights.00499.pt'  # UPDATE\n",
    "\n",
    "CONFIG = {\n",
    "    # Data\n",
    "    'data': f'./data/coil100/coil100_{DATA_TASK}.h5',\n",
    "    'outdir': f'./out/gppvae_coil100_{KERNEL_TYPE}_{DATA_TASK}/{timestamp}',\n",
    "    \n",
    "    # VAE\n",
    "    'vae_cfg': VAE_CFG,\n",
    "    'vae_weights': VAE_WEIGHTS,\n",
    "    \n",
    "    # Training\n",
    "    'epochs': 500,\n",
    "    'batch_size': 64,\n",
    "    'vae_lr': 0.001,\n",
    "    'gp_lr': 0.001,\n",
    "    'xdim': 64,\n",
    "    \n",
    "    # Kernel - RBF-Circle with wrapped distance\n",
    "    'view_kernel': KERNEL_TYPE,\n",
    "    'kernel_kwargs': {\n",
    "        'lengthscale': 30.0,  # 30 degrees (1.5 view steps)\n",
    "        'variance': 1.0,\n",
    "    },\n",
    "    \n",
    "    # Logging\n",
    "    'epoch_cb': 100,\n",
    "    'use_wandb': True,\n",
    "    'wandb_project': 'gppvae-coil100',\n",
    "    'wandb_run_name': f'gppvae_{KERNEL_TYPE}_{DATA_TASK}_{timestamp}',\n",
    "    'seed': 0,\n",
    "}\n",
    "\n",
    "print(\"GP-VAE Training Configuration:\")\n",
    "print(\"=\" * 60)\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key:20s}: {value}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if not os.path.exists(CONFIG['vae_weights']):\n",
    "    print(f\"\\n‚ö†Ô∏è Update VAE_CFG and VAE_WEIGHTS paths!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacd3c6f",
   "metadata": {},
   "source": [
    "## 8. Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6dfe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Add coil100 to path FIRST before importing anything\n",
    "# This ensures coil100's data_parser is used, not faceplace's\n",
    "import sys\n",
    "import os\n",
    "\n",
    "coil100_path = os.path.join(PROJECT_PATH, 'GPPVAE/pysrc/coil100')\n",
    "if coil100_path not in sys.path:\n",
    "    sys.path.insert(0, coil100_path)\n",
    "\n",
    "os.chdir(coil100_path)\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from vae import FaceVAE\n",
    "from vmod import Vmodel\n",
    "from gp import GP\n",
    "import numpy as np\n",
    "import logging\n",
    "import pylab as pl\n",
    "from utils import smartSum, smartAppendDict, smartAppend, export_scripts\n",
    "from callbacks import callback_gppvae\n",
    "import pickle\n",
    "import time\n",
    "import wandb\n",
    "\n",
    "# COIL-100 data parser (explicitly import from coil100, not faceplace)\n",
    "from data_parser import COIL100Dataset, get_n_views, get_num_objects\n",
    "\n",
    "# Verify we're using the right data_parser\n",
    "import data_parser\n",
    "print(f\"‚úÖ data_parser loaded from: {data_parser.__file__}\")\n",
    "if 'coil100' in data_parser.__file__:\n",
    "    print(\"‚úÖ Using COIL-100 data_parser (correct!)\")\n",
    "else:\n",
    "    print(\"‚ùå WARNING: Using faceplace data_parser (wrong!)\")\n",
    "print(\"‚úÖ All modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa50b35",
   "metadata": {},
   "source": [
    "## 9. Setup Training Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16464e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(PROJECT_PATH)\n",
    "\n",
    "outdir = CONFIG['outdir']\n",
    "wdir = os.path.join(outdir, \"weights\")\n",
    "fdir = os.path.join(outdir, \"plots\")\n",
    "os.makedirs(wdir, exist_ok=True)\n",
    "os.makedirs(fdir, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "log_format = \"%(asctime)s %(message)s\"\n",
    "logging.basicConfig(level=logging.INFO, format=log_format, datefmt=\"%m/%d %I:%M:%S %p\")\n",
    "fh = logging.FileHandler(os.path.join(outdir, \"log.txt\"))\n",
    "fh.setFormatter(logging.Formatter(log_format))\n",
    "logging.getLogger().addHandler(fh)\n",
    "\n",
    "export_scripts(os.path.join(outdir, \"scripts\"))\n",
    "print(f\"‚úÖ Output: {outdir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dbd8c8",
   "metadata": {},
   "source": [
    "## 10. Initialize Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf34316",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(CONFIG['seed'])\n",
    "\n",
    "if CONFIG['use_wandb']:\n",
    "    wandb.init(project=CONFIG['wandb_project'], name=CONFIG['wandb_run_name'], config=CONFIG)\n",
    "\n",
    "# Load VAE\n",
    "vae_cfg = pickle.load(open(CONFIG['vae_cfg'], \"rb\"))\n",
    "vae = FaceVAE(**vae_cfg).to(device)\n",
    "vae.load_state_dict(torch.load(CONFIG['vae_weights'], map_location=device))\n",
    "print(f\"‚úÖ VAE loaded\")\n",
    "\n",
    "# Load data\n",
    "train_data = COIL100Dataset(CONFIG['data'], split='train', use_angle_encoding=False)\n",
    "val_data = COIL100Dataset(CONFIG['data'], split='val', use_angle_encoding=False)\n",
    "train_queue = DataLoader(train_data, batch_size=CONFIG['batch_size'], shuffle=True)\n",
    "val_queue = DataLoader(val_data, batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "\n",
    "# IMPORTANT: Use get_num_objects for correct P (includes all objects from all splits)\n",
    "P = get_num_objects(CONFIG['data'])  # 100 for COIL-100\n",
    "Q = get_n_views()\n",
    "print(f\"P={P}, Q={Q}\")\n",
    "\n",
    "Dt = Variable(train_data.Did.long(), requires_grad=False).to(device)\n",
    "Dv = Variable(val_data.Did.long(), requires_grad=False).to(device)\n",
    "Wt = Variable(train_data.Rid.long(), requires_grad=False).to(device)\n",
    "Wv = Variable(val_data.Rid.long(), requires_grad=False).to(device)\n",
    "\n",
    "# Initialize Vmodel with RBF-Circle kernel\n",
    "print(f\"\\nüî¨ Initializing '{KERNEL_TYPE}' kernel...\")\n",
    "vm = Vmodel(P=P, Q=Q, p=CONFIG['xdim'], view_kernel=CONFIG['view_kernel'], **CONFIG['kernel_kwargs']).to(device)\n",
    "gp = GP(n_rand_effs=1).to(device)\n",
    "\n",
    "# Show kernel matrix\n",
    "K = vm.get_kernel_matrix()\n",
    "print(f\"   K[0,0]={K[0,0].item():.4f} (self)\")\n",
    "print(f\"   K[0,1]={K[0,1].item():.4f} (20¬∞ apart)\")\n",
    "print(f\"   K[0,9]={K[0,9].item():.4f} (180¬∞ apart)\")\n",
    "print(f\"   K[0,17]={K[0,17].item():.4f} (340¬∞=20¬∞ wrapped)\")\n",
    "\n",
    "gp_params = nn.ParameterList()\n",
    "gp_params.extend(vm.parameters())\n",
    "gp_params.extend(gp.parameters())\n",
    "\n",
    "vae_optimizer = optim.Adam(vae.parameters(), lr=CONFIG['vae_lr'])\n",
    "gp_optimizer = optim.Adam(gp_params, lr=CONFIG['gp_lr'])\n",
    "print(f\"\\n‚úÖ Models initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5e74e5",
   "metadata": {},
   "source": [
    "## 11. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77c269f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_Y(vae, train_queue):\n",
    "    vae.eval()\n",
    "    with torch.no_grad():\n",
    "        n = train_queue.dataset.Y.shape[0]\n",
    "        Zm = Variable(torch.zeros(n, vae_cfg[\"zdim\"]), requires_grad=False).to(device)\n",
    "        Zs = Variable(torch.zeros(n, vae_cfg[\"zdim\"]), requires_grad=False).to(device)\n",
    "        for data in train_queue:\n",
    "            y = data[0].to(device)\n",
    "            idxs = data[-1].to(device)\n",
    "            zm, zs = vae.encode(y)\n",
    "            Zm[idxs], Zs[idxs] = zm.detach(), zs.detach()\n",
    "    return Zm, Zs\n",
    "\n",
    "def eval_step(vae, gp, vm, val_queue, Zm, Vt, Vv, Wv):\n",
    "    rv = {}\n",
    "    with torch.no_grad():\n",
    "        _X = vm.x().data.cpu().numpy()\n",
    "        _W = vm.v().data.cpu().numpy()\n",
    "        covs = {\"XX\": np.dot(_X, _X.T), \"WW\": np.dot(_W, _W.T)}\n",
    "        rv[\"vars\"] = gp.get_vs().data.cpu().numpy()\n",
    "        \n",
    "        vs = gp.get_vs()\n",
    "        U, UBi, _ = gp.U_UBi_Shb([Vt], vs)\n",
    "        Kiz = gp.solve(Zm, U, UBi, vs)\n",
    "        Zo = vs[0] * Vv.mm(Vt.transpose(0, 1).mm(Kiz))\n",
    "        \n",
    "        mse_out = Variable(torch.zeros(Vv.shape[0], 1), requires_grad=False).to(device)\n",
    "        mse_val = Variable(torch.zeros(Vv.shape[0], 1), requires_grad=False).to(device)\n",
    "        all_Yv, all_Yr, all_Yo = [], [], []\n",
    "        \n",
    "        for data in val_queue:\n",
    "            idxs = data[-1].to(device)\n",
    "            Yv = data[0].to(device)\n",
    "            Zv = vae.encode(Yv)[0].detach()\n",
    "            Yr = vae.decode(Zv)\n",
    "            Yo = vae.decode(Zo[idxs])\n",
    "            mse_out[idxs] = ((Yv - Yo) ** 2).view(Yv.shape[0], -1).mean(1)[:, None].detach()\n",
    "            mse_val[idxs] = ((Yv - Yr) ** 2).view(Yv.shape[0], -1).mean(1)[:, None].detach()\n",
    "            all_Yv.append(Yv.data.cpu().numpy().transpose(0, 2, 3, 1))\n",
    "            all_Yr.append(Yr.data.cpu().numpy().transpose(0, 2, 3, 1))\n",
    "            all_Yo.append(Yo.data.cpu().numpy().transpose(0, 2, 3, 1))\n",
    "        \n",
    "        all_Yv = np.concatenate(all_Yv, axis=0)\n",
    "        all_Yr = np.concatenate(all_Yr, axis=0)\n",
    "        all_Yo = np.concatenate(all_Yo, axis=0)\n",
    "        n_total = all_Yv.shape[0]\n",
    "        sample_indices = np.arange(0, n_total, max(1, n_total // 24))[:24]\n",
    "        imgs = {\"Yv\": all_Yv[sample_indices], \"Yr\": all_Yr[sample_indices], \"Yo\": all_Yo[sample_indices]}\n",
    "        rv[\"mse_out\"] = float(mse_out.data.mean().cpu())\n",
    "        rv[\"mse_val\"] = float(mse_val.data.mean().cpu())\n",
    "    return rv, imgs, covs\n",
    "\n",
    "def backprop_and_update(vae, gp, vm, train_queue, Dt, Wt, Eps, Zb, Vbs, vbs, vae_optimizer, gp_optimizer):\n",
    "    rv = {}\n",
    "    vae_optimizer.zero_grad()\n",
    "    gp_optimizer.zero_grad()\n",
    "    vae.train(); gp.train(); vm.train()\n",
    "    \n",
    "    for data in train_queue:\n",
    "        y = data[0].to(device)\n",
    "        eps = Eps[data[-1]]\n",
    "        _d, _w = Dt[data[-1]], Wt[data[-1]]\n",
    "        _Zb = Zb[data[-1]]\n",
    "        _Vbs = [Vbs[0][data[-1]]]\n",
    "        \n",
    "        zm, zs = vae.encode(y)\n",
    "        z = zm + zs * eps\n",
    "        yr = vae.decode(z)\n",
    "        recon_term, mse = vae.nll(y, yr)\n",
    "        \n",
    "        _Vs = [vm(_d, _w)]\n",
    "        gp_nll_fo = gp.taylor_expansion(z, _Vs, _Zb, _Vbs, vbs) / vae.K\n",
    "        pen_term = -0.5 * zs.sum(1)[:, None] / vae.K\n",
    "        \n",
    "        loss = (recon_term + gp_nll_fo + pen_term).sum()\n",
    "        loss.backward()\n",
    "        \n",
    "        _n = train_queue.dataset.Y.shape[0]\n",
    "        smartSum(rv, \"mse\", float(mse.data.sum().cpu()) / _n)\n",
    "        smartSum(rv, \"recon_term\", float(recon_term.data.sum().cpu()) / _n)\n",
    "        smartSum(rv, \"pen_term\", float(pen_term.data.sum().cpu()) / _n)\n",
    "    \n",
    "    vae_optimizer.step()\n",
    "    gp_optimizer.step()\n",
    "    return rv\n",
    "\n",
    "print(\"‚úÖ Training functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ef2b90",
   "metadata": {},
   "source": [
    "## 12. Train GP-VAE üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d426ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {}\n",
    "start_time = time.time()\n",
    "\n",
    "print(f\"üöÄ Training GP-VAE with {KERNEL_TYPE} kernel for {CONFIG['epochs']} epochs...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for epoch in range(CONFIG['epochs']):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    Zm, Zs = encode_Y(vae, train_queue)\n",
    "    Eps = Variable(torch.randn(*Zs.shape), requires_grad=False).to(device)\n",
    "    Z = Zm + Eps * Zs\n",
    "    \n",
    "    Vt = vm(Dt, Wt).detach()\n",
    "    Vv = vm(Dv, Wv).detach()\n",
    "    \n",
    "    rv_eval, imgs, covs = eval_step(vae, gp, vm, val_queue, Zm, Vt, Vv, Wv)\n",
    "    Zb, Vbs, vbs, gp_nll = gp.taylor_coeff(Z, [Vt])\n",
    "    rv_eval[\"gp_nll\"] = float(gp_nll.data.mean().cpu()) / vae.K\n",
    "    \n",
    "    rv_back = backprop_and_update(vae, gp, vm, train_queue, Dt, Wt, Eps, Zb, Vbs, vbs, vae_optimizer, gp_optimizer)\n",
    "    rv_back[\"loss\"] = rv_back[\"recon_term\"] + rv_eval[\"gp_nll\"] + rv_back[\"pen_term\"]\n",
    "    \n",
    "    smartAppendDict(history, rv_eval)\n",
    "    smartAppendDict(history, rv_back)\n",
    "    smartAppend(history, \"vs\", gp.get_vs().data.cpu().numpy())\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    vs = gp.get_vs().data.cpu().numpy()\n",
    "    variance_ratio = vs[0] / (vs[0] + vs[1])\n",
    "    \n",
    "    # Get learned lengthscale\n",
    "    learned_ls = vm.kernel.lengthscale.item()\n",
    "    \n",
    "    if epoch % 5 == 0 or epoch == CONFIG['epochs'] - 1:\n",
    "        print(f\"Epoch {epoch:4d} | MSE: {rv_back['mse']:.6f} | Out: {rv_eval['mse_out']:.6f} | \"\n",
    "              f\"GP NLL: {rv_eval['gp_nll']:.4f} | ‚Ñì: {learned_ls:.1f}¬∞ | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): {variance_ratio:.3f}\")\n",
    "    \n",
    "    if CONFIG['use_wandb']:\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch, \"mse_train\": rv_back[\"mse\"], \"mse_out\": rv_eval[\"mse_out\"],\n",
    "            \"gp_nll\": rv_eval[\"gp_nll\"], \"lengthscale\": learned_ls, \"variance_ratio\": variance_ratio,\n",
    "        })\n",
    "    \n",
    "    if epoch % CONFIG['epoch_cb'] == 0 or epoch == CONFIG['epochs'] - 1:\n",
    "        torch.save(vae.state_dict(), os.path.join(wdir, f\"vae_weights.{epoch:05d}.pt\"))\n",
    "        torch.save({'gp_state': gp.state_dict(), 'vm_state': vm.state_dict()}, \n",
    "                   os.path.join(wdir, f\"gp_weights.{epoch:05d}.pt\"))\n",
    "        ffile = os.path.join(fdir, f\"plot.{epoch:05d}.png\")\n",
    "        callback_gppvae(epoch, history, covs, imgs, ffile)\n",
    "        if CONFIG['use_wandb']:\n",
    "            wandb.log({\"reconstructions\": wandb.Image(ffile)})\n",
    "        print(f\"  ‚úì Checkpoint saved\")\n",
    "\n",
    "print(f\"\\n‚úÖ Complete! Time: {(time.time()-start_time)/60:.1f}min, Final MSE out: {rv_eval['mse_out']:.6f}\")\n",
    "print(f\"   Learned lengthscale: {learned_ls:.1f}¬∞\")\n",
    "if CONFIG['use_wandb']: wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c07c780",
   "metadata": {},
   "source": [
    "## 13. View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314c7462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import glob\n",
    "\n",
    "plot_files = sorted(glob.glob(os.path.join(fdir, \"*.png\")))\n",
    "if plot_files:\n",
    "    display(Image(filename=plot_files[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad4ed4b",
   "metadata": {},
   "source": [
    "## 14. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5222f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r /content/gppvae_rbf_circle_output.zip {CONFIG['outdir']}\n",
    "from google.colab import files\n",
    "files.download('/content/gppvae_rbf_circle_output.zip')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
