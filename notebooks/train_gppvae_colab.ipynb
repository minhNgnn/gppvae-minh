{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50651924",
   "metadata": {},
   "source": [
    "## 9b. Diagnostic: Check for scipy imports\n",
    "\n",
    "Run this to see if scipy is still being imported (either explicitly or via cupyx):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8a173e",
   "metadata": {
    "id": "0f8a173e"
   },
   "source": [
    "# GP-VAE Training on Google Colab\n",
    "\n",
    "This notebook trains the **GP-VAE (Gaussian Process Variational Autoencoder)** model using Google Colab's free GPU.\n",
    "\n",
    "## What is GP-VAE?\n",
    "GP-VAE adds a **Gaussian Process prior** to the VAE latent space to model structured correlations:\n",
    "- **VAE**: Learns image â†” latent code mapping\n",
    "- **GP Prior**: Models correlations between latent codes based on:\n",
    "  - Object identity (same person's face)\n",
    "  - View angle (front, side, profile)\n",
    "  - Other factors of variation\n",
    "\n",
    "## Prerequisites âš ï¸\n",
    "**You MUST have trained VAE weights first!** This model loads pre-trained VAE and fine-tunes it jointly with the GP.\n",
    "\n",
    "Required files:\n",
    "- âœ… `out/vae_colab/YYYYMMDD_HHMMSS/vae.cfg.p` - VAE configuration\n",
    "- âœ… `out/vae_colab/YYYYMMDD_HHMMSS/weights/weights.00000.pt` - Trained VAE weights\n",
    "\n",
    "## Output Directory Structure:\n",
    "\n",
    "Each training run creates a **timestamped directory** to avoid overwriting previous runs:\n",
    "- Format: `./out/gppvae_colab/YYYYMMDD_HHMMSS/`\n",
    "- Example: `./out/gppvae_colab/20251224_143530/weights/weights.00100.pt`\n",
    "- This allows you to compare different training runs and keep a history!\n",
    "\n",
    "Cell 6 below will automatically find your latest VAE training run.\n",
    "\n",
    "## Setup Instructions:\n",
    "\n",
    "1. **Open this notebook in VS Code**\n",
    "2. **Connect to Colab**: Click kernel picker â†’ \"Connect to Colab\" â†’ Choose **GPU runtime (T4)**\n",
    "3. **Important**: When prompted with \"Alias your server\", press Enter\n",
    "4. **Run cell 2** - it will automatically detect your project location\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d4d88e",
   "metadata": {
    "id": "a7d4d88e"
   },
   "source": [
    "## 1. Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9450aba9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9450aba9",
    "outputId": "4829818c-c509-4940-b6e7-7d680c601696"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.0+cu126\n",
      "CUDA available: True\n",
      "GPU Device: Tesla T4\n",
      "GPU Memory: 15.83 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"âš ï¸ WARNING: GPU not detected! Go to Runtime â†’ Change runtime type â†’ GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a792140f",
   "metadata": {
    "id": "a792140f"
   },
   "source": [
    "## 2. Auto-Detect Project Path\n",
    "\n",
    "This automatically finds your project files on the Colab runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33fa06a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33fa06a0",
    "outputId": "4596e88c-da94-40c2-f618-4e15d04c4241"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Current directory: /content\n",
      "\n",
      "ğŸ”„ Mounting Google Drive...\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "âœ… Found project in Google Drive: /content/drive/MyDrive/gppvae\n",
      "\n",
      "ğŸ“ Contents of /content/drive/MyDrive/gppvae:\n",
      "   ğŸ“‚ GPPVAE/\n",
      "   ğŸ“‚ data/\n",
      "   ğŸ“„ environment.yml\n",
      "   ğŸ“‚ notebooks/\n",
      "   ğŸ“‚ out/\n",
      "\n",
      "ğŸ” Checking required files:\n",
      "   âœ… GPPVAE code\n",
      "   âœ… data/faceplace\n",
      "   âœ… data_faces.h5\n",
      "   âœ… VAE config\n",
      "   âœ… VAE weights\n",
      "\n",
      "ğŸ“¦ Found 1 VAE training run(s):\n",
      "   1. 20251224_120136/ (16 checkpoints)\n",
      "      Latest: weights.00140.pt\n",
      "\n",
      "ğŸ’¡ Cell 6 below will help you choose which run to use\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Get current directory\n",
    "current_dir = os.getcwd()\n",
    "print(f\"ğŸ“ Current directory: {current_dir}\")\n",
    "\n",
    "# Check if on Colab and need to mount Drive\n",
    "if current_dir == '/content':\n",
    "    print(\"\\nğŸ”„ Mounting Google Drive...\")\n",
    "\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "\n",
    "        # Check for project in Drive\n",
    "        drive_path = '/content/drive/MyDrive/gppvae'\n",
    "        if os.path.exists(drive_path):\n",
    "            PROJECT_PATH = drive_path\n",
    "            print(f\"âœ… Found project in Google Drive: {PROJECT_PATH}\")\n",
    "        else:\n",
    "            print(f\"\\nâš ï¸  Project not found at: {drive_path}\")\n",
    "            print(\"\\nPlease upload your gppvae folder to Google Drive!\")\n",
    "            print(\"Required structure:\")\n",
    "            print(\"  MyDrive/gppvae/\")\n",
    "            print(\"    â”œâ”€â”€ GPPVAE/\")\n",
    "            print(\"    â”œâ”€â”€ data/faceplace/data_faces.h5\")\n",
    "            print(\"    â””â”€â”€ out/vae_colab/YYYYMMDD_HHMMSS/\")\n",
    "            print(\"        â”œâ”€â”€ vae.cfg.p\")\n",
    "            print(\"        â””â”€â”€ weights/weights.00000.pt\")\n",
    "            PROJECT_PATH = '/content'\n",
    "    except Exception as e:\n",
    "        print(f\"Could not mount Drive: {e}\")\n",
    "        PROJECT_PATH = '/content'\n",
    "else:\n",
    "    # Running via VS Code sync\n",
    "    if 'notebooks' in current_dir:\n",
    "        PROJECT_PATH = os.path.dirname(current_dir)\n",
    "    else:\n",
    "        PROJECT_PATH = current_dir\n",
    "    print(f\"ğŸ’» Using project path: {PROJECT_PATH}\")\n",
    "\n",
    "# Verify structure\n",
    "print(f\"\\nğŸ“ Contents of {PROJECT_PATH}:\")\n",
    "if os.path.exists(PROJECT_PATH):\n",
    "    items = os.listdir(PROJECT_PATH)\n",
    "    for item in sorted(items)[:15]:\n",
    "        item_path = os.path.join(PROJECT_PATH, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            print(f\"   ğŸ“‚ {item}/\")\n",
    "        else:\n",
    "            print(f\"   ğŸ“„ {item}\")\n",
    "\n",
    "    # Check required files (with timestamped directory structure)\n",
    "    print(f\"\\nğŸ” Checking required files:\")\n",
    "    required = {\n",
    "        'GPPVAE code': os.path.exists(os.path.join(PROJECT_PATH, 'GPPVAE')),\n",
    "        'data/faceplace': os.path.exists(os.path.join(PROJECT_PATH, 'data/faceplace')),\n",
    "        'data_faces.h5': os.path.exists(os.path.join(PROJECT_PATH, 'data/faceplace/data_faces.h5')),\n",
    "    }\n",
    "\n",
    "    # Check for VAE runs (timestamped subdirectories)\n",
    "    vae_base_dir = os.path.join(PROJECT_PATH, 'out/vae_colab')\n",
    "    vae_run_found = False\n",
    "    vae_weights_found = False\n",
    "\n",
    "    if os.path.exists(vae_base_dir):\n",
    "        # Look for timestamped subdirectories\n",
    "        potential_runs = [d for d in os.listdir(vae_base_dir)\n",
    "                         if os.path.isdir(os.path.join(vae_base_dir, d)) and d[0].isdigit()]\n",
    "\n",
    "        for run_dir in potential_runs:\n",
    "            run_path = os.path.join(vae_base_dir, run_dir)\n",
    "            cfg_path = os.path.join(run_path, 'vae.cfg.p')\n",
    "            weights_dir = os.path.join(run_path, 'weights')\n",
    "\n",
    "            if os.path.exists(cfg_path):\n",
    "                vae_run_found = True\n",
    "\n",
    "            if os.path.exists(weights_dir):\n",
    "                weight_files = [f for f in os.listdir(weights_dir) if f.endswith('.pt')]\n",
    "                if weight_files:\n",
    "                    vae_weights_found = True\n",
    "                    break\n",
    "\n",
    "    required['VAE config'] = vae_run_found\n",
    "    required['VAE weights'] = vae_weights_found\n",
    "\n",
    "    for name, exists in required.items():\n",
    "        status = \"âœ…\" if exists else \"âŒ\"\n",
    "        print(f\"   {status} {name}\")\n",
    "\n",
    "    # Show VAE runs if they exist\n",
    "    if os.path.exists(vae_base_dir):\n",
    "        potential_runs = sorted([d for d in os.listdir(vae_base_dir)\n",
    "                                if os.path.isdir(os.path.join(vae_base_dir, d)) and d[0].isdigit()],\n",
    "                               reverse=True)\n",
    "\n",
    "        if potential_runs:\n",
    "            print(f\"\\nğŸ“¦ Found {len(potential_runs)} VAE training run(s):\")\n",
    "            for i, run_dir in enumerate(potential_runs[:3], 1):  # Show latest 3\n",
    "                run_path = os.path.join(vae_base_dir, run_dir)\n",
    "                weights_dir = os.path.join(run_path, 'weights')\n",
    "\n",
    "                if os.path.exists(weights_dir):\n",
    "                    weight_files = sorted([f for f in os.listdir(weights_dir) if f.endswith('.pt')])\n",
    "                    print(f\"   {i}. {run_dir}/ ({len(weight_files)} checkpoints)\")\n",
    "                    if weight_files:\n",
    "                        print(f\"      Latest: {weight_files[-1]}\")\n",
    "\n",
    "            if len(potential_runs) > 3:\n",
    "                print(f\"   ... and {len(potential_runs) - 3} more\")\n",
    "\n",
    "            print(f\"\\nğŸ’¡ Cell 6 below will help you choose which run to use\")\n",
    "\n",
    "    if not all(required.values()):\n",
    "        print(f\"\\nâš ï¸  Missing required files!\")\n",
    "        if not required['VAE weights']:\n",
    "            print(\"\\nğŸš¨ CRITICAL: No trained VAE weights found!\")\n",
    "            print(\"   You must train VAE first before running GP-VAE\")\n",
    "            print(\"   Use the train_vae_colab.ipynb notebook\")\n",
    "else:\n",
    "    print(f\"âŒ Path doesn't exist: {PROJECT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd61ed4d",
   "metadata": {
    "id": "dd61ed4d"
   },
   "source": [
    "## 3. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eb3366a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5eb3366a",
    "outputId": "9ed6dc98-5815-4968-adba-917966843362"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31mÃ—\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31mÃ—\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "âœ… All dependencies installed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install -q wandb==0.12.21 imageio==2.15.0 pyyaml\n",
    "\n",
    "# Verify installations\n",
    "import wandb\n",
    "import imageio\n",
    "import yaml\n",
    "import numpy as np\n",
    "print(\"âœ… All dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428e2eb3",
   "metadata": {
    "id": "428e2eb3"
   },
   "source": [
    "## 4. Login to Weights & Biases (Optional)\n",
    "\n",
    "Track your experiments with W&B for better monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a116fb79",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a116fb79",
    "outputId": "a1620602-7496-4c28-ad9f-51a381c68ecd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminh1008\u001b[0m (\u001b[33mminh1008-ludwig-maximilianuniversity-of-munich\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "# Or run offline without W&B:\n",
    "# import os\n",
    "# os.environ['WANDB_MODE'] = 'offline'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064cf6ef",
   "metadata": {
    "id": "064cf6ef"
   },
   "source": [
    "## 5. Navigate to Project Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9ddd5a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9ddd5a1",
    "outputId": "07d1b73e-e7c0-4d1e-c04b-916a8d5bf3cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /content/drive/MyDrive/gppvae\n",
      "\n",
      "Project structure:\n",
      "total 17\n",
      "drwx------ 3 root root 4096 Dec 23 14:09 data\n",
      "-rw------- 1 root root  258 Dec 23 11:40 environment.yml\n",
      "drwx------ 3 root root 4096 Dec 23 14:09 GPPVAE\n",
      "drwx------ 2 root root 4096 Dec 23 14:09 notebooks\n",
      "drwx------ 4 root root 4096 Dec 23 14:21 out\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir(PROJECT_PATH)\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "\n",
    "# Add to Python path\n",
    "sys.path.insert(0, os.path.join(PROJECT_PATH, 'GPPVAE/pysrc/faceplace'))\n",
    "\n",
    "print(\"\\nProject structure:\")\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638c36f7",
   "metadata": {
    "id": "638c36f7"
   },
   "source": [
    "## 6. Verify VAE Weights\n",
    "\n",
    "**Critical check:** Make sure you have trained VAE weights!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26a9a8de",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "26a9a8de",
    "outputId": "f3e09e36-726b-4026-e081-4cda0216f64c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Found 1 VAE training run(s):\n",
      "\n",
      "Run 1: 20251224_120136\n",
      "   Config: zdim=256, nf=32\n",
      "   Checkpoints: 16 files\n",
      "      ğŸ“¦ weights.00000.pt ... weights.00140.pt\n",
      "\n",
      "ğŸ’¡ Recommendation:\n",
      "   Use latest run: 20251224_120136\n",
      "   Latest checkpoint: weights.00140.pt\n",
      "   \n",
      "   Set in next cell:\n",
      "   CONFIG['vae_cfg'] = './out/vae_colab/20251224_120136/vae.cfg.p'\n",
      "   CONFIG['vae_weights'] = './out/vae_colab/20251224_120136/weights/weights.00140.pt'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "# Check for VAE runs (may be in timestamped subdirectories)\n",
    "vae_base_dir = './out/vae_colab'\n",
    "vae_runs = []\n",
    "\n",
    "if os.path.exists(vae_base_dir):\n",
    "    # Look for timestamped subdirectories\n",
    "    potential_runs = [d for d in os.listdir(vae_base_dir) if os.path.isdir(os.path.join(vae_base_dir, d))]\n",
    "    for run_dir in sorted(potential_runs, reverse=True):  # Most recent first\n",
    "        run_path = os.path.join(vae_base_dir, run_dir)\n",
    "        cfg_path = os.path.join(run_path, 'vae.cfg.p')\n",
    "        weights_dir = os.path.join(run_path, 'weights')\n",
    "\n",
    "        if os.path.exists(cfg_path) and os.path.exists(weights_dir):\n",
    "            weight_files = sorted([f for f in os.listdir(weights_dir) if f.endswith('.pt')])\n",
    "            if weight_files:\n",
    "                vae_runs.append({\n",
    "                    'run_dir': run_dir,\n",
    "                    'cfg_path': cfg_path,\n",
    "                    'weights_dir': weights_dir,\n",
    "                    'weight_files': weight_files\n",
    "                })\n",
    "\n",
    "if vae_runs:\n",
    "    print(f\"âœ… Found {len(vae_runs)} VAE training run(s):\\n\")\n",
    "\n",
    "    for i, run in enumerate(vae_runs, 1):\n",
    "        print(f\"Run {i}: {run['run_dir']}\")\n",
    "\n",
    "        # Load and show config\n",
    "        vae_cfg = pickle.load(open(run['cfg_path'], 'rb'))\n",
    "        print(f\"   Config: zdim={vae_cfg.get('zdim', 'N/A')}, nf={vae_cfg.get('nf', 'N/A')}\")\n",
    "\n",
    "        # Show checkpoints\n",
    "        print(f\"   Checkpoints: {len(run['weight_files'])} files\")\n",
    "        if len(run['weight_files']) <= 3:\n",
    "            for wf in run['weight_files']:\n",
    "                print(f\"      ğŸ“¦ {wf}\")\n",
    "        else:\n",
    "            print(f\"      ğŸ“¦ {run['weight_files'][0]} ... {run['weight_files'][-1]}\")\n",
    "        print()\n",
    "\n",
    "    # Recommendation\n",
    "    latest_run = vae_runs[0]\n",
    "    latest_weight = latest_run['weight_files'][-1]\n",
    "    recommended_path = os.path.join(latest_run['weights_dir'], latest_weight)\n",
    "\n",
    "    print(f\"ğŸ’¡ Recommendation:\")\n",
    "    print(f\"   Use latest run: {latest_run['run_dir']}\")\n",
    "    print(f\"   Latest checkpoint: {latest_weight}\")\n",
    "    print(f\"   \\n   Set in next cell:\")\n",
    "    print(f\"   CONFIG['vae_cfg'] = '{latest_run['cfg_path']}'\")\n",
    "    print(f\"   CONFIG['vae_weights'] = '{recommended_path}'\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ No trained VAE runs found!\")\n",
    "    print(\"\\n   Please train VAE first using train_vae_colab.ipynb\")\n",
    "    print(f\"   Expected location: {vae_base_dir}/YYYYMMDD_HHMMSS/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fa53f3",
   "metadata": {
    "id": "10fa53f3"
   },
   "source": [
    "## 8. Configure GP-VAE Training\n",
    "\n",
    "Adjust these parameters as needed:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70721bf",
   "metadata": {
    "id": "d70721bf"
   },
   "source": [
    "## 7. Choose View Kernel ğŸ”¬\n",
    "\n",
    "**NEW: Kernel Selection for View Correlations**\n",
    "\n",
    "The view kernel models how correlations between face angles (0Â°, 15Â°, 30Â°, ..., 90Â°) are structured.\n",
    "\n",
    "### Available Kernels:\n",
    "\n",
    "1. **`'legacy'`** - Original implementation (normalized embeddings, 81 params)\n",
    "   - Most flexible but can overfit\n",
    "   - Good baseline for comparison\n",
    "\n",
    "2. **`'fullrank'`** - Direct full-rank covariance (45 params)\n",
    "   - Flexible but still many parameters\n",
    "   - Better than legacy due to fewer constraints\n",
    "\n",
    "3. **`'periodic'`** â­ **RECOMMENDED** - Periodic kernel (1 param: lengthscale)\n",
    "   - Knows that 0Â° = 360Â° (periodicity!)\n",
    "   - Smooth correlations between nearby angles\n",
    "   - Massive regularization (only 1 parameter)\n",
    "   - Best for rotation data\n",
    "\n",
    "4. **`'vonmises'`** â­ **RECOMMENDED** - Von Mises kernel (1 param: kappa)\n",
    "   - Designed specifically for circular/angular data\n",
    "   - Similar to Periodic but different parameterization\n",
    "   - Also best for rotation data\n",
    "\n",
    "5. **`'matern'`** - MatÃ©rn kernel (1 param: lengthscale)\n",
    "   - More realistic than RBF, less smooth\n",
    "   - Good for modeling realistic correlations\n",
    "   - Can choose smoothness: nu=1.5 or nu=2.5\n",
    "\n",
    "6. **`'linear'`** - Low-rank linear (rankÃ—9 params)\n",
    "   - Original GP-VAE kernel from Casale et al. (2018)\n",
    "   - Good middle-ground\n",
    "\n",
    "7. **`'rbf'`** - RBF/Gaussian (1 param: lengthscale)\n",
    "   - Smooth but NOT periodic\n",
    "   - Use only if views don't wrap around\n",
    "\n",
    "### Expected Performance:\n",
    "\n",
    "| Metric | Legacy | FullRank | Periodic | VonMises | MatÃ©rn |\n",
    "|--------|--------|----------|----------|----------|--------|\n",
    "| Val MSE | Medium | Medium | **Best** | **Best** | Good |\n",
    "| Out-of-sample | Worst | Bad | **Best** | **Best** | Good |\n",
    "| Overfitting | High | Medium | Low | Low | Low |\n",
    "| Parameters | 81 | 45 | 1 | 1 | 1 |\n",
    "| Smoothness | - | - | Very smooth | Very smooth | Adjustable |\n",
    "\n",
    "**Recommendation**:\n",
    "- **Best for rotations**: `'periodic'` or `'vonmises'`\n",
    "- **More realistic**: `'matern'` (less smooth than periodic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c3fdd1f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6c3fdd1f",
    "outputId": "0d6ce303-dc1f-4ac1-f26b-a181da2f49d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Kernel Configuration:\n",
      "============================================================\n",
      "Kernel type: periodic\n",
      "Parameters: {'lengthscale': 1.0}\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# KERNEL CONFIGURATION - Choose one option below\n",
    "# ============================================================================\n",
    "\n",
    "# Option 1: Periodic kernel (RECOMMENDED for face rotations)\n",
    "KERNEL_CONFIG = {\n",
    "    'view_kernel': 'periodic',\n",
    "    'kernel_kwargs': {'lengthscale': 1.0}\n",
    "}\n",
    "\n",
    "# Option 2: Von Mises kernel (RECOMMENDED alternative)\n",
    "# KERNEL_CONFIG = {\n",
    "#     'view_kernel': 'vonmises',\n",
    "#     'kernel_kwargs': {'kappa': 1.0}\n",
    "# }\n",
    "\n",
    "# Option 3: MatÃ©rn kernel (realistic, less smooth than periodic)\n",
    "# KERNEL_CONFIG = {\n",
    "#     'view_kernel': 'matern',\n",
    "#     'kernel_kwargs': {'lengthscale': 1.0, 'nu': 1.5}  # nu=1.5 or nu=2.5\n",
    "# }\n",
    "\n",
    "# Option 4: Legacy (original implementation - baseline)\n",
    "# KERNEL_CONFIG = {\n",
    "#     'view_kernel': 'legacy',\n",
    "#     'kernel_kwargs': {}\n",
    "# }\n",
    "\n",
    "# Option 5: Full Rank (flexible, 45 params)\n",
    "# KERNEL_CONFIG = {\n",
    "#     'view_kernel': 'fullrank',\n",
    "#     'kernel_kwargs': {}\n",
    "# }\n",
    "\n",
    "# Option 6: Linear low-rank (original GP-VAE paper)\n",
    "# KERNEL_CONFIG = {\n",
    "#     'view_kernel': 'linear',\n",
    "#     'kernel_kwargs': {'rank': 3}\n",
    "# }\n",
    "\n",
    "# Option 7: RBF (smooth but not periodic)\n",
    "# KERNEL_CONFIG = {\n",
    "#     'view_kernel': 'rbf',\n",
    "#     'kernel_kwargs': {'lengthscale': 1.0}\n",
    "# }\n",
    "\n",
    "print(\"Selected Kernel Configuration:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Kernel type: {KERNEL_CONFIG['view_kernel']}\")\n",
    "if KERNEL_CONFIG['kernel_kwargs']:\n",
    "    print(f\"Parameters: {KERNEL_CONFIG['kernel_kwargs']}\")\n",
    "else:\n",
    "    print(\"Parameters: (default)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aeb82c9c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aeb82c9c",
    "outputId": "b300165c-db99-41dd-d65e-b3be68b62339"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GP-VAE Training Configuration:\n",
      "============================================================\n",
      "  data                : ./data/faceplace/data_faces.h5\n",
      "  outdir              : ./out/gppvae_colab/periodic_20251224_122758\n",
      "  vae_cfg             : ./out/vae_colab/20251224_120136/vae.cfg.p\n",
      "  vae_weights         : ./out/vae_colab/20251224_120136/weights/weights.00140.pt\n",
      "  epochs              : 50\n",
      "  batch_size          : 64\n",
      "  vae_lr              : 0.001\n",
      "  gp_lr               : 0.01\n",
      "  xdim                : 64\n",
      "  view_kernel         : periodic\n",
      "  kernel_kwargs       : {'lengthscale': 1.0}\n",
      "  epoch_cb            : 10\n",
      "  use_wandb           : True\n",
      "  wandb_project       : gppvae-kernels\n",
      "  wandb_run_name      : colab_periodic_20251224_122758\n",
      "  seed                : 0\n",
      "============================================================\n",
      "\n",
      "âœ… Output will be saved to:\n",
      "   ./out/gppvae_colab/periodic_20251224_122758\n",
      "\n",
      "   Directory name includes kernel type for easy comparison!\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# GP-VAE Training configuration\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "kernel_name = KERNEL_CONFIG['view_kernel']\n",
    "\n",
    "CONFIG = {\n",
    "    'data': './data/faceplace/data_faces.h5',\n",
    "    # Output directory now includes kernel name for easy comparison\n",
    "    'outdir': f'./out/gppvae_colab/{kernel_name}_{timestamp}',\n",
    "    'vae_cfg': './out/vae_colab/20251224_120136/vae.cfg.p',\n",
    "    'vae_weights': './out/vae_colab/20251224_120136/weights/weights.00140.pt',  # â¬…ï¸ Change this if using different checkpoint\n",
    "\n",
    "    # Training hyperparameters\n",
    "    'epochs': 50,  # Start with 50, increase to 100+ for better results\n",
    "    'batch_size': 64,\n",
    "    'vae_lr': 0.001,  # Learning rate for VAE (fine-tuning)\n",
    "    'gp_lr': 0.01,    # Learning rate for GP and Vmodel\n",
    "    'xdim': 64,        # Rank of object linear covariance\n",
    "\n",
    "    # Kernel configuration (from cell above)\n",
    "    'view_kernel': KERNEL_CONFIG['view_kernel'],\n",
    "    'kernel_kwargs': KERNEL_CONFIG['kernel_kwargs'],\n",
    "\n",
    "    # Logging\n",
    "    'epoch_cb': 10,    # Save checkpoint every N epochs\n",
    "    'use_wandb': True,\n",
    "    'wandb_project': 'gppvae-kernels',\n",
    "    'wandb_run_name': f'colab_{kernel_name}_{timestamp}',  # Include kernel in run name\n",
    "    'seed': 0,\n",
    "}\n",
    "\n",
    "print(\"GP-VAE Training Configuration:\")\n",
    "print(\"=\" * 60)\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key:20s}: {value}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Verify VAE weights path\n",
    "if not os.path.exists(CONFIG['vae_weights']):\n",
    "    print(f\"\\nâš ï¸  WARNING: VAE weights not found at:\")\n",
    "    print(f\"   {CONFIG['vae_weights']}\")\n",
    "    print(f\"\\n   Please update CONFIG['vae_weights'] to point to a valid checkpoint.\")\n",
    "\n",
    "print(f\"\\nâœ… Output will be saved to:\")\n",
    "print(f\"   {CONFIG['outdir']}\")\n",
    "print(f\"\\n   Directory name includes kernel type for easy comparison!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9255bb2",
   "metadata": {
    "id": "f9255bb2"
   },
   "source": [
    "## 9. Import Training Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16ab22b2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "16ab22b2",
    "outputId": "fc481672-d9be-4e7e-d738-8ab7b3385b8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All modules imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Change to training script directory\n",
    "os.chdir(os.path.join(PROJECT_PATH, 'GPPVAE/pysrc/faceplace'))\n",
    "\n",
    "# Import modules\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from vae import FaceVAE\n",
    "from vmod import Vmodel\n",
    "from gp import GP\n",
    "import h5py\n",
    "import numpy as np\n",
    "import logging\n",
    "import pylab as pl\n",
    "from utils import smartSum, smartAppendDict, smartAppend, export_scripts\n",
    "from callbacks import callback_gppvae\n",
    "from data_parser import read_face_data, FaceDataset\n",
    "import pickle\n",
    "import time\n",
    "import wandb\n",
    "\n",
    "print(\"âœ… All modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1953910",
   "metadata": {
    "id": "e1953910"
   },
   "source": [
    "## 10. Setup Training Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd715632",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dd715632",
    "outputId": "49a06f48-5c39-4834-ad16-51fbf099538e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "âœ… Training environment setup complete!\n",
      "   Outputs will be saved to: ./out/gppvae_colab/periodic_20251224_122758\n"
     ]
    }
   ],
   "source": [
    "# Go back to project root\n",
    "os.chdir(PROJECT_PATH)\n",
    "\n",
    "# Create output directories\n",
    "outdir = CONFIG['outdir']\n",
    "wdir = os.path.join(outdir, \"weights\")\n",
    "fdir = os.path.join(outdir, \"plots\")\n",
    "os.makedirs(wdir, exist_ok=True)\n",
    "os.makedirs(fdir, exist_ok=True)\n",
    "\n",
    "# Setup device (GPU)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Setup logging\n",
    "log_format = \"%(asctime)s %(message)s\"\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=log_format,\n",
    "    datefmt=\"%m/%d %I:%M:%S %p\",\n",
    ")\n",
    "fh = logging.FileHandler(os.path.join(outdir, \"log.txt\"))\n",
    "fh.setFormatter(logging.Formatter(log_format))\n",
    "logging.getLogger().addHandler(fh)\n",
    "\n",
    "# Copy code to output\n",
    "export_scripts(os.path.join(outdir, \"scripts\"))\n",
    "\n",
    "print(\"âœ… Training environment setup complete!\")\n",
    "print(f\"   Outputs will be saved to: {outdir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36678b2b",
   "metadata": {
    "id": "36678b2b"
   },
   "source": [
    "## 10. Initialize Models and Data\n",
    "\n",
    "This cell:\n",
    "1. Loads pre-trained VAE\n",
    "2. Creates GP and Vmodel\n",
    "3. Loads dataset\n",
    "4. Sets up optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7bf143",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "9c7bf143",
    "outputId": "770b2698-d6ee-4dd3-8e0c-21b95218a6ae"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20251224_122801-es4zl5sq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae-kernels/runs/es4zl5sq' target=\"_blank\">colab_periodic_20251224_122758</a></strong> to <a href='https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae-kernels' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae-kernels' target=\"_blank\">https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae-kernels</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae-kernels/runs/es4zl5sq' target=\"_blank\">https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae-kernels/runs/es4zl5sq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAE config: {'nf': 32, 'zdim': 256, 'vy': 0.002}\n",
      "\n",
      "Loading pre-trained VAE...\n",
      "âœ… VAE loaded from ./out/vae_colab/20251224_120136/weights/weights.00140.pt\n",
      "   Total VAE parameters: 553,304\n",
      "\n",
      "Loading dataset...\n",
      "âœ… Data loaded:\n",
      "   Training samples: 3868\n",
      "   Validation samples: 484\n",
      "\n",
      "Initializing GP-VAE components...\n",
      "   Objects (people): 542\n",
      "   Views (angles): 9\n",
      "âœ… GP-VAE components initialized:\n",
      "   Vmodel parameters: 34,769\n",
      "   GP parameters: 2\n",
      "   Total trainable: 588,075\n",
      "\n",
      "âœ… Optimizers created:\n",
      "   VAE optimizer: Adam(lr=0.001)\n",
      "   GP optimizer: Adam(lr=0.01)\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "torch.manual_seed(CONFIG['seed'])\n",
    "\n",
    "# Initialize W&B\n",
    "if CONFIG['use_wandb']:\n",
    "    wandb.init(\n",
    "        project=CONFIG['wandb_project'],\n",
    "        name=CONFIG['wandb_run_name'],\n",
    "        config=CONFIG\n",
    "    )\n",
    "\n",
    "# Load VAE configuration\n",
    "vae_cfg = pickle.load(open(CONFIG['vae_cfg'], \"rb\"))\n",
    "print(f\"VAE config: {vae_cfg}\")\n",
    "\n",
    "# Load pre-trained VAE\n",
    "print(\"\\nLoading pre-trained VAE...\")\n",
    "vae = FaceVAE(**vae_cfg).to(device)\n",
    "vae_state = torch.load(CONFIG['vae_weights'], map_location=device)\n",
    "vae.load_state_dict(vae_state)\n",
    "print(f\"âœ… VAE loaded from {CONFIG['vae_weights']}\")\n",
    "print(f\"   Total VAE parameters: {sum(p.numel() for p in vae.parameters()):,}\")\n",
    "\n",
    "# Load data\n",
    "print(\"\\nLoading dataset...\")\n",
    "img, obj, view = read_face_data(CONFIG['data'])\n",
    "train_data = FaceDataset(img[\"train\"], obj[\"train\"], view[\"train\"])\n",
    "val_data = FaceDataset(img[\"val\"], obj[\"val\"], view[\"val\"])\n",
    "train_queue = DataLoader(train_data, batch_size=CONFIG['batch_size'], shuffle=True)\n",
    "val_queue = DataLoader(val_data, batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "print(f\"âœ… Data loaded:\")\n",
    "print(f\"   Training samples: {len(train_data)}\")\n",
    "print(f\"   Validation samples: {len(val_data)}\")\n",
    "\n",
    "# Create object and view variables for GP\n",
    "Dt = Variable(obj[\"train\"][:, 0].long(), requires_grad=False).cuda()\n",
    "Wt = Variable(view[\"train\"][:, 0].long(), requires_grad=False).cuda()\n",
    "Dv = Variable(obj[\"val\"][:, 0].long(), requires_grad=False).cuda()\n",
    "Wv = Variable(view[\"val\"][:, 0].long(), requires_grad=False).cuda()\n",
    "\n",
    "# Initialize GP and Vmodel\n",
    "print(\"\\nInitializing GP-VAE components...\")\n",
    "P = np.unique(obj[\"train\"]).shape[0]  # Number of unique objects (people)\n",
    "Q = np.unique(view[\"train\"]).shape[0]  # Number of unique views (angles)\n",
    "print(f\"   Objects (people): {P}\")\n",
    "print(f\"   Views (angles): {Q}\")\n",
    "\n",
    "vm = Vmodel(\n",
    "    P, Q, \n",
    "    p=CONFIG['xdim'], \n",
    "    q=Q, \n",
    "    view_kernel=CONFIG['view_kernel'],\n",
    "    **CONFIG['kernel_kwargs']\n",
    ").cuda()\n",
    "gp = GP(n_rand_effs=1).to(device)\n",
    "\n",
    "# Combine GP parameters (Vmodel + GP)\n",
    "gp_params = nn.ParameterList()\n",
    "gp_params.extend(vm.parameters())\n",
    "gp_params.extend(gp.parameters())\n",
    "\n",
    "print(f\"âœ… GP-VAE components initialized:\")\n",
    "print(f\"   Vmodel parameters: {sum(p.numel() for p in vm.parameters()):,}\")\n",
    "print(f\"   GP parameters: {sum(p.numel() for p in gp.parameters()):,}\")\n",
    "print(f\"   Total trainable: {sum(p.numel() for p in vae.parameters()) + sum(p.numel() for p in gp_params):,}\")\n",
    "\n",
    "# Create optimizers (separate for VAE and GP)\n",
    "vae_optimizer = optim.Adam(vae.parameters(), lr=CONFIG['vae_lr'])\n",
    "gp_optimizer = optim.Adam(gp_params, lr=CONFIG['gp_lr'])\n",
    "print(f\"\\nâœ… Optimizers created:\")\n",
    "print(f\"   VAE optimizer: Adam(lr={CONFIG['vae_lr']})\")\n",
    "print(f\"   GP optimizer: Adam(lr={CONFIG['gp_lr']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9082858",
   "metadata": {
    "id": "b9082858"
   },
   "source": [
    "## 11. Define Training Functions\n",
    "\n",
    "These functions handle the complex GP-VAE training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfa7bebf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dfa7bebf",
    "outputId": "97bd1352-e1e2-417f-b85a-2fd0c6630fa5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Training functions defined\n"
     ]
    }
   ],
   "source": [
    "def encode_Y(vae, train_queue):\n",
    "    \"\"\"Encode all training images to get latent codes\"\"\"\n",
    "    vae.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        n = train_queue.dataset.Y.shape[0]\n",
    "        Zm = Variable(torch.zeros(n, vae_cfg[\"zdim\"]), requires_grad=False).cuda()\n",
    "        Zs = Variable(torch.zeros(n, vae_cfg[\"zdim\"]), requires_grad=False).cuda()\n",
    "\n",
    "        for batch_i, data in enumerate(train_queue):\n",
    "            y = data[0].cuda()\n",
    "            idxs = data[-1].cuda()\n",
    "            zm, zs = vae.encode(y)\n",
    "            Zm[idxs], Zs[idxs] = zm.detach(), zs.detach()\n",
    "\n",
    "    return Zm, Zs\n",
    "\n",
    "\n",
    "def eval_step(vae, gp, vm, val_queue, Zm, Vt, Vv):\n",
    "    \"\"\"Evaluate model on validation set\"\"\"\n",
    "    rv = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _X = vm.x().data.cpu().numpy()\n",
    "        _W = vm.v().data.cpu().numpy()\n",
    "        covs = {\"XX\": np.dot(_X, _X.T), \"WW\": np.dot(_W, _W.T)}\n",
    "        rv[\"vars\"] = gp.get_vs().data.cpu().numpy()\n",
    "\n",
    "        # Out-of-sample prediction\n",
    "        vs = gp.get_vs()\n",
    "        U, UBi, _ = gp.U_UBi_Shb([Vt], vs)\n",
    "        Kiz = gp.solve(Zm, U, UBi, vs)\n",
    "        Zo = vs[0] * Vv.mm(Vt.transpose(0, 1).mm(Kiz))\n",
    "\n",
    "        mse_out = Variable(torch.zeros(Vv.shape[0], 1), requires_grad=False).cuda()\n",
    "        mse_val = Variable(torch.zeros(Vv.shape[0], 1), requires_grad=False).cuda()\n",
    "\n",
    "        for batch_i, data in enumerate(val_queue):\n",
    "            idxs = data[-1].cuda()\n",
    "            Yv = data[0].cuda()\n",
    "            Zv = vae.encode(Yv)[0].detach()\n",
    "            Yr = vae.decode(Zv)\n",
    "            Yo = vae.decode(Zo[idxs])\n",
    "            mse_out[idxs] = ((Yv - Yo) ** 2).view(Yv.shape[0], -1).mean(1)[:, None].detach()\n",
    "            mse_val[idxs] = ((Yv - Yr) ** 2).view(Yv.shape[0], -1).mean(1)[:, None].detach()\n",
    "\n",
    "            # Store examples for visualization\n",
    "            if batch_i == 0:\n",
    "                imgs = {}\n",
    "                imgs[\"Yv\"] = Yv[:24].data.cpu().numpy().transpose(0, 2, 3, 1)\n",
    "                imgs[\"Yr\"] = Yr[:24].data.cpu().numpy().transpose(0, 2, 3, 1)\n",
    "                imgs[\"Yo\"] = Yo[:24].data.cpu().numpy().transpose(0, 2, 3, 1)\n",
    "\n",
    "        rv[\"mse_out\"] = float(mse_out.data.mean().cpu())\n",
    "        rv[\"mse_val\"] = float(mse_val.data.mean().cpu())\n",
    "\n",
    "    return rv, imgs, covs\n",
    "\n",
    "\n",
    "def backprop_and_update(vae, gp, vm, train_queue, Dt, Wt, Eps, Zb, Vbs, vbs, vae_optimizer, gp_optimizer):\n",
    "    \"\"\"Joint optimization of VAE and GP\"\"\"\n",
    "    rv = {}\n",
    "\n",
    "    vae_optimizer.zero_grad()\n",
    "    gp_optimizer.zero_grad()\n",
    "    vae.train()\n",
    "    gp.train()\n",
    "    vm.train()\n",
    "\n",
    "    for batch_i, data in enumerate(train_queue):\n",
    "        # Get batch data\n",
    "        y = data[0].cuda()\n",
    "        eps = Eps[data[-1]]\n",
    "        _d = Dt[data[-1]]\n",
    "        _w = Wt[data[-1]]\n",
    "        _Zb = Zb[data[-1]]\n",
    "        _Vbs = [Vbs[0][data[-1]]]\n",
    "\n",
    "        # Forward through VAE\n",
    "        zm, zs = vae.encode(y)\n",
    "        z = zm + zs * eps\n",
    "        yr = vae.decode(z)\n",
    "        recon_term, mse = vae.nll(y, yr)\n",
    "\n",
    "        # Forward through GP\n",
    "        _Vs = [vm(_d, _w)]\n",
    "        gp_nll_fo = gp.taylor_expansion(z, _Vs, _Zb, _Vbs, vbs) / vae.K\n",
    "\n",
    "        # Penalization term\n",
    "        pen_term = -0.5 * zs.sum(1)[:, None] / vae.K\n",
    "\n",
    "        # Joint loss and backward\n",
    "        loss = (recon_term + gp_nll_fo + pen_term).sum()\n",
    "        loss.backward()\n",
    "\n",
    "        # Accumulate metrics\n",
    "        _n = train_queue.dataset.Y.shape[0]\n",
    "        smartSum(rv, \"mse\", float(mse.data.sum().cpu()) / _n)\n",
    "        smartSum(rv, \"recon_term\", float(recon_term.data.sum().cpu()) / _n)\n",
    "        smartSum(rv, \"pen_term\", float(pen_term.data.sum().cpu()) / _n)\n",
    "\n",
    "    # Update both optimizers\n",
    "    vae_optimizer.step()\n",
    "    gp_optimizer.step()\n",
    "\n",
    "    return rv\n",
    "\n",
    "print(\"âœ… Training functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c869fdf",
   "metadata": {
    "id": "4c869fdf"
   },
   "source": [
    "## 12. Train GP-VAE Model ğŸš€\n",
    "\n",
    "**This is joint optimization!** Both VAE and GP are updated together each iteration.\n",
    "\n",
    "Training process per epoch:\n",
    "1. Encode images to latent codes (VAE)\n",
    "2. Compute GP prior likelihood on latents\n",
    "3. Backpropagate through joint loss\n",
    "4. Update VAE, GP, and Vmodel simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f6f1485",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "2f6f1485",
    "outputId": "cdf9c1a0-b2af-4ef3-fe46-a70ef616fb66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Starting GP-VAE training for 50 epochs...\n",
      "================================================================================\n",
      "Training mode: JOINT OPTIMIZATION (VAE + GP updated together)\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/gppvae/GPPVAE/pysrc/faceplace/vae.py:46: UserWarning: `nn.functional.upsample` is deprecated. Use `nn.functional.interpolate` instead.\n",
      "  x = F.upsample(x, scale_factor=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/50 | MSE val: 0.004238 | MSE out: 0.068923 | GP NLL: 0.0020 | Loss: -2.1612 | Time: 6.4s\n",
      "  âœ“ Checkpoint saved at epoch 0\n",
      "Epoch    5/50 | MSE val: 0.031072 | MSE out: 0.050268 | GP NLL: -0.0001 | Loss: 4.6122 | Time: 5.7s\n",
      "Epoch   10/50 | MSE val: 0.015151 | MSE out: 0.037484 | GP NLL: -0.0001 | Loss: 0.5970 | Time: 5.8s\n",
      "  âœ“ Checkpoint saved at epoch 10\n",
      "Epoch   15/50 | MSE val: 0.011732 | MSE out: 0.034518 | GP NLL: -0.0000 | Loss: -0.1987 | Time: 5.9s\n",
      "Epoch   20/50 | MSE val: 0.009168 | MSE out: 0.031360 | GP NLL: -0.0003 | Loss: -0.8755 | Time: 5.9s\n",
      "  âœ“ Checkpoint saved at epoch 20\n",
      "Epoch   25/50 | MSE val: 0.007705 | MSE out: 0.029252 | GP NLL: -0.0003 | Loss: -1.2451 | Time: 6.0s\n",
      "Epoch   30/50 | MSE val: 0.006775 | MSE out: 0.029119 | GP NLL: -0.0003 | Loss: -1.4836 | Time: 6.4s\n",
      "  âœ“ Checkpoint saved at epoch 30\n",
      "Epoch   35/50 | MSE val: 0.006400 | MSE out: 0.028752 | GP NLL: -0.0004 | Loss: -1.5873 | Time: 5.9s\n",
      "Epoch   40/50 | MSE val: 0.005885 | MSE out: 0.027998 | GP NLL: -0.0005 | Loss: -1.7146 | Time: 6.2s\n",
      "  âœ“ Checkpoint saved at epoch 40\n",
      "Epoch   45/50 | MSE val: 0.005470 | MSE out: 0.027902 | GP NLL: -0.0006 | Loss: -1.8256 | Time: 6.0s\n",
      "Epoch   49/50 | MSE val: 0.005294 | MSE out: 0.027992 | GP NLL: -0.0007 | Loss: -1.8743 | Time: 6.0s\n",
      "  âœ“ Checkpoint saved at epoch 49\n",
      "\n",
      "================================================================================\n",
      "âœ… GP-VAE training complete!\n",
      "   Total time: 5.1 minutes (0.08 hours)\n",
      "   Average time per epoch: 6.1 seconds\n",
      "   Final validation MSE: 0.005294\n",
      "   Final out-of-sample MSE: 0.027992\n",
      "   Final GP NLL: -0.0007\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>gp_nll</td><td>â–…â–ˆâ–…â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>loss</td><td>â–â–ˆâ–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>mse_out</td><td>â–ƒâ–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>mse_val</td><td>â–â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>pen_term</td><td>â–…â–ˆâ–†â–‡â–â–…â–†â–…â–…â–†â–†â–†â–†â–†â–†â–„â–ƒâ–„â–„â–…â–„â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>recon_term</td><td>â–â–ˆâ–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>time/epoch_seconds</td><td>â–ˆâ–â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–†â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–„â–ƒâ–„â–„â–ƒâ–„â–ƒâ–„â–„â–„â–†â–„â–„â–ƒâ–„â–„â–„â–„</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>gp_nll</td><td>-0.00065</td></tr><tr><td>loss</td><td>-1.87432</td></tr><tr><td>mse_out</td><td>0.02799</td></tr><tr><td>mse_val</td><td>0.00529</td></tr><tr><td>pen_term</td><td>-2e-05</td></tr><tr><td>recon_term</td><td>-1.87364</td></tr><tr><td>time/epoch_seconds</td><td>5.96904</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">colab_periodic_20251224_122758</strong> at: <a href='https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae-kernels/runs/es4zl5sq' target=\"_blank\">https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae-kernels/runs/es4zl5sq</a><br> View project at: <a href='https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae-kernels' target=\"_blank\">https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae-kernels</a><br>Synced 5 W&B file(s), 12 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/content/wandb/run-20251224_122801-es4zl5sq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”— View detailed results in W&B dashboard\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "history = {}\n",
    "start_time = time.time()\n",
    "\n",
    "print(f\"ğŸš€ Starting GP-VAE training for {CONFIG['epochs']} epochs...\")\n",
    "print(\"=\" * 80)\n",
    "print(\"Training mode: JOINT OPTIMIZATION (VAE + GP updated together)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for epoch in range(CONFIG['epochs']):\n",
    "    epoch_start = time.time()\n",
    "\n",
    "    # 1. Encode all training images\n",
    "    Zm, Zs = encode_Y(vae, train_queue)\n",
    "\n",
    "    # 2. Sample latent codes\n",
    "    Eps = Variable(torch.randn(*Zs.shape), requires_grad=False).cuda()\n",
    "    Z = Zm + Eps * Zs\n",
    "\n",
    "    # 3. Compute variance matrices\n",
    "    Vt = vm(Dt, Wt).detach()\n",
    "    Vv = vm(Dv, Wv).detach()\n",
    "\n",
    "    # 4. Evaluate on validation set\n",
    "    rv_eval, imgs, covs = eval_step(vae, gp, vm, val_queue, Zm, Vt, Vv)\n",
    "\n",
    "    # 5. Compute GP Taylor expansion coefficients\n",
    "    Zb, Vbs, vbs, gp_nll = gp.taylor_coeff(Z, [Vt])\n",
    "    rv_eval[\"gp_nll\"] = float(gp_nll.data.mean().cpu()) / vae.K\n",
    "\n",
    "    # 6. Joint training step (VAE + GP)\n",
    "    rv_back = backprop_and_update(\n",
    "        vae, gp, vm, train_queue, Dt, Wt, Eps,\n",
    "        Zb, Vbs, vbs, vae_optimizer, gp_optimizer\n",
    "    )\n",
    "    rv_back[\"loss\"] = rv_back[\"recon_term\"] + rv_eval[\"gp_nll\"] + rv_back[\"pen_term\"]\n",
    "\n",
    "    # Store history\n",
    "    smartAppendDict(history, rv_eval)\n",
    "    smartAppendDict(history, rv_back)\n",
    "    smartAppend(history, \"vs\", gp.get_vs().data.cpu().numpy())\n",
    "\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    total_time = time.time() - start_time\n",
    "\n",
    "    # Print progress\n",
    "    if epoch % 5 == 0 or epoch == CONFIG['epochs'] - 1:\n",
    "        print(f\"Epoch {epoch:4d}/{CONFIG['epochs']} | \"\n",
    "              f\"MSE val: {rv_eval['mse_val']:.6f} | \"\n",
    "              f\"MSE out: {rv_eval['mse_out']:.6f} | \"\n",
    "              f\"GP NLL: {rv_eval['gp_nll']:.4f} | \"\n",
    "              f\"Loss: {rv_back['loss']:.4f} | \"\n",
    "              f\"Time: {epoch_time:.1f}s\")\n",
    "\n",
    "    # Log to W&B\n",
    "    if CONFIG['use_wandb']:\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch,\n",
    "            \"mse_val\": rv_eval[\"mse_val\"],\n",
    "            \"mse_out\": rv_eval[\"mse_out\"],\n",
    "            \"gp_nll\": rv_eval[\"gp_nll\"],\n",
    "            \"recon_term\": rv_back[\"recon_term\"],\n",
    "            \"pen_term\": rv_back[\"pen_term\"],\n",
    "            \"loss\": rv_back[\"loss\"],\n",
    "            \"vars\": rv_eval[\"vars\"],\n",
    "            \"time/epoch_seconds\": epoch_time,\n",
    "        })\n",
    "\n",
    "    # Save checkpoint\n",
    "    if epoch % CONFIG['epoch_cb'] == 0 or epoch == CONFIG['epochs'] - 1:\n",
    "        logging.info(f\"Epoch {epoch} - saving checkpoint\")\n",
    "\n",
    "        # Save VAE weights\n",
    "        vae_file = os.path.join(wdir, f\"vae_weights.{epoch:05d}.pt\")\n",
    "        torch.save(vae.state_dict(), vae_file)\n",
    "\n",
    "        # Save GP weights\n",
    "        gp_file = os.path.join(wdir, f\"gp_weights.{epoch:05d}.pt\")\n",
    "        torch.save({\n",
    "            'gp_state': gp.state_dict(),\n",
    "            'vm_state': vm.state_dict(),\n",
    "            'gp_params': gp_params.state_dict(),\n",
    "        }, gp_file)\n",
    "\n",
    "        # Save visualization\n",
    "        ffile = os.path.join(fdir, f\"plot.{epoch:05d}.png\")\n",
    "        callback_gppvae(epoch, history, covs, imgs, ffile)\n",
    "\n",
    "        if CONFIG['use_wandb']:\n",
    "            wandb.log({\n",
    "                \"reconstructions\": wandb.Image(ffile),\n",
    "                \"covariances/XX\": wandb.Image(ffile),  # Uses same plot\n",
    "            })\n",
    "\n",
    "        print(f\"  âœ“ Checkpoint saved at epoch {epoch}\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"âœ… GP-VAE training complete!\")\n",
    "print(f\"   Total time: {total_time/60:.1f} minutes ({total_time/3600:.2f} hours)\")\n",
    "print(f\"   Average time per epoch: {total_time/CONFIG['epochs']:.1f} seconds\")\n",
    "print(f\"   Final validation MSE: {rv_eval['mse_val']:.6f}\")\n",
    "print(f\"   Final out-of-sample MSE: {rv_eval['mse_out']:.6f}\")\n",
    "print(f\"   Final GP NLL: {rv_eval['gp_nll']:.4f}\")\n",
    "\n",
    "if CONFIG['use_wandb']:\n",
    "    wandb.finish()\n",
    "    print(\"\\nğŸ”— View detailed results in W&B dashboard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a98f4bc",
   "metadata": {
    "id": "9a98f4bc"
   },
   "source": [
    "## 13. Download Results\n",
    "\n",
    "Download the trained model and visualizations to your computer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337a096a",
   "metadata": {
    "id": "337a096a"
   },
   "outputs": [],
   "source": [
    "# Compress output folder\n",
    "output_zip = '/content/gppvae_output.zip'\n",
    "!zip -r {output_zip} {CONFIG['outdir']}\n",
    "\n",
    "# Download\n",
    "from google.colab import files\n",
    "print(\"Preparing download...\")\n",
    "files.download(output_zip)\n",
    "print(\"\\nâœ… Download started! Extract the zip on your local machine.\")\n",
    "print(f\"\\nContents include:\")\n",
    "print(f\"  - Trained VAE weights (fine-tuned)\")\n",
    "print(f\"  - GP + Vmodel weights\")\n",
    "print(f\"  - Visualization plots\")\n",
    "print(f\"  - Training logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f397bbc",
   "metadata": {
    "id": "7f397bbc"
   },
   "source": [
    "## 14. Visualize Results\n",
    "\n",
    "View the latest reconstruction and covariance plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6230cf91",
   "metadata": {
    "id": "6230cf91"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import glob\n",
    "\n",
    "# Get latest plot\n",
    "plot_files = sorted(glob.glob(os.path.join(fdir, \"*.png\")))\n",
    "if plot_files:\n",
    "    latest_plot = plot_files[-1]\n",
    "    print(f\"Latest visualization: {latest_plot}\")\n",
    "    display(Image(filename=latest_plot))\n",
    "else:\n",
    "    print(\"No plots generated yet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170c0da5",
   "metadata": {
    "id": "170c0da5"
   },
   "source": [
    "## 15. Analyze Learned Structure\n",
    "\n",
    "Examine what the GP-VAE learned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46167479",
   "metadata": {
    "id": "46167479"
   },
   "outputs": [],
   "source": [
    "# Get learned variance components\n",
    "vs = gp.get_vs().data.cpu().numpy()\n",
    "print(\"Learned variance components:\")\n",
    "print(f\"  Object variance (people): {vs[0]:.4f} ({vs[0]*100:.1f}%)\")\n",
    "print(f\"  Noise variance: {vs[1]:.4f} ({vs[1]*100:.1f}%)\")\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"  {vs[0]*100:.1f}% of latent variation explained by object identity\")\n",
    "print(f\"  {vs[1]*100:.1f}% unexplained (noise + view + other factors)\")\n",
    "\n",
    "# Get object and view embeddings\n",
    "X_embed = vm.x().data.cpu().numpy()\n",
    "V_embed = vm.v().data.cpu().numpy()\n",
    "print(f\"\\nLearned embeddings:\")\n",
    "print(f\"  Object embeddings shape: {X_embed.shape}\")\n",
    "print(f\"  View embeddings shape: {V_embed.shape}\")\n",
    "\n",
    "# Compute correlation structures\n",
    "XX = np.dot(X_embed, X_embed.T)\n",
    "VV = np.dot(V_embed, V_embed.T)\n",
    "print(f\"\\nCovariance matrices:\")\n",
    "print(f\"  Object-object correlation range: [{XX.min():.3f}, {XX.max():.3f}]\")\n",
    "print(f\"  View-view correlation range: [{VV.min():.3f}, {VV.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f88e50c",
   "metadata": {
    "id": "2f88e50c"
   },
   "source": [
    "## 16. Compare with VAE-only Model\n",
    "\n",
    "Compare GP-VAE's out-of-sample prediction with standard VAE reconstruction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5384975",
   "metadata": {
    "id": "b5384975"
   },
   "outputs": [],
   "source": [
    "print(\"Performance Summary:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"VAE reconstruction MSE:        {rv_eval['mse_val']:.6f}\")\n",
    "print(f\"GP-VAE out-of-sample MSE:      {rv_eval['mse_out']:.6f}\")\n",
    "print(f\"Difference:                     {rv_eval['mse_out'] - rv_eval['mse_val']:.6f}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if rv_eval['mse_out'] < rv_eval['mse_val'] * 1.1:\n",
    "    print(\"âœ… Excellent! GP-VAE predicts unseen views almost as well as VAE reconstructs\")\n",
    "    print(\"   This means the GP successfully learned view-independent representations\")\n",
    "elif rv_eval['mse_out'] < rv_eval['mse_val'] * 1.5:\n",
    "    print(\"âœ“ Good! GP-VAE can predict unseen views reasonably well\")\n",
    "    print(\"  Consider training longer for better results\")\n",
    "else:\n",
    "    print(\"âš ï¸ GP-VAE out-of-sample prediction is significantly worse\")\n",
    "    print(\"  Try:\")\n",
    "    print(\"  - Training for more epochs\")\n",
    "    print(\"  - Adjusting learning rates\")\n",
    "    print(\"  - Increasing xdim (covariance rank)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593db584",
   "metadata": {
    "id": "593db584"
   },
   "source": [
    "## 17. Next Steps & Tips\n",
    "\n",
    "### Understanding the Results:\n",
    "- **mse_val**: How well VAE reconstructs images (baseline)\n",
    "- **mse_out**: How well GP-VAE predicts **unseen views** of known objects\n",
    "- **gp_nll**: GP prior likelihood (lower is better)\n",
    "- **vars**: Variance decomposition (object vs noise)\n",
    "\n",
    "### To improve results:\n",
    "1. **Train longer**: Try 1000+ epochs for publication quality\n",
    "2. **Adjust xdim**: Increase from 64 to 128 for more expressive covariances\n",
    "3. **Tune learning rates**: Lower vae_lr if fine-tuning too aggressive\n",
    "4. **Better VAE**: Train VAE for more epochs before GP-VAE\n",
    "\n",
    "### What you've learned:\n",
    "âœ… GP-VAE enables **structured latent representations**  \n",
    "âœ… Can predict **new viewpoints** of known objects  \n",
    "âœ… Learns **disentangled** object identity vs view factors  \n",
    "âœ… Joint optimization of VAE + GP works!  \n",
    "\n",
    "### Performance vs Local:\n",
    "- **Colab GPU**: ~1-2 hours for 100 epochs\n",
    "- **M1 Pro CPU**: Would take 20-50 hours!\n",
    "- **Speedup**: 20-50x faster on Colab ğŸš€\n",
    "\n",
    "Congratulations on training a GP-VAE! ğŸ‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da63d10",
   "metadata": {
    "id": "8da63d10"
   },
   "source": [
    "## 18. Compare Different Kernels ğŸ“Š\n",
    "\n",
    "**Want to compare multiple kernels?** Follow these steps:\n",
    "\n",
    "### 1. Train with multiple kernels:\n",
    "   - Run cells 1-13 with `view_kernel='legacy'` â†’ saves to `./out/gppvae_colab/legacy_TIMESTAMP/`\n",
    "   - Change cell 7 to `view_kernel='periodic'` â†’ restart from cell 7 â†’ saves to `./out/gppvae_colab/periodic_TIMESTAMP/`\n",
    "   - Change cell 7 to `view_kernel='vonmises'` â†’ restart from cell 7 â†’ saves to `./out/gppvae_colab/vonmises_TIMESTAMP/`\n",
    "   - Change cell 7 to `view_kernel='matern'` â†’ restart from cell 7 â†’ saves to `./out/gppvae_colab/matern_TIMESTAMP/`\n",
    "   - Change cell 7 to `view_kernel='fullrank'` â†’ restart from cell 7 â†’ saves to `./out/gppvae_colab/fullrank_TIMESTAMP/`\n",
    "\n",
    "### 2. Output structure:\n",
    "```\n",
    "./out/gppvae_colab/\n",
    "â”œâ”€â”€ legacy_20251224_143530/\n",
    "â”‚   â”œâ”€â”€ weights/\n",
    "â”‚   â”œâ”€â”€ plots/\n",
    "â”‚   â””â”€â”€ log.txt\n",
    "â”œâ”€â”€ periodic_20251224_150215/\n",
    "â”‚   â”œâ”€â”€ weights/\n",
    "â”‚   â”œâ”€â”€ plots/\n",
    "â”‚   â””â”€â”€ log.txt\n",
    "â”œâ”€â”€ vonmises_20251224_152830/\n",
    "â”‚   â”œâ”€â”€ weights/\n",
    "â”‚   â”œâ”€â”€ plots/\n",
    "â”‚   â””â”€â”€ log.txt\n",
    "â”œâ”€â”€ matern_20251224_154120/\n",
    "â”‚   â”œâ”€â”€ weights/\n",
    "â”‚   â”œâ”€â”€ plots/\n",
    "â”‚   â””â”€â”€ log.txt\n",
    "â””â”€â”€ fullrank_20251224_155445/\n",
    "    â”œâ”€â”€ weights/\n",
    "    â”œâ”€â”€ plots/\n",
    "    â””â”€â”€ log.txt\n",
    "```\n",
    "\n",
    "### 3. Compare results:\n",
    "   - **W&B Dashboard**: View all runs side-by-side at wandb.ai\n",
    "   - **Manual comparison**: Run the cell below to load and compare metrics\n",
    "   - **Visual comparison**: Check the learned kernel matrices in cell 16\n",
    "\n",
    "### 4. Expected winners:\n",
    "   - **Best validation MSE**: Periodic or VonMises (regularization!)\n",
    "   - **Best out-of-sample**: Periodic or VonMises (smooth interpolation!)\n",
    "   - **Most realistic**: MatÃ©rn (less smooth, more natural)\n",
    "   - **Lowest training MSE**: Legacy (overfitting)\n",
    "   - **Most interpretable**: Periodic, VonMises, or MatÃ©rn (1 parameter!)\n",
    "\n",
    "### 5. Kernel characteristics:\n",
    "   - **Periodic**: Infinitely smooth, perfect for rotations\n",
    "   - **VonMises**: Designed for circular data, similar to Periodic\n",
    "   - **MatÃ©rn (Î½=1.5)**: Once differentiable, more realistic\n",
    "   - **MatÃ©rn (Î½=2.5)**: Twice differentiable, smoother than Î½=1.5\n",
    "   - **Legacy**: No structure, overfits easily\n",
    "   - **FullRank**: Flexible but needs more data\n",
    "\n",
    "Run the next cell to compare all kernel runs in your output directory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be379602",
   "metadata": {
    "id": "be379602"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Find all kernel runs\n",
    "gppvae_base = './out/gppvae_colab'\n",
    "\n",
    "if not os.path.exists(gppvae_base):\n",
    "    print(f\"âŒ No GP-VAE runs found at {gppvae_base}\")\n",
    "    print(\"   Train at least one model first!\")\n",
    "else:\n",
    "    # Get all subdirectories\n",
    "    all_runs = [d for d in os.listdir(gppvae_base)\n",
    "                if os.path.isdir(os.path.join(gppvae_base, d))]\n",
    "\n",
    "    if not all_runs:\n",
    "        print(f\"âŒ No runs found in {gppvae_base}\")\n",
    "    else:\n",
    "        print(f\"ğŸ“¦ Found {len(all_runs)} GP-VAE run(s):\\n\")\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for run_dir in sorted(all_runs):\n",
    "            run_path = os.path.join(gppvae_base, run_dir)\n",
    "            log_file = os.path.join(run_path, 'log.txt')\n",
    "\n",
    "            # Extract kernel name from directory\n",
    "            kernel_match = re.match(r'(\\w+)_(\\d{8}_\\d{6})', run_dir)\n",
    "            if kernel_match:\n",
    "                kernel_name = kernel_match.group(1)\n",
    "                timestamp = kernel_match.group(2)\n",
    "            else:\n",
    "                kernel_name = 'unknown'\n",
    "                timestamp = run_dir\n",
    "\n",
    "            print(f\"Run: {run_dir}\")\n",
    "            print(f\"  Kernel: {kernel_name}\")\n",
    "            print(f\"  Timestamp: {timestamp}\")\n",
    "\n",
    "            # Try to extract final metrics from log\n",
    "            if os.path.exists(log_file):\n",
    "                # This is a simple parser - you might need to adjust based on actual log format\n",
    "                with open(log_file, 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                    # Look for last few lines with metrics\n",
    "                    # You can parse specific metrics from your log format\n",
    "                    print(f\"  Log file: âœ“ ({len(lines)} lines)\")\n",
    "\n",
    "            # Check for saved weights\n",
    "            weights_dir = os.path.join(run_path, 'weights')\n",
    "            if os.path.exists(weights_dir):\n",
    "                vae_weights = sorted(glob.glob(os.path.join(weights_dir, 'vae_weights.*.pt')))\n",
    "                gp_weights = sorted(glob.glob(os.path.join(weights_dir, 'gp_weights.*.pt')))\n",
    "                print(f\"  Checkpoints: {len(vae_weights)} VAE, {len(gp_weights)} GP\")\n",
    "\n",
    "            # Check for plots\n",
    "            plots_dir = os.path.join(run_path, 'plots')\n",
    "            if os.path.exists(plots_dir):\n",
    "                plots = glob.glob(os.path.join(plots_dir, '*.png'))\n",
    "                print(f\"  Plots: {len(plots)} files\")\n",
    "\n",
    "            print()\n",
    "\n",
    "            results.append({\n",
    "                'kernel': kernel_name,\n",
    "                'timestamp': timestamp,\n",
    "                'run_dir': run_dir,\n",
    "                'path': run_path\n",
    "            })\n",
    "\n",
    "        # Create comparison summary\n",
    "        if len(results) > 1:\n",
    "            print(\"\\n\" + \"=\" * 80)\n",
    "            print(\"ğŸ“Š KERNEL COMPARISON SUMMARY\")\n",
    "            print(\"=\" * 80)\n",
    "            print(\"\\nTo compare results:\")\n",
    "            print(\"1. Check W&B dashboard for detailed metrics\")\n",
    "            print(\"2. Compare learned kernel matrices in plots/\")\n",
    "            print(\"3. Compare final MSE values from training output\")\n",
    "            print(\"\\nRuns available for comparison:\")\n",
    "            for r in results:\n",
    "                print(f\"  â€¢ {r['kernel']:12s} - {r['run_dir']}\")\n",
    "\n",
    "            print(\"\\nğŸ’¡ Expected ranking (best to worst):\")\n",
    "            print(\"   1. Periodic or VonMises - Best generalization (smooth)\")\n",
    "            print(\"   2. MatÃ©rn - More realistic (less smooth)\")\n",
    "            print(\"   3. FullRank - Good but more parameters\")\n",
    "            print(\"   4. Legacy - Most flexible but overfits\")\n",
    "\n",
    "            # If you have W&B, show link\n",
    "            if CONFIG.get('use_wandb'):\n",
    "                print(f\"\\nğŸ”— View all runs in W&B:\")\n",
    "                print(f\"   https://wandb.ai/[YOUR_USERNAME]/{CONFIG['wandb_project']}\")\n",
    "\n",
    "        else:\n",
    "            print(\"â„¹ï¸  Only one run found. Train with different kernels to compare!\")\n",
    "            print(\"   Change KERNEL_CONFIG in cell 7 and rerun from there.\")\n",
    "            print(\"\\n   Suggested kernels to try:\")\n",
    "            print(\"   â€¢ periodic (RECOMMENDED - smooth, periodic)\")\n",
    "            print(\"   â€¢ vonmises (RECOMMENDED - circular data)\")\n",
    "            print(\"   â€¢ matern (realistic, adjustable smoothness)\")\n",
    "            print(\"   â€¢ fullrank (flexible)\")\n",
    "            print(\"   â€¢ legacy (baseline)\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
