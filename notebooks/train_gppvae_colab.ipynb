{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0f8a173e",
      "metadata": {
        "id": "0f8a173e"
      },
      "source": [
        "# GP-VAE Training on Google Colab\n",
        "\n",
        "This notebook trains the **GP-VAE (Gaussian Process Variational Autoencoder)** model using Google Colab's free GPU.\n",
        "\n",
        "## What is GP-VAE?\n",
        "GP-VAE adds a **Gaussian Process prior** to the VAE latent space to model structured correlations:\n",
        "- **VAE**: Learns image ‚Üî latent code mapping\n",
        "- **GP Prior**: Models correlations between latent codes based on:\n",
        "  - Object identity (same person's face)\n",
        "  - View angle (front, side, profile)\n",
        "  - Other factors of variation\n",
        "\n",
        "## Prerequisites ‚ö†Ô∏è\n",
        "**You MUST have trained VAE weights first!** This model loads pre-trained VAE and fine-tunes it jointly with the GP.\n",
        "\n",
        "Required files:\n",
        "- ‚úÖ `out/vae_colab/YYYYMMDD_HHMMSS/vae.cfg.p` - VAE configuration\n",
        "- ‚úÖ `out/vae_colab/YYYYMMDD_HHMMSS/weights/weights.00000.pt` - Trained VAE weights\n",
        "\n",
        "## Output Directory Structure:\n",
        "\n",
        "Each training run creates a **timestamped directory** to avoid overwriting previous runs:\n",
        "- Format: `./out/gppvae_colab/YYYYMMDD_HHMMSS/`\n",
        "- Example: `./out/gppvae_colab/20251224_143530/weights/weights.00100.pt`\n",
        "- This allows you to compare different training runs and keep a history!\n",
        "\n",
        "Cell 6 below will automatically find your latest VAE training run.\n",
        "\n",
        "## Setup Instructions:\n",
        "\n",
        "1. **Open this notebook in VS Code**\n",
        "2. **Connect to Colab**: Click kernel picker ‚Üí \"Connect to Colab\" ‚Üí Choose **GPU runtime (T4)**\n",
        "3. **Important**: When prompted with \"Alias your server\", press Enter\n",
        "4. **Run cell 2** - it will automatically detect your project location\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7d4d88e",
      "metadata": {
        "id": "a7d4d88e"
      },
      "source": [
        "## 1. Check GPU Availability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9450aba9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9450aba9",
        "outputId": "06a4870c-5e25-44e8-ac32-6a8f2dd4d141"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.9.0+cu126\n",
            "CUDA available: True\n",
            "GPU Device: Tesla T4\n",
            "GPU Memory: 15.83 GB\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è WARNING: GPU not detected! Go to Runtime ‚Üí Change runtime type ‚Üí GPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a792140f",
      "metadata": {
        "id": "a792140f"
      },
      "source": [
        "## 2. Auto-Detect Project Path\n",
        "\n",
        "This automatically finds your project files on the Colab runtime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "33fa06a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33fa06a0",
        "outputId": "777cead4-29b2-4bcb-b259-64ed8a830cf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìç Current directory: /content\n",
            "\n",
            "üîÑ Mounting Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ Found project in Google Drive: /content/drive/MyDrive/gppvae\n",
            "\n",
            "üìÅ Contents of /content/drive/MyDrive/gppvae:\n",
            "   üìÇ GPPVAE/\n",
            "   üìÇ data/\n",
            "   üìÑ environment.yml\n",
            "   üìÇ notebooks/\n",
            "   üìÇ out/\n",
            "\n",
            "üîç Checking required files:\n",
            "   ‚úÖ GPPVAE code\n",
            "   ‚úÖ data/faceplace\n",
            "   ‚úÖ data_faces.h5\n",
            "   ‚úÖ VAE config\n",
            "   ‚úÖ VAE weights\n",
            "\n",
            "üì¶ Found 1 VAE training run(s):\n",
            "   1. 20251224_120136/ (16 checkpoints)\n",
            "      Latest: weights.00140.pt\n",
            "\n",
            "üí° Cell 6 below will help you choose which run to use\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# Get current directory\n",
        "current_dir = os.getcwd()\n",
        "print(f\"üìç Current directory: {current_dir}\")\n",
        "\n",
        "# Check if on Colab and need to mount Drive\n",
        "if current_dir == '/content':\n",
        "    print(\"\\nüîÑ Mounting Google Drive...\")\n",
        "\n",
        "    try:\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "\n",
        "        # Check for project in Drive\n",
        "        drive_path = '/content/drive/MyDrive/gppvae'\n",
        "        if os.path.exists(drive_path):\n",
        "            PROJECT_PATH = drive_path\n",
        "            print(f\"‚úÖ Found project in Google Drive: {PROJECT_PATH}\")\n",
        "        else:\n",
        "            print(f\"\\n‚ö†Ô∏è  Project not found at: {drive_path}\")\n",
        "            print(\"\\nPlease upload your gppvae folder to Google Drive!\")\n",
        "            print(\"Required structure:\")\n",
        "            print(\"  MyDrive/gppvae/\")\n",
        "            print(\"    ‚îú‚îÄ‚îÄ GPPVAE/\")\n",
        "            print(\"    ‚îú‚îÄ‚îÄ data/faceplace/data_faces.h5\")\n",
        "            print(\"    ‚îî‚îÄ‚îÄ out/vae_colab/YYYYMMDD_HHMMSS/\")\n",
        "            print(\"        ‚îú‚îÄ‚îÄ vae.cfg.p\")\n",
        "            print(\"        ‚îî‚îÄ‚îÄ weights/weights.00000.pt\")\n",
        "            PROJECT_PATH = '/content'\n",
        "    except Exception as e:\n",
        "        print(f\"Could not mount Drive: {e}\")\n",
        "        PROJECT_PATH = '/content'\n",
        "else:\n",
        "    # Running via VS Code sync\n",
        "    if 'notebooks' in current_dir:\n",
        "        PROJECT_PATH = os.path.dirname(current_dir)\n",
        "    else:\n",
        "        PROJECT_PATH = current_dir\n",
        "    print(f\"üíª Using project path: {PROJECT_PATH}\")\n",
        "\n",
        "# Verify structure\n",
        "print(f\"\\nüìÅ Contents of {PROJECT_PATH}:\")\n",
        "if os.path.exists(PROJECT_PATH):\n",
        "    items = os.listdir(PROJECT_PATH)\n",
        "    for item in sorted(items)[:15]:\n",
        "        item_path = os.path.join(PROJECT_PATH, item)\n",
        "        if os.path.isdir(item_path):\n",
        "            print(f\"   üìÇ {item}/\")\n",
        "        else:\n",
        "            print(f\"   üìÑ {item}\")\n",
        "\n",
        "    # Check required files (with timestamped directory structure)\n",
        "    print(f\"\\nüîç Checking required files:\")\n",
        "    required = {\n",
        "        'GPPVAE code': os.path.exists(os.path.join(PROJECT_PATH, 'GPPVAE')),\n",
        "        'data/faceplace': os.path.exists(os.path.join(PROJECT_PATH, 'data/faceplace')),\n",
        "        'data_faces.h5': os.path.exists(os.path.join(PROJECT_PATH, 'data/faceplace/data_faces.h5')),\n",
        "    }\n",
        "\n",
        "    # Check for VAE runs (timestamped subdirectories)\n",
        "    vae_base_dir = os.path.join(PROJECT_PATH, 'out/vae_colab')\n",
        "    vae_run_found = False\n",
        "    vae_weights_found = False\n",
        "\n",
        "    if os.path.exists(vae_base_dir):\n",
        "        # Look for timestamped subdirectories\n",
        "        potential_runs = [d for d in os.listdir(vae_base_dir)\n",
        "                         if os.path.isdir(os.path.join(vae_base_dir, d)) and d[0].isdigit()]\n",
        "\n",
        "        for run_dir in potential_runs:\n",
        "            run_path = os.path.join(vae_base_dir, run_dir)\n",
        "            cfg_path = os.path.join(run_path, 'vae.cfg.p')\n",
        "            weights_dir = os.path.join(run_path, 'weights')\n",
        "\n",
        "            if os.path.exists(cfg_path):\n",
        "                vae_run_found = True\n",
        "\n",
        "            if os.path.exists(weights_dir):\n",
        "                weight_files = [f for f in os.listdir(weights_dir) if f.endswith('.pt')]\n",
        "                if weight_files:\n",
        "                    vae_weights_found = True\n",
        "                    break\n",
        "\n",
        "    required['VAE config'] = vae_run_found\n",
        "    required['VAE weights'] = vae_weights_found\n",
        "\n",
        "    for name, exists in required.items():\n",
        "        status = \"‚úÖ\" if exists else \"‚ùå\"\n",
        "        print(f\"   {status} {name}\")\n",
        "\n",
        "    # Show VAE runs if they exist\n",
        "    if os.path.exists(vae_base_dir):\n",
        "        potential_runs = sorted([d for d in os.listdir(vae_base_dir)\n",
        "                                if os.path.isdir(os.path.join(vae_base_dir, d)) and d[0].isdigit()],\n",
        "                               reverse=True)\n",
        "\n",
        "        if potential_runs:\n",
        "            print(f\"\\nüì¶ Found {len(potential_runs)} VAE training run(s):\")\n",
        "            for i, run_dir in enumerate(potential_runs[:3], 1):  # Show latest 3\n",
        "                run_path = os.path.join(vae_base_dir, run_dir)\n",
        "                weights_dir = os.path.join(run_path, 'weights')\n",
        "\n",
        "                if os.path.exists(weights_dir):\n",
        "                    weight_files = sorted([f for f in os.listdir(weights_dir) if f.endswith('.pt')])\n",
        "                    print(f\"   {i}. {run_dir}/ ({len(weight_files)} checkpoints)\")\n",
        "                    if weight_files:\n",
        "                        print(f\"      Latest: {weight_files[-1]}\")\n",
        "\n",
        "            if len(potential_runs) > 3:\n",
        "                print(f\"   ... and {len(potential_runs) - 3} more\")\n",
        "\n",
        "            print(f\"\\nüí° Cell 6 below will help you choose which run to use\")\n",
        "\n",
        "    if not all(required.values()):\n",
        "        print(f\"\\n‚ö†Ô∏è  Missing required files!\")\n",
        "        if not required['VAE weights']:\n",
        "            print(\"\\nüö® CRITICAL: No trained VAE weights found!\")\n",
        "            print(\"   You must train VAE first before running GP-VAE\")\n",
        "            print(\"   Use the train_vae_colab.ipynb notebook\")\n",
        "else:\n",
        "    print(f\"‚ùå Path doesn't exist: {PROJECT_PATH}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd61ed4d",
      "metadata": {
        "id": "dd61ed4d"
      },
      "source": [
        "## 3. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5eb3366a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eb3366a",
        "outputId": "70095e44-752b-4635-c81d-879b00e0d602"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m√ó\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m√ó\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "‚úÖ All dependencies installed successfully!\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install -q wandb==0.12.21 imageio==2.15.0 pyyaml\n",
        "\n",
        "# Verify installations\n",
        "import wandb\n",
        "import imageio\n",
        "import yaml\n",
        "import numpy as np\n",
        "print(\"‚úÖ All dependencies installed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "428e2eb3",
      "metadata": {
        "id": "428e2eb3"
      },
      "source": [
        "## 4. Login to Weights & Biases (Optional)\n",
        "\n",
        "Track your experiments with W&B for better monitoring."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a116fb79",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a116fb79",
        "outputId": "34e5e0db-03d3-411a-b4ec-05e6c7d36fb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminh1008\u001b[0m (\u001b[33mminh1008-ludwig-maximilianuniversity-of-munich\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login()\n",
        "\n",
        "# Or run offline without W&B:\n",
        "# import os\n",
        "# os.environ['WANDB_MODE'] = 'offline'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "064cf6ef",
      "metadata": {
        "id": "064cf6ef"
      },
      "source": [
        "## 5. Navigate to Project Directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a9ddd5a1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9ddd5a1",
        "outputId": "da1c2af1-f526-4aad-a063-6e6b310aaa89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current directory: /content/drive/MyDrive/gppvae\n",
            "\n",
            "Project structure:\n",
            "total 17\n",
            "drwx------ 3 root root 4096 Dec 23 14:09 data\n",
            "-rw------- 1 root root  258 Dec 23 11:40 environment.yml\n",
            "drwx------ 3 root root 4096 Dec 23 14:09 GPPVAE\n",
            "drwx------ 2 root root 4096 Dec 23 14:09 notebooks\n",
            "drwx------ 3 root root 4096 Dec 23 14:21 out\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "os.chdir(PROJECT_PATH)\n",
        "print(f\"Current directory: {os.getcwd()}\")\n",
        "\n",
        "# Add to Python path\n",
        "sys.path.insert(0, os.path.join(PROJECT_PATH, 'GPPVAE/pysrc/faceplace'))\n",
        "\n",
        "print(\"\\nProject structure:\")\n",
        "!ls -la"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "638c36f7",
      "metadata": {
        "id": "638c36f7"
      },
      "source": [
        "## 6. Verify VAE Weights\n",
        "\n",
        "**Critical check:** Make sure you have trained VAE weights!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "26a9a8de",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26a9a8de",
        "outputId": "879c71ab-9824-4e0b-c00d-b71a9b2a21cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Found 1 VAE training run(s):\n",
            "\n",
            "Run 1: 20251224_120136\n",
            "   Config: zdim=256, nf=32\n",
            "   Checkpoints: 16 files\n",
            "      üì¶ weights.00000.pt ... weights.00140.pt\n",
            "\n",
            "üí° Recommendation:\n",
            "   Use latest run: 20251224_120136\n",
            "   Latest checkpoint: weights.00140.pt\n",
            "   \n",
            "   Set in next cell:\n",
            "   CONFIG['vae_cfg'] = './out/vae_colab/20251224_120136/vae.cfg.p'\n",
            "   CONFIG['vae_weights'] = './out/vae_colab/20251224_120136/weights/weights.00140.pt'\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pickle\n",
        "import glob\n",
        "\n",
        "# Check for VAE runs (may be in timestamped subdirectories)\n",
        "vae_base_dir = './out/vae_colab'\n",
        "vae_runs = []\n",
        "\n",
        "if os.path.exists(vae_base_dir):\n",
        "    # Look for timestamped subdirectories\n",
        "    potential_runs = [d for d in os.listdir(vae_base_dir) if os.path.isdir(os.path.join(vae_base_dir, d))]\n",
        "    for run_dir in sorted(potential_runs, reverse=True):  # Most recent first\n",
        "        run_path = os.path.join(vae_base_dir, run_dir)\n",
        "        cfg_path = os.path.join(run_path, 'vae.cfg.p')\n",
        "        weights_dir = os.path.join(run_path, 'weights')\n",
        "\n",
        "        if os.path.exists(cfg_path) and os.path.exists(weights_dir):\n",
        "            weight_files = sorted([f for f in os.listdir(weights_dir) if f.endswith('.pt')])\n",
        "            if weight_files:\n",
        "                vae_runs.append({\n",
        "                    'run_dir': run_dir,\n",
        "                    'cfg_path': cfg_path,\n",
        "                    'weights_dir': weights_dir,\n",
        "                    'weight_files': weight_files\n",
        "                })\n",
        "\n",
        "if vae_runs:\n",
        "    print(f\"‚úÖ Found {len(vae_runs)} VAE training run(s):\\n\")\n",
        "\n",
        "    for i, run in enumerate(vae_runs, 1):\n",
        "        print(f\"Run {i}: {run['run_dir']}\")\n",
        "\n",
        "        # Load and show config\n",
        "        vae_cfg = pickle.load(open(run['cfg_path'], 'rb'))\n",
        "        print(f\"   Config: zdim={vae_cfg.get('zdim', 'N/A')}, nf={vae_cfg.get('nf', 'N/A')}\")\n",
        "\n",
        "        # Show checkpoints\n",
        "        print(f\"   Checkpoints: {len(run['weight_files'])} files\")\n",
        "        if len(run['weight_files']) <= 3:\n",
        "            for wf in run['weight_files']:\n",
        "                print(f\"      üì¶ {wf}\")\n",
        "        else:\n",
        "            print(f\"      üì¶ {run['weight_files'][0]} ... {run['weight_files'][-1]}\")\n",
        "        print()\n",
        "\n",
        "    # Recommendation\n",
        "    latest_run = vae_runs[0]\n",
        "    latest_weight = latest_run['weight_files'][-1]\n",
        "    recommended_path = os.path.join(latest_run['weights_dir'], latest_weight)\n",
        "\n",
        "    print(f\"üí° Recommendation:\")\n",
        "    print(f\"   Use latest run: {latest_run['run_dir']}\")\n",
        "    print(f\"   Latest checkpoint: {latest_weight}\")\n",
        "    print(f\"   \\n   Set in next cell:\")\n",
        "    print(f\"   CONFIG['vae_cfg'] = '{latest_run['cfg_path']}'\")\n",
        "    print(f\"   CONFIG['vae_weights'] = '{recommended_path}'\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå No trained VAE runs found!\")\n",
        "    print(\"\\n   Please train VAE first using train_vae_colab.ipynb\")\n",
        "    print(f\"   Expected location: {vae_base_dir}/YYYYMMDD_HHMMSS/\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10fa53f3",
      "metadata": {
        "id": "10fa53f3"
      },
      "source": [
        "## 7. Configure GP-VAE Training\n",
        "\n",
        "Adjust these parameters as needed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "aeb82c9c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeb82c9c",
        "outputId": "8102204c-6150-4e4f-be58-ed04268a1818"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GP-VAE Training Configuration:\n",
            "============================================================\n",
            "  data                : ./data/faceplace/data_faces.h5\n",
            "  outdir              : ./out/gppvae_colab/20251224_111332\n",
            "  vae_cfg             : ./out/vae_colab/20251224_120136/vae.cfg.p\n",
            "  vae_weights         : ./out/vae_colab/20251224_120136/weights/weights.00140.pt\n",
            "  epochs              : 50\n",
            "  batch_size          : 64\n",
            "  vae_lr              : 0.001\n",
            "  gp_lr               : 0.01\n",
            "  xdim                : 64\n",
            "  epoch_cb            : 10\n",
            "  use_wandb           : True\n",
            "  wandb_project       : gppvae\n",
            "  wandb_run_name      : colab_gppvae_gpu_20251224_111332\n",
            "  seed                : 0\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# GP-VAE Training configuration\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "CONFIG = {\n",
        "    'data': './data/faceplace/data_faces.h5',\n",
        "    'outdir': f'./out/gppvae_colab/{timestamp}',  # Timestamped directory for each run\n",
        "    'vae_cfg': './out/vae_colab/20251224_120136/vae.cfg.p',\n",
        "    'vae_weights': './out/vae_colab/20251224_120136/weights/weights.00140.pt',  # ‚¨ÖÔ∏è Change this if using different checkpoint\n",
        "\n",
        "    # Training hyperparameters\n",
        "    'epochs': 50,  # Start with 100, increase to 1000+ for publication quality\n",
        "    'batch_size': 64,\n",
        "    'vae_lr': 0.001,  # Learning rate for VAE (fine-tuning)\n",
        "    'gp_lr': 0.01,    # Learning rate for GP and Vmodel\n",
        "    'xdim': 64,        # Rank of object linear covariance\n",
        "\n",
        "    # Logging\n",
        "    'epoch_cb': 10,    # Save checkpoint every N epochs\n",
        "    'use_wandb': True,\n",
        "    'wandb_project': 'gppvae',\n",
        "    'wandb_run_name': f'colab_gppvae_gpu_{timestamp}',  # Also add timestamp to run name\n",
        "    'seed': 0,\n",
        "}\n",
        "\n",
        "print(\"GP-VAE Training Configuration:\")\n",
        "print(\"=\" * 60)\n",
        "for key, value in CONFIG.items():\n",
        "    print(f\"  {key:20s}: {value}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Verify VAE weights path\n",
        "if not os.path.exists(CONFIG['vae_weights']):\n",
        "    print(f\"\\n‚ö†Ô∏è  WARNING: VAE weights not found at:\")\n",
        "    print(f\"   {CONFIG['vae_weights']}\")\n",
        "    print(f\"\\n   Please update CONFIG['vae_weights'] to point to a valid checkpoint.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9255bb2",
      "metadata": {
        "id": "f9255bb2"
      },
      "source": [
        "## 8. Import Training Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "16ab22b2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16ab22b2",
        "outputId": "d968f78f-d545-4ef4-9fbf-16b4e9ba7785"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All modules imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Change to training script directory\n",
        "os.chdir(os.path.join(PROJECT_PATH, 'GPPVAE/pysrc/faceplace'))\n",
        "\n",
        "# Import modules\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from vae import FaceVAE\n",
        "from vmod import Vmodel\n",
        "from gp import GP\n",
        "import h5py\n",
        "import numpy as np\n",
        "import logging\n",
        "import pylab as pl\n",
        "from utils import smartSum, smartAppendDict, smartAppend, export_scripts\n",
        "from callbacks import callback_gppvae\n",
        "from data_parser import read_face_data, FaceDataset\n",
        "import pickle\n",
        "import time\n",
        "import wandb\n",
        "\n",
        "print(\"‚úÖ All modules imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1953910",
      "metadata": {
        "id": "e1953910"
      },
      "source": [
        "## 9. Setup Training Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "dd715632",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd715632",
        "outputId": "851f2a45-ab73-422e-9fb2-22975e7ead3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n",
            "‚úÖ Training environment setup complete!\n",
            "   Outputs will be saved to: ./out/gppvae_colab/20251224_111332\n"
          ]
        }
      ],
      "source": [
        "# Go back to project root\n",
        "os.chdir(PROJECT_PATH)\n",
        "\n",
        "# Create output directories\n",
        "outdir = CONFIG['outdir']\n",
        "wdir = os.path.join(outdir, \"weights\")\n",
        "fdir = os.path.join(outdir, \"plots\")\n",
        "os.makedirs(wdir, exist_ok=True)\n",
        "os.makedirs(fdir, exist_ok=True)\n",
        "\n",
        "# Setup device (GPU)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Setup logging\n",
        "log_format = \"%(asctime)s %(message)s\"\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=log_format,\n",
        "    datefmt=\"%m/%d %I:%M:%S %p\",\n",
        ")\n",
        "fh = logging.FileHandler(os.path.join(outdir, \"log.txt\"))\n",
        "fh.setFormatter(logging.Formatter(log_format))\n",
        "logging.getLogger().addHandler(fh)\n",
        "\n",
        "# Copy code to output\n",
        "export_scripts(os.path.join(outdir, \"scripts\"))\n",
        "\n",
        "print(\"‚úÖ Training environment setup complete!\")\n",
        "print(f\"   Outputs will be saved to: {outdir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36678b2b",
      "metadata": {
        "id": "36678b2b"
      },
      "source": [
        "## 10. Initialize Models and Data\n",
        "\n",
        "This cell:\n",
        "1. Loads pre-trained VAE\n",
        "2. Creates GP and Vmodel\n",
        "3. Loads dataset\n",
        "4. Sets up optimizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "9c7bf143",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "9c7bf143",
        "outputId": "3c7911aa-ed09-41ea-b1c7-a57437bd273b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251224_111400-gt3c8r3u</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae/runs/gt3c8r3u' target=\"_blank\">colab_gppvae_gpu_20251224_111332</a></strong> to <a href='https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae' target=\"_blank\">https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae/runs/gt3c8r3u' target=\"_blank\">https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae/runs/gt3c8r3u</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VAE config: {'nf': 32, 'zdim': 256, 'vy': 0.002}\n",
            "\n",
            "Loading pre-trained VAE...\n",
            "‚úÖ VAE loaded from ./out/vae_colab/20251224_120136/weights/weights.00140.pt\n",
            "   Total VAE parameters: 553,304\n",
            "\n",
            "Loading dataset...\n",
            "‚úÖ Data loaded:\n",
            "   Training samples: 3868\n",
            "   Validation samples: 484\n",
            "\n",
            "Initializing GP-VAE components...\n",
            "   Objects (people): 542\n",
            "   Views (angles): 9\n",
            "‚úÖ GP-VAE components initialized:\n",
            "   Vmodel parameters: 34,769\n",
            "   GP parameters: 2\n",
            "   Total trainable: 588,075\n",
            "\n",
            "‚úÖ Optimizers created:\n",
            "   VAE optimizer: Adam(lr=0.001)\n",
            "   GP optimizer: Adam(lr=0.01)\n"
          ]
        }
      ],
      "source": [
        "# Set random seed\n",
        "torch.manual_seed(CONFIG['seed'])\n",
        "\n",
        "# Initialize W&B\n",
        "if CONFIG['use_wandb']:\n",
        "    wandb.init(\n",
        "        project=CONFIG['wandb_project'],\n",
        "        name=CONFIG['wandb_run_name'],\n",
        "        config=CONFIG\n",
        "    )\n",
        "\n",
        "# Load VAE configuration\n",
        "vae_cfg = pickle.load(open(CONFIG['vae_cfg'], \"rb\"))\n",
        "print(f\"VAE config: {vae_cfg}\")\n",
        "\n",
        "# Load pre-trained VAE\n",
        "print(\"\\nLoading pre-trained VAE...\")\n",
        "vae = FaceVAE(**vae_cfg).to(device)\n",
        "vae_state = torch.load(CONFIG['vae_weights'], map_location=device)\n",
        "vae.load_state_dict(vae_state)\n",
        "print(f\"‚úÖ VAE loaded from {CONFIG['vae_weights']}\")\n",
        "print(f\"   Total VAE parameters: {sum(p.numel() for p in vae.parameters()):,}\")\n",
        "\n",
        "# Load data\n",
        "print(\"\\nLoading dataset...\")\n",
        "img, obj, view = read_face_data(CONFIG['data'])\n",
        "train_data = FaceDataset(img[\"train\"], obj[\"train\"], view[\"train\"])\n",
        "val_data = FaceDataset(img[\"val\"], obj[\"val\"], view[\"val\"])\n",
        "train_queue = DataLoader(train_data, batch_size=CONFIG['batch_size'], shuffle=True)\n",
        "val_queue = DataLoader(val_data, batch_size=CONFIG['batch_size'], shuffle=False)\n",
        "print(f\"‚úÖ Data loaded:\")\n",
        "print(f\"   Training samples: {len(train_data)}\")\n",
        "print(f\"   Validation samples: {len(val_data)}\")\n",
        "\n",
        "# Create object and view variables for GP\n",
        "Dt = Variable(obj[\"train\"][:, 0].long(), requires_grad=False).cuda()\n",
        "Wt = Variable(view[\"train\"][:, 0].long(), requires_grad=False).cuda()\n",
        "Dv = Variable(obj[\"val\"][:, 0].long(), requires_grad=False).cuda()\n",
        "Wv = Variable(view[\"val\"][:, 0].long(), requires_grad=False).cuda()\n",
        "\n",
        "# Initialize GP and Vmodel\n",
        "print(\"\\nInitializing GP-VAE components...\")\n",
        "P = np.unique(obj[\"train\"]).shape[0]  # Number of unique objects (people)\n",
        "Q = np.unique(view[\"train\"]).shape[0]  # Number of unique views (angles)\n",
        "print(f\"   Objects (people): {P}\")\n",
        "print(f\"   Views (angles): {Q}\")\n",
        "\n",
        "vm = Vmodel(P, Q, CONFIG['xdim'], Q).cuda()\n",
        "gp = GP(n_rand_effs=1).to(device)\n",
        "\n",
        "# Combine GP parameters (Vmodel + GP)\n",
        "gp_params = nn.ParameterList()\n",
        "gp_params.extend(vm.parameters())\n",
        "gp_params.extend(gp.parameters())\n",
        "\n",
        "print(f\"‚úÖ GP-VAE components initialized:\")\n",
        "print(f\"   Vmodel parameters: {sum(p.numel() for p in vm.parameters()):,}\")\n",
        "print(f\"   GP parameters: {sum(p.numel() for p in gp.parameters()):,}\")\n",
        "print(f\"   Total trainable: {sum(p.numel() for p in vae.parameters()) + sum(p.numel() for p in gp_params):,}\")\n",
        "\n",
        "# Create optimizers (separate for VAE and GP)\n",
        "vae_optimizer = optim.Adam(vae.parameters(), lr=CONFIG['vae_lr'])\n",
        "gp_optimizer = optim.Adam(gp_params, lr=CONFIG['gp_lr'])\n",
        "print(f\"\\n‚úÖ Optimizers created:\")\n",
        "print(f\"   VAE optimizer: Adam(lr={CONFIG['vae_lr']})\")\n",
        "print(f\"   GP optimizer: Adam(lr={CONFIG['gp_lr']})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9082858",
      "metadata": {
        "id": "b9082858"
      },
      "source": [
        "## 11. Define Training Functions\n",
        "\n",
        "These functions handle the complex GP-VAE training loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "dfa7bebf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfa7bebf",
        "outputId": "45dcf075-4389-4063-a8fc-0214b9f28393"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Training functions defined\n"
          ]
        }
      ],
      "source": [
        "def encode_Y(vae, train_queue):\n",
        "    \"\"\"Encode all training images to get latent codes\"\"\"\n",
        "    vae.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        n = train_queue.dataset.Y.shape[0]\n",
        "        Zm = Variable(torch.zeros(n, vae_cfg[\"zdim\"]), requires_grad=False).cuda()\n",
        "        Zs = Variable(torch.zeros(n, vae_cfg[\"zdim\"]), requires_grad=False).cuda()\n",
        "\n",
        "        for batch_i, data in enumerate(train_queue):\n",
        "            y = data[0].cuda()\n",
        "            idxs = data[-1].cuda()\n",
        "            zm, zs = vae.encode(y)\n",
        "            Zm[idxs], Zs[idxs] = zm.detach(), zs.detach()\n",
        "\n",
        "    return Zm, Zs\n",
        "\n",
        "\n",
        "def eval_step(vae, gp, vm, val_queue, Zm, Vt, Vv):\n",
        "    \"\"\"Evaluate model on validation set\"\"\"\n",
        "    rv = {}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        _X = vm.x().data.cpu().numpy()\n",
        "        _W = vm.v().data.cpu().numpy()\n",
        "        covs = {\"XX\": np.dot(_X, _X.T), \"WW\": np.dot(_W, _W.T)}\n",
        "        rv[\"vars\"] = gp.get_vs().data.cpu().numpy()\n",
        "\n",
        "        # Out-of-sample prediction\n",
        "        vs = gp.get_vs()\n",
        "        U, UBi, _ = gp.U_UBi_Shb([Vt], vs)\n",
        "        Kiz = gp.solve(Zm, U, UBi, vs)\n",
        "        Zo = vs[0] * Vv.mm(Vt.transpose(0, 1).mm(Kiz))\n",
        "\n",
        "        mse_out = Variable(torch.zeros(Vv.shape[0], 1), requires_grad=False).cuda()\n",
        "        mse_val = Variable(torch.zeros(Vv.shape[0], 1), requires_grad=False).cuda()\n",
        "\n",
        "        for batch_i, data in enumerate(val_queue):\n",
        "            idxs = data[-1].cuda()\n",
        "            Yv = data[0].cuda()\n",
        "            Zv = vae.encode(Yv)[0].detach()\n",
        "            Yr = vae.decode(Zv)\n",
        "            Yo = vae.decode(Zo[idxs])\n",
        "            mse_out[idxs] = ((Yv - Yo) ** 2).view(Yv.shape[0], -1).mean(1)[:, None].detach()\n",
        "            mse_val[idxs] = ((Yv - Yr) ** 2).view(Yv.shape[0], -1).mean(1)[:, None].detach()\n",
        "\n",
        "            # Store examples for visualization\n",
        "            if batch_i == 0:\n",
        "                imgs = {}\n",
        "                imgs[\"Yv\"] = Yv[:24].data.cpu().numpy().transpose(0, 2, 3, 1)\n",
        "                imgs[\"Yr\"] = Yr[:24].data.cpu().numpy().transpose(0, 2, 3, 1)\n",
        "                imgs[\"Yo\"] = Yo[:24].data.cpu().numpy().transpose(0, 2, 3, 1)\n",
        "\n",
        "        rv[\"mse_out\"] = float(mse_out.data.mean().cpu())\n",
        "        rv[\"mse_val\"] = float(mse_val.data.mean().cpu())\n",
        "\n",
        "    return rv, imgs, covs\n",
        "\n",
        "\n",
        "def backprop_and_update(vae, gp, vm, train_queue, Dt, Wt, Eps, Zb, Vbs, vbs, vae_optimizer, gp_optimizer):\n",
        "    \"\"\"Joint optimization of VAE and GP\"\"\"\n",
        "    rv = {}\n",
        "\n",
        "    vae_optimizer.zero_grad()\n",
        "    gp_optimizer.zero_grad()\n",
        "    vae.train()\n",
        "    gp.train()\n",
        "    vm.train()\n",
        "\n",
        "    for batch_i, data in enumerate(train_queue):\n",
        "        # Get batch data\n",
        "        y = data[0].cuda()\n",
        "        eps = Eps[data[-1]]\n",
        "        _d = Dt[data[-1]]\n",
        "        _w = Wt[data[-1]]\n",
        "        _Zb = Zb[data[-1]]\n",
        "        _Vbs = [Vbs[0][data[-1]]]\n",
        "\n",
        "        # Forward through VAE\n",
        "        zm, zs = vae.encode(y)\n",
        "        z = zm + zs * eps\n",
        "        yr = vae.decode(z)\n",
        "        recon_term, mse = vae.nll(y, yr)\n",
        "\n",
        "        # Forward through GP\n",
        "        _Vs = [vm(_d, _w)]\n",
        "        gp_nll_fo = gp.taylor_expansion(z, _Vs, _Zb, _Vbs, vbs) / vae.K\n",
        "\n",
        "        # Penalization term\n",
        "        pen_term = -0.5 * zs.sum(1)[:, None] / vae.K\n",
        "\n",
        "        # Joint loss and backward\n",
        "        loss = (recon_term + gp_nll_fo + pen_term).sum()\n",
        "        loss.backward()\n",
        "\n",
        "        # Accumulate metrics\n",
        "        _n = train_queue.dataset.Y.shape[0]\n",
        "        smartSum(rv, \"mse\", float(mse.data.sum().cpu()) / _n)\n",
        "        smartSum(rv, \"recon_term\", float(recon_term.data.sum().cpu()) / _n)\n",
        "        smartSum(rv, \"pen_term\", float(pen_term.data.sum().cpu()) / _n)\n",
        "\n",
        "    # Update both optimizers\n",
        "    vae_optimizer.step()\n",
        "    gp_optimizer.step()\n",
        "\n",
        "    return rv\n",
        "\n",
        "print(\"‚úÖ Training functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c869fdf",
      "metadata": {
        "id": "4c869fdf"
      },
      "source": [
        "## 12. Train GP-VAE Model üöÄ\n",
        "\n",
        "**This is joint optimization!** Both VAE and GP are updated together each iteration.\n",
        "\n",
        "Training process per epoch:\n",
        "1. Encode images to latent codes (VAE)\n",
        "2. Compute GP prior likelihood on latents\n",
        "3. Backpropagate through joint loss\n",
        "4. Update VAE, GP, and Vmodel simultaneously"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "2f6f1485",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2f6f1485",
        "outputId": "bce07a0f-fc34-4c7a-ab24-26812fdbb2d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Starting GP-VAE training for 50 epochs...\n",
            "================================================================================\n",
            "Training mode: JOINT OPTIMIZATION (VAE + GP updated together)\n",
            "================================================================================\n",
            "Epoch    0/50 | MSE val: 0.004238 | MSE out: 0.068923 | GP NLL: 0.0020 | Loss: -2.1612 | Time: 6.1s\n",
            "  ‚úì Checkpoint saved at epoch 0\n",
            "Epoch    5/50 | MSE val: 0.031072 | MSE out: 0.050269 | GP NLL: -0.0001 | Loss: 4.6122 | Time: 6.2s\n",
            "Epoch   10/50 | MSE val: 0.015151 | MSE out: 0.037485 | GP NLL: -0.0001 | Loss: 0.5970 | Time: 6.0s\n",
            "  ‚úì Checkpoint saved at epoch 10\n",
            "Epoch   15/50 | MSE val: 0.011732 | MSE out: 0.034518 | GP NLL: -0.0000 | Loss: -0.1987 | Time: 6.1s\n",
            "Epoch   20/50 | MSE val: 0.009168 | MSE out: 0.031358 | GP NLL: -0.0003 | Loss: -0.8755 | Time: 6.1s\n",
            "  ‚úì Checkpoint saved at epoch 20\n",
            "Epoch   25/50 | MSE val: 0.007705 | MSE out: 0.029252 | GP NLL: -0.0003 | Loss: -1.2451 | Time: 6.1s\n",
            "Epoch   30/50 | MSE val: 0.006775 | MSE out: 0.029119 | GP NLL: -0.0003 | Loss: -1.4836 | Time: 6.0s\n",
            "  ‚úì Checkpoint saved at epoch 30\n",
            "Epoch   35/50 | MSE val: 0.006400 | MSE out: 0.028752 | GP NLL: -0.0004 | Loss: -1.5873 | Time: 6.1s\n",
            "Epoch   40/50 | MSE val: 0.005885 | MSE out: 0.027997 | GP NLL: -0.0005 | Loss: -1.7146 | Time: 6.1s\n",
            "  ‚úì Checkpoint saved at epoch 40\n",
            "Epoch   45/50 | MSE val: 0.005470 | MSE out: 0.027902 | GP NLL: -0.0006 | Loss: -1.8256 | Time: 6.1s\n",
            "Epoch   49/50 | MSE val: 0.005294 | MSE out: 0.028006 | GP NLL: -0.0007 | Loss: -1.8743 | Time: 6.1s\n",
            "  ‚úì Checkpoint saved at epoch 49\n",
            "\n",
            "================================================================================\n",
            "‚úÖ GP-VAE training complete!\n",
            "   Total time: 5.2 minutes (0.09 hours)\n",
            "   Average time per epoch: 6.2 seconds\n",
            "   Final validation MSE: 0.005294\n",
            "   Final out-of-sample MSE: 0.028006\n",
            "   Final GP NLL: -0.0007\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà</td></tr><tr><td>gp_nll</td><td>‚ñÖ‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>loss</td><td>‚ñÅ‚ñà‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>mse_out</td><td>‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>mse_val</td><td>‚ñÅ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>pen_term</td><td>‚ñá‚ñà‚ñá‚ñÖ‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>recon_term</td><td>‚ñÅ‚ñà‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>time/epoch_seconds</td><td>‚ñÑ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñÑ‚ñà‚ñÖ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñÅ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÇ‚ñÑ‚ñÇ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÜ‚ñÑ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>gp_nll</td><td>-0.00065</td></tr><tr><td>loss</td><td>-1.87432</td></tr><tr><td>mse_out</td><td>0.02801</td></tr><tr><td>mse_val</td><td>0.00529</td></tr><tr><td>pen_term</td><td>-2e-05</td></tr><tr><td>recon_term</td><td>-1.87364</td></tr><tr><td>time/epoch_seconds</td><td>6.10906</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">colab_gppvae_gpu_20251224_111332</strong> at: <a href='https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae/runs/gt3c8r3u' target=\"_blank\">https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae/runs/gt3c8r3u</a><br> View project at: <a href='https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae' target=\"_blank\">https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae</a><br>Synced 5 W&B file(s), 12 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>/content/wandb/run-20251224_111400-gt3c8r3u/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîó View detailed results in W&B dashboard\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "history = {}\n",
        "start_time = time.time()\n",
        "\n",
        "print(f\"üöÄ Starting GP-VAE training for {CONFIG['epochs']} epochs...\")\n",
        "print(\"=\" * 80)\n",
        "print(\"Training mode: JOINT OPTIMIZATION (VAE + GP updated together)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for epoch in range(CONFIG['epochs']):\n",
        "    epoch_start = time.time()\n",
        "\n",
        "    # 1. Encode all training images\n",
        "    Zm, Zs = encode_Y(vae, train_queue)\n",
        "\n",
        "    # 2. Sample latent codes\n",
        "    Eps = Variable(torch.randn(*Zs.shape), requires_grad=False).cuda()\n",
        "    Z = Zm + Eps * Zs\n",
        "\n",
        "    # 3. Compute variance matrices\n",
        "    Vt = vm(Dt, Wt).detach()\n",
        "    Vv = vm(Dv, Wv).detach()\n",
        "\n",
        "    # 4. Evaluate on validation set\n",
        "    rv_eval, imgs, covs = eval_step(vae, gp, vm, val_queue, Zm, Vt, Vv)\n",
        "\n",
        "    # 5. Compute GP Taylor expansion coefficients\n",
        "    Zb, Vbs, vbs, gp_nll = gp.taylor_coeff(Z, [Vt])\n",
        "    rv_eval[\"gp_nll\"] = float(gp_nll.data.mean().cpu()) / vae.K\n",
        "\n",
        "    # 6. Joint training step (VAE + GP)\n",
        "    rv_back = backprop_and_update(\n",
        "        vae, gp, vm, train_queue, Dt, Wt, Eps,\n",
        "        Zb, Vbs, vbs, vae_optimizer, gp_optimizer\n",
        "    )\n",
        "    rv_back[\"loss\"] = rv_back[\"recon_term\"] + rv_eval[\"gp_nll\"] + rv_back[\"pen_term\"]\n",
        "\n",
        "    # Store history\n",
        "    smartAppendDict(history, rv_eval)\n",
        "    smartAppendDict(history, rv_back)\n",
        "    smartAppend(history, \"vs\", gp.get_vs().data.cpu().numpy())\n",
        "\n",
        "    epoch_time = time.time() - epoch_start\n",
        "    total_time = time.time() - start_time\n",
        "\n",
        "    # Print progress\n",
        "    if epoch % 5 == 0 or epoch == CONFIG['epochs'] - 1:\n",
        "        print(f\"Epoch {epoch:4d}/{CONFIG['epochs']} | \"\n",
        "              f\"MSE val: {rv_eval['mse_val']:.6f} | \"\n",
        "              f\"MSE out: {rv_eval['mse_out']:.6f} | \"\n",
        "              f\"GP NLL: {rv_eval['gp_nll']:.4f} | \"\n",
        "              f\"Loss: {rv_back['loss']:.4f} | \"\n",
        "              f\"Time: {epoch_time:.1f}s\")\n",
        "\n",
        "    # Log to W&B\n",
        "    if CONFIG['use_wandb']:\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch,\n",
        "            \"mse_val\": rv_eval[\"mse_val\"],\n",
        "            \"mse_out\": rv_eval[\"mse_out\"],\n",
        "            \"gp_nll\": rv_eval[\"gp_nll\"],\n",
        "            \"recon_term\": rv_back[\"recon_term\"],\n",
        "            \"pen_term\": rv_back[\"pen_term\"],\n",
        "            \"loss\": rv_back[\"loss\"],\n",
        "            \"vars\": rv_eval[\"vars\"],\n",
        "            \"time/epoch_seconds\": epoch_time,\n",
        "        })\n",
        "\n",
        "    # Save checkpoint\n",
        "    if epoch % CONFIG['epoch_cb'] == 0 or epoch == CONFIG['epochs'] - 1:\n",
        "        logging.info(f\"Epoch {epoch} - saving checkpoint\")\n",
        "\n",
        "        # Save VAE weights\n",
        "        vae_file = os.path.join(wdir, f\"vae_weights.{epoch:05d}.pt\")\n",
        "        torch.save(vae.state_dict(), vae_file)\n",
        "\n",
        "        # Save GP weights\n",
        "        gp_file = os.path.join(wdir, f\"gp_weights.{epoch:05d}.pt\")\n",
        "        torch.save({\n",
        "            'gp_state': gp.state_dict(),\n",
        "            'vm_state': vm.state_dict(),\n",
        "            'gp_params': gp_params.state_dict(),\n",
        "        }, gp_file)\n",
        "\n",
        "        # Save visualization\n",
        "        ffile = os.path.join(fdir, f\"plot.{epoch:05d}.png\")\n",
        "        callback_gppvae(epoch, history, covs, imgs, ffile)\n",
        "\n",
        "        if CONFIG['use_wandb']:\n",
        "            wandb.log({\n",
        "                \"reconstructions\": wandb.Image(ffile),\n",
        "                \"covariances/XX\": wandb.Image(ffile),  # Uses same plot\n",
        "            })\n",
        "\n",
        "        print(f\"  ‚úì Checkpoint saved at epoch {epoch}\")\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(f\"‚úÖ GP-VAE training complete!\")\n",
        "print(f\"   Total time: {total_time/60:.1f} minutes ({total_time/3600:.2f} hours)\")\n",
        "print(f\"   Average time per epoch: {total_time/CONFIG['epochs']:.1f} seconds\")\n",
        "print(f\"   Final validation MSE: {rv_eval['mse_val']:.6f}\")\n",
        "print(f\"   Final out-of-sample MSE: {rv_eval['mse_out']:.6f}\")\n",
        "print(f\"   Final GP NLL: {rv_eval['gp_nll']:.4f}\")\n",
        "\n",
        "if CONFIG['use_wandb']:\n",
        "    wandb.finish()\n",
        "    print(\"\\nüîó View detailed results in W&B dashboard\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a98f4bc",
      "metadata": {
        "id": "9a98f4bc"
      },
      "source": [
        "## 13. Download Results\n",
        "\n",
        "Download the trained model and visualizations to your computer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "337a096a",
      "metadata": {
        "id": "337a096a"
      },
      "outputs": [],
      "source": [
        "# Compress output folder\n",
        "output_zip = '/content/gppvae_output.zip'\n",
        "!zip -r {output_zip} {CONFIG['outdir']}\n",
        "\n",
        "# Download\n",
        "from google.colab import files\n",
        "print(\"Preparing download...\")\n",
        "files.download(output_zip)\n",
        "print(\"\\n‚úÖ Download started! Extract the zip on your local machine.\")\n",
        "print(f\"\\nContents include:\")\n",
        "print(f\"  - Trained VAE weights (fine-tuned)\")\n",
        "print(f\"  - GP + Vmodel weights\")\n",
        "print(f\"  - Visualization plots\")\n",
        "print(f\"  - Training logs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f397bbc",
      "metadata": {
        "id": "7f397bbc"
      },
      "source": [
        "## 14. Visualize Results\n",
        "\n",
        "View the latest reconstruction and covariance plots:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6230cf91",
      "metadata": {
        "id": "6230cf91"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "import glob\n",
        "\n",
        "# Get latest plot\n",
        "plot_files = sorted(glob.glob(os.path.join(fdir, \"*.png\")))\n",
        "if plot_files:\n",
        "    latest_plot = plot_files[-1]\n",
        "    print(f\"Latest visualization: {latest_plot}\")\n",
        "    display(Image(filename=latest_plot))\n",
        "else:\n",
        "    print(\"No plots generated yet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "170c0da5",
      "metadata": {
        "id": "170c0da5"
      },
      "source": [
        "## 15. Analyze Learned Structure\n",
        "\n",
        "Examine what the GP-VAE learned:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46167479",
      "metadata": {
        "id": "46167479"
      },
      "outputs": [],
      "source": [
        "# Get learned variance components\n",
        "vs = gp.get_vs().data.cpu().numpy()\n",
        "print(\"Learned variance components:\")\n",
        "print(f\"  Object variance (people): {vs[0]:.4f} ({vs[0]*100:.1f}%)\")\n",
        "print(f\"  Noise variance: {vs[1]:.4f} ({vs[1]*100:.1f}%)\")\n",
        "print(f\"\\nInterpretation:\")\n",
        "print(f\"  {vs[0]*100:.1f}% of latent variation explained by object identity\")\n",
        "print(f\"  {vs[1]*100:.1f}% unexplained (noise + view + other factors)\")\n",
        "\n",
        "# Get object and view embeddings\n",
        "X_embed = vm.x().data.cpu().numpy()\n",
        "V_embed = vm.v().data.cpu().numpy()\n",
        "print(f\"\\nLearned embeddings:\")\n",
        "print(f\"  Object embeddings shape: {X_embed.shape}\")\n",
        "print(f\"  View embeddings shape: {V_embed.shape}\")\n",
        "\n",
        "# Compute correlation structures\n",
        "XX = np.dot(X_embed, X_embed.T)\n",
        "VV = np.dot(V_embed, V_embed.T)\n",
        "print(f\"\\nCovariance matrices:\")\n",
        "print(f\"  Object-object correlation range: [{XX.min():.3f}, {XX.max():.3f}]\")\n",
        "print(f\"  View-view correlation range: [{VV.min():.3f}, {VV.max():.3f}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f88e50c",
      "metadata": {
        "id": "2f88e50c"
      },
      "source": [
        "## 16. Compare with VAE-only Model\n",
        "\n",
        "Compare GP-VAE's out-of-sample prediction with standard VAE reconstruction:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5384975",
      "metadata": {
        "id": "b5384975"
      },
      "outputs": [],
      "source": [
        "print(\"Performance Summary:\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"VAE reconstruction MSE:        {rv_eval['mse_val']:.6f}\")\n",
        "print(f\"GP-VAE out-of-sample MSE:      {rv_eval['mse_out']:.6f}\")\n",
        "print(f\"Difference:                     {rv_eval['mse_out'] - rv_eval['mse_val']:.6f}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if rv_eval['mse_out'] < rv_eval['mse_val'] * 1.1:\n",
        "    print(\"‚úÖ Excellent! GP-VAE predicts unseen views almost as well as VAE reconstructs\")\n",
        "    print(\"   This means the GP successfully learned view-independent representations\")\n",
        "elif rv_eval['mse_out'] < rv_eval['mse_val'] * 1.5:\n",
        "    print(\"‚úì Good! GP-VAE can predict unseen views reasonably well\")\n",
        "    print(\"  Consider training longer for better results\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è GP-VAE out-of-sample prediction is significantly worse\")\n",
        "    print(\"  Try:\")\n",
        "    print(\"  - Training for more epochs\")\n",
        "    print(\"  - Adjusting learning rates\")\n",
        "    print(\"  - Increasing xdim (covariance rank)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "593db584",
      "metadata": {
        "id": "593db584"
      },
      "source": [
        "## 17. Next Steps & Tips\n",
        "\n",
        "### Understanding the Results:\n",
        "- **mse_val**: How well VAE reconstructs images (baseline)\n",
        "- **mse_out**: How well GP-VAE predicts **unseen views** of known objects\n",
        "- **gp_nll**: GP prior likelihood (lower is better)\n",
        "- **vars**: Variance decomposition (object vs noise)\n",
        "\n",
        "### To improve results:\n",
        "1. **Train longer**: Try 1000+ epochs for publication quality\n",
        "2. **Adjust xdim**: Increase from 64 to 128 for more expressive covariances\n",
        "3. **Tune learning rates**: Lower vae_lr if fine-tuning too aggressive\n",
        "4. **Better VAE**: Train VAE for more epochs before GP-VAE\n",
        "\n",
        "### What you've learned:\n",
        "‚úÖ GP-VAE enables **structured latent representations**  \n",
        "‚úÖ Can predict **new viewpoints** of known objects  \n",
        "‚úÖ Learns **disentangled** object identity vs view factors  \n",
        "‚úÖ Joint optimization of VAE + GP works!  \n",
        "\n",
        "### Performance vs Local:\n",
        "- **Colab GPU**: ~1-2 hours for 100 epochs\n",
        "- **M1 Pro CPU**: Would take 20-50 hours!\n",
        "- **Speedup**: 20-50x faster on Colab üöÄ\n",
        "\n",
        "Congratulations on training a GP-VAE! üéâ"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}