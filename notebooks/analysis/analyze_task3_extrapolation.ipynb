{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e47cbcd",
   "metadata": {},
   "source": [
    "# Task 3 (Extrapolation) Analysis - Kernel Comparison\n",
    "\n",
    "This notebook analyzes the performance of different GP kernels on **Task 3 (Extrapolation)**:\n",
    "\n",
    "## Task Description\n",
    "- **Task 3 (Extrapolation)**: Predict views **BEYOND** the training range\n",
    "- **Train Views**: Views 0-9 (0¬∞ to 180¬∞) - covering front half of rotation\n",
    "- **Val Views**: Views 10-11 (200¬∞, 220¬∞) - near extrapolation\n",
    "- **Test Views**: Views 12-17 (240¬∞-340¬∞) - far extrapolation\n",
    "- **Goal**: Test out-of-distribution generalization via GP extrapolation\n",
    "\n",
    "## Research Question\n",
    "> \"How do different kernel-induced inductive biases influence **extrapolation** to unseen extreme views?\"\n",
    "\n",
    "## Kernels Compared\n",
    "1. **Full Rank**: Free-form learnable covariance (Q√óQ parameters) - **Expected to fail** (no structure)\n",
    "2. **Periodic**: Standard periodic kernel - **Expected to succeed** (wraps around 360¬∞)\n",
    "3. **SM Wrapped**: Spectral Mixture with wrapped distance - Should benefit from periodicity\n",
    "4. **SM Free**: Spectral Mixture (unwrapped) - Intermediate performance expected\n",
    "\n",
    "## Analysis (Extended for Extrapolation)\n",
    "- **Per-View MSE**: How MSE degrades as we extrapolate further from training\n",
    "- **Extrapolation Distance Analysis**: MSE vs angular distance from training range\n",
    "- **Near vs Far Extrapolation**: Compare val (near) vs test (far) performance\n",
    "- **Periodicity Benefit**: Which kernels leverage circular structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2a1646",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104d6f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.patches import Patch\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185e21bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "print(f\"üìç Current directory: {current_dir}\")\n",
    "\n",
    "if current_dir == '/content':\n",
    "    print(\"\\nüîÑ Mounting Google Drive...\")\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        drive_path = '/content/drive/MyDrive/gppvae'\n",
    "        if os.path.exists(drive_path):\n",
    "            PROJECT_PATH = drive_path\n",
    "            print(f\"‚úÖ Found project in Google Drive: {PROJECT_PATH}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Project not found at: {drive_path}\")\n",
    "            PROJECT_PATH = '/content'\n",
    "    except Exception as e:\n",
    "        print(f\"Could not mount Drive: {e}\")\n",
    "        PROJECT_PATH = '/content'\n",
    "else:\n",
    "    if 'notebooks' in current_dir:\n",
    "        PROJECT_PATH = os.path.dirname(os.path.dirname(current_dir))\n",
    "    else:\n",
    "        PROJECT_PATH = current_dir\n",
    "    print(f\"üíª Using project path: {PROJECT_PATH}\")\n",
    "\n",
    "coil100_path = os.path.join(PROJECT_PATH, 'GPPVAE/pysrc/coil100')\n",
    "sys.path.insert(0, coil100_path)\n",
    "\n",
    "os.chdir(PROJECT_PATH)\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "print(f\"Code path added: {coil100_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c75bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vae import FaceVAE\n",
    "from vmod import Vmodel\n",
    "from gp import GP\n",
    "from data_parser import COIL100Dataset, get_n_views, get_num_objects\n",
    "\n",
    "print(\"‚úÖ All modules imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5db4156",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b529bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3 (Extrapolation) configuration\n",
    "CONFIG = {\n",
    "    'task': 'task3_extrapolation',\n",
    "    'data_path': './data/coil100/coil100_task3_extrapolation.h5',\n",
    "    'batch_size': 64,\n",
    "    'xdim': 64,\n",
    "}\n",
    "\n",
    "# Auto-detect paths\n",
    "if os.path.exists('./GPPVAE/results'):\n",
    "    CONFIG['results_base'] = './GPPVAE/results'\n",
    "    print(f\"‚úÖ Found results at: {os.path.abspath(CONFIG['results_base'])}\")\n",
    "elif os.path.exists('./results'):\n",
    "    CONFIG['results_base'] = './results'\n",
    "    print(f\"‚úÖ Found results at: {os.path.abspath(CONFIG['results_base'])}\")\n",
    "else:\n",
    "    CONFIG['results_base'] = './results'\n",
    "    print(f\"‚ö†Ô∏è Results folder not found\")\n",
    "\n",
    "if os.path.exists('./GPPVAE/data/coil100/coil100_task3_extrapolation.h5'):\n",
    "    CONFIG['data_path'] = './GPPVAE/data/coil100/coil100_task3_extrapolation.h5'\n",
    "    print(f\"‚úÖ Found data at: {os.path.abspath(CONFIG['data_path'])}\")\n",
    "elif os.path.exists('./data/coil100/coil100_task3_extrapolation.h5'):\n",
    "    CONFIG['data_path'] = './data/coil100/coil100_task3_extrapolation.h5'\n",
    "    print(f\"‚úÖ Found data at: {os.path.abspath(CONFIG['data_path'])}\")\n",
    "\n",
    "# View configuration for Task 3 (Extrapolation)\n",
    "# Train: views 0-9 (0¬∞-180¬∞) \n",
    "# Val: views 10-11 (200¬∞, 220¬∞) - near extrapolation\n",
    "# Test: views 12-17 (240¬∞, 260¬∞, 280¬∞, 300¬∞, 320¬∞, 340¬∞) - far extrapolation\n",
    "TRAIN_VIEW_INDICES = list(range(0, 10))  # 0-9 (0¬∞ to 180¬∞)\n",
    "VAL_VIEW_INDICES = [10, 11]  # 200¬∞, 220¬∞ (near extrapolation)\n",
    "TEST_VIEW_INDICES = [12, 13, 14, 15, 16, 17]  # 240¬∞-340¬∞ (far extrapolation)\n",
    "VIEW_ANGLES = {i: i * 20 for i in range(18)}\n",
    "\n",
    "# Compute extrapolation distances\n",
    "TRAIN_MAX_ANGLE = max([VIEW_ANGLES[v] for v in TRAIN_VIEW_INDICES])  # 180¬∞\n",
    "EXTRAPOLATION_DISTANCES = {v: VIEW_ANGLES[v] - TRAIN_MAX_ANGLE for v in VAL_VIEW_INDICES + TEST_VIEW_INDICES}\n",
    "\n",
    "print(f\"\\nüìä Extrapolation Task Setup:\")\n",
    "print(f\"   Train views: {[VIEW_ANGLES[v] for v in TRAIN_VIEW_INDICES]}¬∞ (max: {TRAIN_MAX_ANGLE}¬∞)\")\n",
    "print(f\"   Val views (near): {[VIEW_ANGLES[v] for v in VAL_VIEW_INDICES]}¬∞\")\n",
    "print(f\"   Test views (far): {[VIEW_ANGLES[v] for v in TEST_VIEW_INDICES]}¬∞\")\n",
    "print(f\"\\n   Extrapolation distances:\")\n",
    "for v, dist in EXTRAPOLATION_DISTANCES.items():\n",
    "    label = \"(near)\" if v in VAL_VIEW_INDICES else \"(far)\"\n",
    "    print(f\"      {VIEW_ANGLES[v]}¬∞ ‚Üí +{dist}¬∞ beyond training {label}\")\n",
    "\n",
    "# Kernel configurations\n",
    "KERNEL_CONFIGS = {\n",
    "    'fullrank': {\n",
    "        'folder': 'task3_fullrank',\n",
    "        'view_kernel': 'full_rank',\n",
    "        'kernel_kwargs': {},\n",
    "        'display_name': 'Full Rank',\n",
    "        'color': '#e74c3c',\n",
    "        'expected': 'FAIL (no structure)',\n",
    "    },\n",
    "    'periodic': {\n",
    "        'folder': 'task3_periodic',\n",
    "        'view_kernel': 'periodic',\n",
    "        'kernel_kwargs': {'period': 360.0, 'lengthscale': 1.0, 'variance': 1.0},\n",
    "        'display_name': 'Periodic',\n",
    "        'color': '#3498db',\n",
    "        'expected': 'SUCCEED (wraps at 360¬∞)',\n",
    "    },\n",
    "    'sm_wrapped': {\n",
    "        'folder': 'task3_sm_wrapped',\n",
    "        'view_kernel': 'sm_circle',\n",
    "        'kernel_kwargs': {'freq_init': [1/360.0, 1/40.0], 'weight_init':[0.5, 0.5], 'length_init':[90,30]},\n",
    "        'display_name': 'SM (Wrapped)',\n",
    "        'color': '#2ecc71',\n",
    "        'expected': 'Should leverage periodicity',\n",
    "    },\n",
    "    'sm_free': {\n",
    "        'folder': 'task3_sm_free',\n",
    "        'view_kernel': 'sm_circle',\n",
    "        'kernel_kwargs': {'freq_init': [1/360.0, 1/40.0], 'weight_init':[0.5, 0.5], 'use_angle_input': True},\n",
    "        'display_name': 'SM (Free)',\n",
    "        'color': '#9b59b6',\n",
    "        'expected': 'Intermediate',\n",
    "    },\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nUsing device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fa411f",
   "metadata": {},
   "source": [
    "## 3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9921b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = COIL100Dataset(CONFIG['data_path'], split='train', use_angle_encoding=False)\n",
    "val_data = COIL100Dataset(CONFIG['data_path'], split='val', use_angle_encoding=False)\n",
    "test_data = COIL100Dataset(CONFIG['data_path'], split='test', use_angle_encoding=False)\n",
    "\n",
    "train_queue = DataLoader(train_data, batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "val_queue = DataLoader(val_data, batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "test_queue = DataLoader(test_data, batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "\n",
    "P = get_num_objects(CONFIG['data_path'])\n",
    "Q = get_n_views()\n",
    "\n",
    "print(f\"\\nüìä Task 3 (Extrapolation) Dataset:\")\n",
    "print(f\"   Objects (P): {P}\")\n",
    "print(f\"   Views (Q): {Q}\")\n",
    "print(f\"   Train: {len(train_data)} samples\")\n",
    "print(f\"   Val (near extrap): {len(val_data)} samples\")\n",
    "print(f\"   Test (far extrap): {len(test_data)} samples\")\n",
    "\n",
    "# Analyze view distribution\n",
    "train_views = set(train_data.Rid.numpy())\n",
    "val_views = set(val_data.Rid.numpy())\n",
    "test_views = set(test_data.Rid.numpy())\n",
    "\n",
    "print(f\"\\n   Train view indices: {sorted(train_views)}\")\n",
    "print(f\"   Val view indices: {sorted(val_views)}\")\n",
    "print(f\"   Test view indices: {sorted(test_views)}\")\n",
    "print(f\"   Train angles: {[VIEW_ANGLES.get(int(v), v*20) for v in sorted(train_views)]}¬∞\")\n",
    "print(f\"   Val angles: {[VIEW_ANGLES.get(int(v), v*20) for v in sorted(val_views)]}¬∞\")\n",
    "print(f\"   Test angles: {[VIEW_ANGLES.get(int(v), v*20) for v in sorted(test_views)]}¬∞\")\n",
    "\n",
    "Dt = Variable(train_data.Did.long(), requires_grad=False).to(device)\n",
    "Wt = Variable(train_data.Rid.long(), requires_grad=False).to(device)\n",
    "Dval = Variable(val_data.Did.long(), requires_grad=False).to(device)\n",
    "Wval = Variable(val_data.Rid.long(), requires_grad=False).to(device)\n",
    "Dtest = Variable(test_data.Did.long(), requires_grad=False).to(device)\n",
    "Wtest = Variable(test_data.Rid.long(), requires_grad=False).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2ac156",
   "metadata": {},
   "source": [
    "## 4. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cde0a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_run_folders(results_base, kernel_folder):\n",
    "    kernel_path = os.path.join(results_base, kernel_folder)\n",
    "    if not os.path.exists(kernel_path):\n",
    "        print(f\"‚ö†Ô∏è Kernel folder not found: {kernel_path}\")\n",
    "        return []\n",
    "    runs = sorted([d for d in os.listdir(kernel_path) \n",
    "                   if os.path.isdir(os.path.join(kernel_path, d))])\n",
    "    return [os.path.join(kernel_path, r) for r in runs]\n",
    "\n",
    "\n",
    "def load_vae_config(run_folder=None):\n",
    "    possible_paths = [\n",
    "        './GPPVAE/pysrc/coil100/vae.cfg.p',\n",
    "        './out/vae/vae.cfg.p',\n",
    "    ]\n",
    "    for path in possible_paths:\n",
    "        if os.path.exists(path):\n",
    "            try:\n",
    "                with open(path, 'rb') as f:\n",
    "                    return pickle.load(f)\n",
    "            except:\n",
    "                continue\n",
    "    return {\n",
    "        'img_size': 128, 'nf': 32, 'zdim': 256,\n",
    "        'steps': 5, 'colors': 3, 'act': 'elu', 'vy': 0.001\n",
    "    }\n",
    "\n",
    "\n",
    "def load_models(run_folder, kernel_config, P, Q, xdim, device):\n",
    "    weights_dir = os.path.join(run_folder, 'weights')\n",
    "    gp_weights_path = os.path.join(weights_dir, 'gp_weights.best.pt')\n",
    "    vae_weights_path = os.path.join(weights_dir, 'vae_weights.best.pt')\n",
    "    \n",
    "    if not os.path.exists(gp_weights_path):\n",
    "        raise FileNotFoundError(f\"GP weights not found: {gp_weights_path}\")\n",
    "    if not os.path.exists(vae_weights_path):\n",
    "        raise FileNotFoundError(f\"VAE weights not found: {vae_weights_path}\")\n",
    "    \n",
    "    vae_cfg = load_vae_config(run_folder)\n",
    "    vae = FaceVAE(**vae_cfg).to(device)\n",
    "    vae.load_state_dict(torch.load(vae_weights_path, map_location=device))\n",
    "    vae.eval()\n",
    "    \n",
    "    vm = Vmodel(\n",
    "        P=P, Q=Q, p=xdim,\n",
    "        view_kernel=kernel_config['view_kernel'],\n",
    "        **kernel_config['kernel_kwargs']\n",
    "    ).to(device)\n",
    "    gp = GP(n_rand_effs=1).to(device)\n",
    "    \n",
    "    checkpoint = torch.load(gp_weights_path, map_location=device)\n",
    "    gp.load_state_dict(checkpoint['gp_state'])\n",
    "    vm.load_state_dict(checkpoint['vm_state'])\n",
    "    \n",
    "    vm.eval()\n",
    "    gp.eval()\n",
    "    \n",
    "    return vae, vm, gp\n",
    "\n",
    "\n",
    "def encode_dataset(vae, data_queue, device):\n",
    "    vae.eval()\n",
    "    n = data_queue.dataset.Y.shape[0]\n",
    "    zdim = 256\n",
    "    Zm = torch.zeros(n, zdim).to(device)\n",
    "    with torch.no_grad():\n",
    "        for data in data_queue:\n",
    "            y = data[0].to(device)\n",
    "            idxs = data[-1].to(device)\n",
    "            zm, _ = vae.encode(y)\n",
    "            Zm[idxs] = zm.detach()\n",
    "    return Zm\n",
    "\n",
    "\n",
    "def evaluate_with_per_view(vae, vm, gp, train_queue, eval_queue, \n",
    "                           Dt, Wt, D_eval, W_eval, device):\n",
    "    \"\"\"\n",
    "    Evaluate on any split (val or test) with per-view MSE breakdown.\n",
    "    \"\"\"\n",
    "    vae.eval()\n",
    "    vm.eval()\n",
    "    gp.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        Zm = encode_dataset(vae, train_queue, device)\n",
    "        Vt = vm(Dt, Wt).detach()\n",
    "        V_eval = vm(D_eval, W_eval).detach()\n",
    "        \n",
    "        vs = gp.get_vs()\n",
    "        U, UBi, _ = gp.U_UBi_Shb([Vt], vs)\n",
    "        Kiz = gp.solve(Zm, U, UBi, vs)\n",
    "        Zo_eval = vs[0] * V_eval.mm(Vt.transpose(0, 1).mm(Kiz))\n",
    "        \n",
    "        eval_Rid = eval_queue.dataset.Rid\n",
    "        mse_per_view = {}\n",
    "        mse_per_sample = []\n",
    "        mse_total = 0.0\n",
    "        \n",
    "        for data in eval_queue:\n",
    "            idxs = data[-1].to(device)\n",
    "            Y_eval = data[0].to(device)\n",
    "            Yo = vae.decode(Zo_eval[idxs])\n",
    "            mse_batch = ((Y_eval - Yo) ** 2).view(Y_eval.shape[0], -1).mean(1)\n",
    "            \n",
    "            for i, idx in enumerate(data[-1]):\n",
    "                view = int(eval_Rid[idx].item())\n",
    "                mse_val = mse_batch[i].item()\n",
    "                \n",
    "                if view not in mse_per_view:\n",
    "                    mse_per_view[view] = []\n",
    "                mse_per_view[view].append(mse_val)\n",
    "                mse_per_sample.append(mse_val)\n",
    "            \n",
    "            mse_total += mse_batch.sum().item()\n",
    "        \n",
    "        mse_mean = mse_total / len(eval_queue.dataset)\n",
    "    \n",
    "    return mse_mean, np.array(mse_per_sample), mse_per_view\n",
    "\n",
    "\n",
    "def get_reconstructions(vae, vm, gp, train_queue, eval_queue,\n",
    "                        Dt, Wt, D_eval, W_eval, device, n_samples=24):\n",
    "    vae.eval()\n",
    "    vm.eval()\n",
    "    gp.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        Zm = encode_dataset(vae, train_queue, device)\n",
    "        Vt = vm(Dt, Wt).detach()\n",
    "        V_eval = vm(D_eval, W_eval).detach()\n",
    "        \n",
    "        vs = gp.get_vs()\n",
    "        U, UBi, _ = gp.U_UBi_Shb([Vt], vs)\n",
    "        Kiz = gp.solve(Zm, U, UBi, vs)\n",
    "        Zo_eval = vs[0] * V_eval.mm(Vt.transpose(0, 1).mm(Kiz))\n",
    "        \n",
    "        n_total = len(eval_queue.dataset)\n",
    "        sample_stride = max(1, n_total // n_samples)\n",
    "        sample_indices = list(range(0, n_total, sample_stride))[:n_samples]\n",
    "        \n",
    "        Y_orig = eval_queue.dataset.Y[sample_indices].numpy().transpose(0, 2, 3, 1)\n",
    "        sample_indices_tensor = torch.tensor(sample_indices, dtype=torch.long).to(device)\n",
    "        Y_recon = vae.decode(Zo_eval[sample_indices_tensor]).cpu().numpy().transpose(0, 2, 3, 1)\n",
    "    \n",
    "    return Y_orig, Y_recon, sample_indices\n",
    "\n",
    "\n",
    "def compute_extrapolation_distance(view_idx, train_max_angle=180):\n",
    "    # \\\"\\\"\\\"Compute how far a view is beyond the training range.\\\"\\\"\\\"\n",
    "    angle = view_idx * 20\n",
    "    if angle <= train_max_angle:\n",
    "        return 0\n",
    "    # Check both directions (could wrap around)\n",
    "    forward_dist = angle - train_max_angle\n",
    "    backward_dist = (360 - angle) + 0  # Distance to 0¬∞ (start of training)\n",
    "    return min(forward_dist, backward_dist)\n",
    "\n",
    "print(\"‚úÖ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4354c7ce",
   "metadata": {},
   "source": [
    "## 5. Evaluate All Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682659ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for kernel_name, kernel_config in KERNEL_CONFIGS.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Evaluating: {kernel_config['display_name']}\")\n",
    "    print(f\"Expected: {kernel_config['expected']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    run_folders = find_run_folders(CONFIG['results_base'], kernel_config['folder'])\n",
    "    \n",
    "    if not run_folders:\n",
    "        print(f\"‚ö†Ô∏è No runs found for {kernel_name}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"Found {len(run_folders)} runs (seeds)\")\n",
    "    \n",
    "    kernel_results = {\n",
    "        'mse_val_per_seed': [],\n",
    "        'mse_test_per_seed': [],\n",
    "        'mse_per_view_val': [],\n",
    "        'mse_per_view_test': [],\n",
    "        'kernel_matrices': [],\n",
    "        'variance_ratios': [],\n",
    "    }\n",
    "    \n",
    "    for i, run_folder in enumerate(run_folders):\n",
    "        try:\n",
    "            print(f\"  Seed {i}: {os.path.basename(run_folder)}...\", end=\" \")\n",
    "            \n",
    "            vae, vm, gp = load_models(\n",
    "                run_folder, kernel_config, P, Q, CONFIG['xdim'], device\n",
    "            )\n",
    "            \n",
    "            # Evaluate on VAL (near extrapolation)\n",
    "            mse_val, _, mse_per_view_val = evaluate_with_per_view(\n",
    "                vae, vm, gp, train_queue, val_queue,\n",
    "                Dt, Wt, Dval, Wval, device\n",
    "            )\n",
    "            \n",
    "            # Evaluate on TEST (far extrapolation)\n",
    "            mse_test, _, mse_per_view_test = evaluate_with_per_view(\n",
    "                vae, vm, gp, train_queue, test_queue,\n",
    "                Dt, Wt, Dtest, Wtest, device\n",
    "            )\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                K = vm.get_kernel_matrix().cpu().numpy()\n",
    "                vs = gp.get_vs().cpu().numpy()\n",
    "                variance_ratio = vs[0] / (vs[0] + vs[1])\n",
    "            \n",
    "            kernel_results['mse_val_per_seed'].append(mse_val)\n",
    "            kernel_results['mse_test_per_seed'].append(mse_test)\n",
    "            kernel_results['mse_per_view_val'].append(mse_per_view_val)\n",
    "            kernel_results['mse_per_view_test'].append(mse_per_view_test)\n",
    "            kernel_results['kernel_matrices'].append(K)\n",
    "            kernel_results['variance_ratios'].append(variance_ratio)\n",
    "            \n",
    "            print(f\"Val={mse_val:.6f}, Test={mse_test:.6f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if kernel_results['mse_test_per_seed']:\n",
    "        kernel_results['mean_mse_val'] = np.mean(kernel_results['mse_val_per_seed'])\n",
    "        kernel_results['std_mse_val'] = np.std(kernel_results['mse_val_per_seed'])\n",
    "        kernel_results['mean_mse_test'] = np.mean(kernel_results['mse_test_per_seed'])\n",
    "        kernel_results['std_mse_test'] = np.std(kernel_results['mse_test_per_seed'])\n",
    "        \n",
    "        # Extrapolation degradation: how much worse is far vs near\n",
    "        kernel_results['extrap_degradation'] = kernel_results['mean_mse_test'] / kernel_results['mean_mse_val']\n",
    "        \n",
    "        # Aggregate per-view MSE\n",
    "        all_views = set()\n",
    "        for pv in kernel_results['mse_per_view_val'] + kernel_results['mse_per_view_test']:\n",
    "            all_views.update(pv.keys())\n",
    "        \n",
    "        kernel_results['mean_mse_per_view'] = {}\n",
    "        for view in all_views:\n",
    "            view_mses = []\n",
    "            for pv in kernel_results['mse_per_view_val'] + kernel_results['mse_per_view_test']:\n",
    "                if view in pv:\n",
    "                    view_mses.extend(pv[view])\n",
    "            kernel_results['mean_mse_per_view'][view] = np.mean(view_mses)\n",
    "        \n",
    "        print(f\"\\n  üìä {kernel_config['display_name']} Summary:\")\n",
    "        print(f\"     Val MSE (near): {kernel_results['mean_mse_val']:.6f} ¬± {kernel_results['std_mse_val']:.6f}\")\n",
    "        print(f\"     Test MSE (far): {kernel_results['mean_mse_test']:.6f} ¬± {kernel_results['std_mse_test']:.6f}\")\n",
    "        print(f\"     Degradation (far/near): {kernel_results['extrap_degradation']:.2f}x\")\n",
    "    \n",
    "    results[kernel_name] = kernel_results\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ Evaluation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab61dcb",
   "metadata": {},
   "source": [
    "## 6. Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135d7165",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_data = []\n",
    "\n",
    "for kernel_name, kernel_config in KERNEL_CONFIGS.items():\n",
    "    if kernel_name in results and results[kernel_name]['mse_test_per_seed']:\n",
    "        r = results[kernel_name]\n",
    "        summary_data.append({\n",
    "            'Kernel': kernel_config['display_name'],\n",
    "            'Val MSE (near)': r['mean_mse_val'],\n",
    "            'Val Std': r['std_mse_val'],\n",
    "            'Test MSE (far)': r['mean_mse_test'],\n",
    "            'Test Std': r['std_mse_test'],\n",
    "            'Degradation': r['extrap_degradation'],\n",
    "            'N Seeds': len(r['mse_test_per_seed']),\n",
    "            'Var Ratio': np.mean(r['variance_ratios']),\n",
    "        })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df = summary_df.sort_values('Test MSE (far)')\n",
    "\n",
    "print(\"\\nüìä Task 3 (Extrapolation) - Kernel Comparison Summary\")\n",
    "print(\"=\"*90)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"=\"*90)\n",
    "print(\"\\n‚ö†Ô∏è Degradation = Test MSE / Val MSE (lower = better extrapolation)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef803b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Styled table\n",
    "styled_df = summary_df.style.format({\n",
    "    'Val MSE (near)': '{:.6f}',\n",
    "    'Val Std': '{:.6f}',\n",
    "    'Test MSE (far)': '{:.6f}',\n",
    "    'Test Std': '{:.6f}',\n",
    "    'Degradation': '{:.2f}x',\n",
    "    'Var Ratio': '{:.3f}',\n",
    "}).background_gradient(subset=['Test MSE (far)'], cmap='RdYlGn_r')\n",
    "\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ed438e",
   "metadata": {},
   "source": [
    "## 6.1. MSE Comparison Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60112f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot with error bars - clean style (Test MSE - far extrapolation)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 5))\n",
    "\n",
    "kernel_names = []\n",
    "means = []\n",
    "stds = []\n",
    "\n",
    "for kernel_name, kernel_config in KERNEL_CONFIGS.items():\n",
    "    if kernel_name in results and results[kernel_name]['mse_test_per_seed']:\n",
    "        kernel_names.append(kernel_config['display_name'])\n",
    "        means.append(results[kernel_name]['mean_mse_test'])\n",
    "        stds.append(results[kernel_name]['std_mse_test'])\n",
    "\n",
    "x = np.arange(len(kernel_names))\n",
    "bars = ax.bar(x, means, yerr=stds, capsize=5, color='#808080', alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(kernel_names, rotation=0, ha='center', fontsize=11)\n",
    "ax.set_ylabel('MSE [test set - far extrapolation]', fontsize=12)\n",
    "ax.set_ylim(bottom=0)\n",
    "ax.tick_params(labelsize=11)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.grid(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./notebooks/analysis/task3_mse_bar.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Saved: task3_mse_bar.png (300 DPI)\")\n",
    "\n",
    "# Box plot - clean style\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 5))\n",
    "\n",
    "data_for_box = []\n",
    "labels_for_box = []\n",
    "\n",
    "for kernel_name, kernel_config in KERNEL_CONFIGS.items():\n",
    "    if kernel_name in results and results[kernel_name]['mse_test_per_seed']:\n",
    "        data_for_box.append(results[kernel_name]['mse_test_per_seed'])\n",
    "        labels_for_box.append(kernel_config['display_name'])\n",
    "\n",
    "bp = ax.boxplot(data_for_box, labels=labels_for_box, patch_artist=True)\n",
    "for patch in bp['boxes']:\n",
    "    patch.set_facecolor('#808080')\n",
    "    patch.set_alpha(0.7)\n",
    "    patch.set_linewidth(0.5)\n",
    "\n",
    "for element in ['whiskers', 'fliers', 'means', 'medians', 'caps']:\n",
    "    plt.setp(bp[element], linewidth=0.5)\n",
    "\n",
    "ax.set_ylabel('MSE [test set - far extrapolation]', fontsize=12)\n",
    "ax.tick_params(axis='x', rotation=0, labelsize=11)\n",
    "ax.tick_params(axis='y', labelsize=11)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.grid(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./notebooks/analysis/task3_mse_boxplot.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Saved: task3_mse_boxplot.png (300 DPI)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2f4e6f",
   "metadata": {},
   "source": [
    "## 7. Near vs Far Extrapolation Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4150d311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "kernel_names = []\n",
    "val_means = []\n",
    "val_stds = []\n",
    "test_means = []\n",
    "test_stds = []\n",
    "colors = []\n",
    "\n",
    "for kernel_name, kernel_config in KERNEL_CONFIGS.items():\n",
    "    if kernel_name in results and results[kernel_name]['mse_test_per_seed']:\n",
    "        kernel_names.append(kernel_config['display_name'])\n",
    "        val_means.append(results[kernel_name]['mean_mse_val'])\n",
    "        val_stds.append(results[kernel_name]['std_mse_val'])\n",
    "        test_means.append(results[kernel_name]['mean_mse_test'])\n",
    "        test_stds.append(results[kernel_name]['std_mse_test'])\n",
    "        colors.append(kernel_config['color'])\n",
    "\n",
    "x = np.arange(len(kernel_names))\n",
    "\n",
    "# Plot 1: Grouped bar chart (Val vs Test) - Clean style\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, val_means, width, yerr=val_stds, capsize=3,\n",
    "               label='Val (near)', color='lightblue', edgecolor='navy', linewidth=0.5)\n",
    "bars2 = ax.bar(x + width/2, test_means, width, yerr=test_stds, capsize=3,\n",
    "               label='Test (far)', color='salmon', edgecolor='darkred', linewidth=0.5)\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(kernel_names, rotation=0, ha='center', fontsize=11)\n",
    "ax.set_ylabel('MSE', fontsize=12)\n",
    "ax.tick_params(labelsize=11)\n",
    "ax.legend(frameon=False, fontsize=11)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.grid(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./notebooks/analysis/task3_near_vs_far_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Saved: task3_near_vs_far_comparison.png (300 DPI)\")\n",
    "\n",
    "# Plot 2: Degradation factor - Clean style\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "\n",
    "degradations = [t/v for t, v in zip(test_means, val_means)]\n",
    "bars = ax.bar(x, degradations, color=colors, alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "ax.axhline(y=1.0, color='green', linestyle='--', linewidth=1, alpha=0.7)\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(kernel_names, rotation=0, ha='center', fontsize=11)\n",
    "ax.set_ylabel('Degradation (Test/Val)', fontsize=12)\n",
    "ax.set_ylim(bottom=0)\n",
    "ax.tick_params(labelsize=11)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.grid(False)\n",
    "\n",
    "for bar, deg in zip(bars, degradations):\n",
    "    ax.annotate(f'{deg:.2f}x',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, bar.get_height()),\n",
    "                xytext=(0, 3), textcoords='offset points',\n",
    "                ha='center', va='bottom', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./notebooks/analysis/task3_degradation.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Saved: task3_degradation.png (300 DPI)\")\n",
    "\n",
    "# Plot 3: Test MSE with kernel colors - Clean style\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "\n",
    "bars = ax.bar(x, test_means, yerr=test_stds, capsize=5, color=colors, \n",
    "              alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(kernel_names, rotation=0, ha='center', fontsize=11)\n",
    "ax.set_ylabel('MSE [test set - far extrapolation]', fontsize=12)\n",
    "ax.set_ylim(bottom=0)\n",
    "ax.tick_params(labelsize=11)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.grid(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./notebooks/analysis/task3_test_mse_colored.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Saved: task3_test_mse_colored.png (300 DPI)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549ad450",
   "metadata": {},
   "source": [
    "## 8. Per-View Extrapolation Analysis\n",
    "\n",
    "Key question: How does MSE degrade as we extrapolate further from training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65193194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as pl\n",
    "pl.rcdefaults()\n",
    "\n",
    "# Get all extrapolation views\n",
    "extrap_views = sorted(list(val_views) + list(test_views))\n",
    "\n",
    "# Define distinct colors for each kernel (avoiding green/red)\n",
    "line_colors = {\n",
    "    'Full Rank': '#1f77b4',      # Blue\n",
    "    'Periodic': '#ff7f0e',        # Orange\n",
    "    'SM (Wrapped)': '#9467bd',    # Purple\n",
    "    'SM (Free)': '#8c564b',       # Brown\n",
    "}\n",
    "\n",
    "# Plot 1: MSE vs View Angle\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "\n",
    "for kernel_name, kernel_config in KERNEL_CONFIGS.items():\n",
    "    if kernel_name in results and 'mean_mse_per_view' in results[kernel_name]:\n",
    "        mean_per_view = results[kernel_name]['mean_mse_per_view']\n",
    "        angles = [v * 20 for v in sorted(mean_per_view.keys())]\n",
    "        mses = [mean_per_view[v] for v in sorted(mean_per_view.keys())]\n",
    "        display_name = kernel_config['display_name']\n",
    "        color = line_colors.get(display_name, kernel_config['color'])\n",
    "        ax.plot(angles, mses, 'o-', label=display_name, \n",
    "                color=color, markersize=8, linewidth=2, alpha=0.8)\n",
    "\n",
    "# Mark training range (training ends at 180¬∞, extrapolation starts at 200¬∞)\n",
    "ax.axvspan(0, 200, alpha=0.15, color='green', zorder=0)\n",
    "ax.axvspan(200, 360, alpha=0.15, color='red', zorder=0)\n",
    "\n",
    "ax.set_xlabel('View Angle (¬∞)', fontsize=16)\n",
    "ax.set_ylabel('Mean MSE', fontsize=16)\n",
    "ax.set_xlim(160, 360)\n",
    "ax.set_xticks([180, 200, 220, 240, 260, 280, 300, 320, 340])\n",
    "ax.tick_params(labelsize=16)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Create custom patches for region legend\n",
    "from matplotlib.patches import Patch\n",
    "region_legend_elements = [\n",
    "    Patch(facecolor='green', alpha=0.15, label='Training range'),\n",
    "    Patch(facecolor='red', alpha=0.15, label='Extrapolation')\n",
    "]\n",
    "\n",
    "# Add region legend (more space for larger text)\n",
    "region_legend = ax.legend(handles=region_legend_elements, loc='upper center', \n",
    "                         bbox_to_anchor=(0.5, -0.12), ncol=2, frameon=False, fontsize=16)\n",
    "ax.add_artist(region_legend)  # Keep this legend when adding the next one\n",
    "\n",
    "# Add kernel legend below (more space for larger text)\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.22), ncol=4, frameon=False, fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./notebooks/analysis/task3_mse_vs_angle.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Saved: task3_mse_vs_angle.png (300 DPI)\")\n",
    "\n",
    "# Plot 2: MSE vs Extrapolation Distance (no region shading, so only one legend)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "\n",
    "for kernel_name, kernel_config in KERNEL_CONFIGS.items():\n",
    "    if kernel_name in results and 'mean_mse_per_view' in results[kernel_name]:\n",
    "        mean_per_view = results[kernel_name]['mean_mse_per_view']\n",
    "        \n",
    "        distances = []\n",
    "        mses = []\n",
    "        for view, mse in sorted(mean_per_view.items()):\n",
    "            dist = compute_extrapolation_distance(view, TRAIN_MAX_ANGLE)\n",
    "            if dist > 0:  # Only extrapolation views\n",
    "                distances.append(dist)\n",
    "                mses.append(mse)\n",
    "        \n",
    "        display_name = kernel_config['display_name']\n",
    "        color = line_colors.get(display_name, kernel_config['color'])\n",
    "        ax.plot(distances, mses, 'o-', label=display_name, \n",
    "                color=color, markersize=8, linewidth=2, alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Distance from Training Range (¬∞)', fontsize=16)\n",
    "ax.set_ylabel('Mean MSE', fontsize=16)\n",
    "ax.tick_params(labelsize=16)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Legend below plot\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), ncol=4, frameon=False, fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./notebooks/analysis/task3_mse_vs_distance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Saved: task3_mse_vs_distance.png (300 DPI)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac841de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-view MSE table\n",
    "per_view_data = []\n",
    "all_extrap_views = sorted([int(v) for v in list(val_views) + list(test_views)])\n",
    "\n",
    "for view in all_extrap_views:\n",
    "    angle = view * 20\n",
    "    dist = compute_extrapolation_distance(view, TRAIN_MAX_ANGLE)\n",
    "    region = 'Near' if view in VAL_VIEW_INDICES else 'Far'\n",
    "    \n",
    "    row = {\n",
    "        'View': f\"{angle}¬∞\", \n",
    "        'Distance': f\"+{dist}¬∞\",\n",
    "        'Region': region\n",
    "    }\n",
    "    for kernel_name, kernel_config in KERNEL_CONFIGS.items():\n",
    "        if kernel_name in results and 'mean_mse_per_view' in results[kernel_name]:\n",
    "            row[kernel_config['display_name']] = results[kernel_name]['mean_mse_per_view'].get(view, np.nan)\n",
    "    per_view_data.append(row)\n",
    "\n",
    "per_view_df = pd.DataFrame(per_view_data)\n",
    "print(\"\\nüìä Per-View MSE (Extrapolation Views):\")\n",
    "print(\"=\"*80)\n",
    "print(per_view_df.to_string(index=False))\n",
    "\n",
    "# Best kernel per view\n",
    "print(\"\\nüèÜ Best Kernel per Extrapolation View:\")\n",
    "kernel_cols = [c for c in per_view_df.columns if c not in ['View', 'Distance', 'Region']]\n",
    "for _, row in per_view_df.iterrows():\n",
    "    best_kernel = min(kernel_cols, key=lambda k: row[k] if pd.notna(row[k]) else float('inf'))\n",
    "    print(f\"   {row['View']} ({row['Region']}): {best_kernel} ({row[best_kernel]:.6f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c833c3",
   "metadata": {},
   "source": [
    "## 9. Periodicity Analysis\n",
    "\n",
    "Check if periodic kernels leverage the wrap-around structure (340¬∞ is close to 0¬∞)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e429b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare MSE at extreme views (340¬∞) which should be close to 0¬∞ in periodic space\n",
    "print(\"üìä Periodicity Benefit Analysis:\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nIf periodic kernels work correctly:\")\n",
    "print(\"- 340¬∞ should have LOWER MSE than 280¬∞ (340¬∞ is 20¬∞ from 0¬∞, 280¬∞ is 60¬∞ from training)\")\n",
    "print(\"- Full Rank should show INCREASING MSE as we go further from training\\n\")\n",
    "\n",
    "for kernel_name, kernel_config in KERNEL_CONFIGS.items():\n",
    "    if kernel_name in results and 'mean_mse_per_view' in results[kernel_name]:\n",
    "        mean_per_view = results[kernel_name]['mean_mse_per_view']\n",
    "        \n",
    "        # Get MSE at key views\n",
    "        mse_280 = mean_per_view.get(14, np.nan)  # 280¬∞\n",
    "        mse_340 = mean_per_view.get(17, np.nan)  # 340¬∞\n",
    "        \n",
    "        if not np.isnan(mse_280) and not np.isnan(mse_340):\n",
    "            ratio = mse_340 / mse_280\n",
    "            pattern = \"‚úÖ PERIODIC (340¬∞ < 280¬∞)\" if ratio < 1 else \"‚ùå NON-PERIODIC (340¬∞ > 280¬∞)\"\n",
    "            print(f\"{kernel_config['display_name']:15s}: 280¬∞={mse_280:.6f}, 340¬∞={mse_340:.6f}, ratio={ratio:.2f} {pattern}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b61809",
   "metadata": {},
   "source": [
    "## 10. Kernel Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05448938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as pl\n",
    "pl.rcdefaults()\n",
    "\n",
    "n_kernels = len([k for k in results if results[k]['kernel_matrices']])\n",
    "if n_kernels > 0:\n",
    "    fig, axes = pl.subplots(2, 2, figsize=(8, 8))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    ax_idx = 0\n",
    "    for kernel_name, kernel_config in KERNEL_CONFIGS.items():\n",
    "        if kernel_name in results and results[kernel_name]['kernel_matrices']:\n",
    "            # Use best seed (lowest test MSE) for consistency\n",
    "            best_seed_idx = np.argmin(results[kernel_name]['mse_test_per_seed'])\n",
    "            K = results[kernel_name]['kernel_matrices'][best_seed_idx]\n",
    "\n",
    "            ax = axes[ax_idx]\n",
    "            im = ax.imshow(K, vmin=-0.4, vmax=1, aspect='auto')\n",
    "            ax.set_title(f\"{kernel_config['display_name']}\\nWW (view cov)\", fontsize=17)\n",
    "\n",
    "            # Mark training vs extrapolation regions (boundary at 9.5 = after view 9 at 180¬∞)\n",
    "            ax.axvline(x=9.5, color='red', linestyle='--', linewidth=2)\n",
    "            ax.axhline(y=9.5, color='red', linestyle='--', linewidth=2)\n",
    "\n",
    "            tick_positions = [0, 5, 10, 17]\n",
    "            tick_labels = [f\"{p*20}¬∞\" for p in tick_positions]\n",
    "            ax.set_xticks(tick_positions)\n",
    "            ax.set_xticklabels(tick_labels, fontsize=17)\n",
    "            ax.set_yticks(tick_positions)\n",
    "            ax.set_yticklabels(tick_labels, fontsize=17)\n",
    "            ax.tick_params(labelsize=16)\n",
    "\n",
    "            cbar = pl.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "            cbar.ax.tick_params(labelsize=16)\n",
    "            ax_idx += 1\n",
    "\n",
    "    # Hide unused subplots\n",
    "    for i in range(ax_idx, 4):\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    # Create legend with red dashed line\n",
    "    from matplotlib.lines import Line2D\n",
    "    legend_elements = [\n",
    "        Line2D([0], [0], color='red', linestyle='--', linewidth=2, \n",
    "               label='Training/extrapolation boundary')\n",
    "    ]\n",
    "    \n",
    "    # Add legend below the figure\n",
    "    fig.legend(handles=legend_elements, loc='lower center', \n",
    "               bbox_to_anchor=(0.5, -0.05), ncol=1, frameon=False, fontsize=17)\n",
    "    \n",
    "    pl.tight_layout()\n",
    "    pl.savefig('./notebooks/analysis/task3_kernel_matrices.png', dpi=300, bbox_inches='tight')\n",
    "    pl.show()\n",
    "    print(\"üìä Saved: task3_kernel_matrices.png (300 DPI)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No kernel matrices to display\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29ba4ad",
   "metadata": {},
   "source": [
    "## 11. Sample Reconstructions (Far Extrapolation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9995362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 8\n",
    "n_kernels = len([k for k in results if results[k]['mse_test_per_seed']])\n",
    "\n",
    "if n_kernels > 0:\n",
    "    fig, axes = plt.subplots(n_kernels + 1, n_samples, figsize=(n_samples * 1.5, (n_kernels + 1) * 1.5))\n",
    "    \n",
    "    # Ground truth\n",
    "    n_total = len(test_data)\n",
    "    sample_stride = max(1, n_total // n_samples)\n",
    "    sample_indices = list(range(0, n_total, sample_stride))[:n_samples]\n",
    "    Y_gt = test_data.Y[sample_indices].numpy().transpose(0, 2, 3, 1)\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        axes[0, i].imshow(np.clip(Y_gt[i], 0, 1))\n",
    "        axes[0, i].axis('off')\n",
    "        view_idx = int(test_data.Rid[sample_indices[i]].item())\n",
    "        axes[0, i].set_title(f\"{view_idx*20}¬∞\", fontsize=10)\n",
    "    axes[0, 0].set_ylabel('GT', fontsize=12)\n",
    "    \n",
    "    row_idx = 1\n",
    "    for kernel_name, kernel_config in KERNEL_CONFIGS.items():\n",
    "        if kernel_name in results and results[kernel_name]['mse_test_per_seed']:\n",
    "            best_seed_idx = np.argmin(results[kernel_name]['mse_test_per_seed'])\n",
    "            best_run = find_run_folders(CONFIG['results_base'], kernel_config['folder'])[best_seed_idx]\n",
    "            \n",
    "            vae, vm, gp = load_models(best_run, kernel_config, P, Q, CONFIG['xdim'], device)\n",
    "            Y_orig, Y_recon, _ = get_reconstructions(\n",
    "                vae, vm, gp, train_queue, test_queue,\n",
    "                Dt, Wt, Dtest, Wtest, device, n_samples=n_samples\n",
    "            )\n",
    "            \n",
    "            for i in range(n_samples):\n",
    "                axes[row_idx, i].imshow(np.clip(Y_recon[i], 0, 1))\n",
    "                axes[row_idx, i].axis('off')\n",
    "            \n",
    "            mse = results[kernel_name]['mse_test_per_seed'][best_seed_idx]\n",
    "            axes[row_idx, 0].set_ylabel(f\"{kernel_config['display_name']}\\n({mse:.4f})\", fontsize=10)\n",
    "            row_idx += 1\n",
    "    \n",
    "    plt.suptitle('Task 3 (Extrapolation): Reconstructions at Far Views (280¬∞-340¬∞)', fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./notebooks/analysis/task3_reconstructions.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(\"üìä Saved: task3_reconstructions.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4093cf",
   "metadata": {},
   "source": [
    "## 12. Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d3574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "kernel_names_list = [k for k in KERNEL_CONFIGS if k in results and results[k]['mse_test_per_seed']]\n",
    "\n",
    "if len(kernel_names_list) >= 2:\n",
    "    print(\"\\nüìä Pairwise T-Tests on Test MSE (far extrapolation)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for i, k1 in enumerate(kernel_names_list):\n",
    "        for j, k2 in enumerate(kernel_names_list):\n",
    "            if i < j:\n",
    "                mse1 = results[k1]['mse_test_per_seed']\n",
    "                mse2 = results[k2]['mse_test_per_seed']\n",
    "                \n",
    "                t_stat, p_value = stats.ttest_ind(mse1, mse2)\n",
    "                \n",
    "                k1_name = KERNEL_CONFIGS[k1]['display_name']\n",
    "                k2_name = KERNEL_CONFIGS[k2]['display_name']\n",
    "                sig = \"*\" if p_value < 0.05 else \"\"\n",
    "                sig = \"**\" if p_value < 0.01 else sig\n",
    "                print(f\"{k1_name} vs {k2_name}: p = {p_value:.4f} {sig}\")\n",
    "    \n",
    "    print(\"\\n* p < 0.05, ** p < 0.01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710083a7",
   "metadata": {},
   "source": [
    "## 13. Callback-Style Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5959caa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from callbacks import callback_gppvae, _compose_multi\n",
    "import pylab as pl\n",
    "\n",
    "def generate_callback_plot_for_kernel(kernel_name, kernel_config, results, \n",
    "                                       train_queue, test_queue,\n",
    "                                       Dt, Wt, Dtest, Wtest, P, Q, xdim, device,\n",
    "                                       output_file):\n",
    "    if kernel_name not in results or not results[kernel_name]['mse_test_per_seed']:\n",
    "        return None\n",
    "    \n",
    "    pl.rcdefaults()\n",
    "    \n",
    "    best_seed_idx = np.argmin(results[kernel_name]['mse_test_per_seed'])\n",
    "    best_run = find_run_folders(CONFIG['results_base'], kernel_config['folder'])[best_seed_idx]\n",
    "    \n",
    "    vae, vm, gp = load_models(best_run, kernel_config, P, Q, xdim, device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        X = vm.x().cpu().numpy()\n",
    "        W = vm.v().cpu().numpy()\n",
    "        XX = X @ X.T\n",
    "        WW = W @ W.T\n",
    "        covs = {\"XX\": XX[:20, :20], \"WW\": WW}\n",
    "        \n",
    "        Zm = encode_dataset(vae, train_queue, device)\n",
    "        Vt = vm(Dt, Wt).detach()\n",
    "        Vtest = vm(Dtest, Wtest).detach()\n",
    "        \n",
    "        vs = gp.get_vs()\n",
    "        U, UBi, _ = gp.U_UBi_Shb([Vt], vs)\n",
    "        Kiz = gp.solve(Zm, U, UBi, vs)\n",
    "        Zo_test = vs[0] * Vtest.mm(Vt.transpose(0, 1).mm(Kiz))\n",
    "        \n",
    "        n_total = len(test_queue.dataset)\n",
    "        sample_stride = max(1, n_total // 24)\n",
    "        sample_indices = np.arange(0, n_total, sample_stride)[:24]\n",
    "        sample_indices_tensor = torch.tensor(sample_indices, dtype=torch.long).to(device)\n",
    "        \n",
    "        Yv = test_queue.dataset.Y[sample_indices].numpy().transpose((0, 2, 3, 1))\n",
    "        Y_input = test_queue.dataset.Y[sample_indices].to(device)\n",
    "        Zm_test, _ = vae.encode(Y_input)\n",
    "        Yr = vae.decode(Zm_test).data.cpu().numpy().transpose((0, 2, 3, 1))\n",
    "        Yo = vae.decode(Zo_test[sample_indices_tensor]).data.cpu().numpy().transpose((0, 2, 3, 1))\n",
    "        \n",
    "        imgs = {\"Yv\": Yv, \"Yr\": Yr, \"Yo\": Yo}\n",
    "        \n",
    "        n_seeds = len(results[kernel_name]['mse_test_per_seed'])\n",
    "        history = {\n",
    "            \"loss\": results[kernel_name]['mse_test_per_seed'],\n",
    "            \"vs\": [[vs.cpu().numpy()[0], vs.cpu().numpy()[1]]] * n_seeds,\n",
    "            \"recon_term\": [0.0] * n_seeds,\n",
    "            \"gp_nll\": [0.0] * n_seeds,\n",
    "            \"mse_out\": results[kernel_name]['mse_test_per_seed'],\n",
    "            \"mse\": [results[kernel_name]['mean_mse_test']] * n_seeds,\n",
    "            \"mse_val\": results[kernel_name]['mse_val_per_seed'],\n",
    "        }\n",
    "    \n",
    "    callback_gppvae(epoch=n_seeds - 1, history=history, covs=covs, imgs=imgs, ffile=output_file)\n",
    "    return output_file\n",
    "\n",
    "print(\"‚úÖ Callback plot function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92000c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate callback plots\n",
    "for kernel_name, kernel_config in KERNEL_CONFIGS.items():\n",
    "    if kernel_name in results and results[kernel_name]['mse_test_per_seed']:\n",
    "        print(f\"\\nüìä Generating callback plot for {kernel_config['display_name']}...\")\n",
    "        filename = f'./notebooks/analysis/task3_callback_{kernel_name}.png'\n",
    "        result = generate_callback_plot_for_kernel(\n",
    "            kernel_name, kernel_config, results,\n",
    "            train_queue, test_queue,\n",
    "            Dt, Wt, Dtest, Wtest, P, Q, CONFIG['xdim'], device,\n",
    "            output_file=filename\n",
    "        )\n",
    "        if result:\n",
    "            print(f\"   ‚úÖ Saved: {filename}\")\n",
    "            from IPython.display import Image, display\n",
    "            display(Image(filename=filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88521340",
   "metadata": {},
   "source": [
    "## 14. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9d7311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed results\n",
    "detailed_results = []\n",
    "\n",
    "for kernel_name, kernel_config in KERNEL_CONFIGS.items():\n",
    "    if kernel_name in results and results[kernel_name]['mse_test_per_seed']:\n",
    "        for seed_idx in range(len(results[kernel_name]['mse_test_per_seed'])):\n",
    "            detailed_results.append({\n",
    "                'kernel': kernel_config['display_name'],\n",
    "                'seed': seed_idx,\n",
    "                'val_mse': results[kernel_name]['mse_val_per_seed'][seed_idx],\n",
    "                'test_mse': results[kernel_name]['mse_test_per_seed'][seed_idx],\n",
    "                'variance_ratio': results[kernel_name]['variance_ratios'][seed_idx],\n",
    "            })\n",
    "\n",
    "detailed_df = pd.DataFrame(detailed_results)\n",
    "detailed_df.to_csv('./notebooks/analysis/task3_detailed_results.csv', index=False)\n",
    "print(\"üìä Saved: task3_detailed_results.csv\")\n",
    "\n",
    "summary_df.to_csv('./notebooks/analysis/task3_summary.csv', index=False)\n",
    "print(\"üìä Saved: task3_summary.csv\")\n",
    "\n",
    "per_view_df.to_csv('./notebooks/analysis/task3_per_view_mse.csv', index=False)\n",
    "print(\"üìä Saved: task3_per_view_mse.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d8efef",
   "metadata": {},
   "source": [
    "## 15. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5354e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä TASK 3 (EXTRAPOLATION) - FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüéØ Research Question:\")\n",
    "print(\"   How do different kernel-induced inductive biases influence\")\n",
    "print(\"   EXTRAPOLATION to unseen extreme views?\")\n",
    "\n",
    "print(\"\\nüìä Hypothesis Check:\")\n",
    "for kernel_name, kernel_config in KERNEL_CONFIGS.items():\n",
    "    if kernel_name in results and results[kernel_name]['mse_test_per_seed']:\n",
    "        print(f\"   {kernel_config['display_name']:15s}: {kernel_config['expected']}\")\n",
    "\n",
    "print(\"\\nüèÜ Kernel Ranking (by Far Extrapolation MSE):\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "ranked = sorted(\n",
    "    [(k, results[k]['mean_mse_test'], results[k]['std_mse_test'], results[k]['extrap_degradation']) \n",
    "     for k in results if results[k]['mse_test_per_seed']],\n",
    "    key=lambda x: x[1]\n",
    ")\n",
    "\n",
    "for rank, (kernel_name, mean_mse, std_mse, degradation) in enumerate(ranked, 1):\n",
    "    display_name = KERNEL_CONFIGS[kernel_name]['display_name']\n",
    "    medal = \"ü•á\" if rank == 1 else \"ü•à\" if rank == 2 else \"ü•â\" if rank == 3 else \"  \"\n",
    "    print(f\"{medal} {rank}. {display_name:15s}: {mean_mse:.6f} ¬± {std_mse:.6f} (degradation: {degradation:.2f}x)\")\n",
    "\n",
    "print(\"\\nüìä Key Findings:\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "# Check if periodic kernels outperform full rank\n",
    "if 'fullrank' in results and 'periodic' in results:\n",
    "    fr_mse = results['fullrank']['mean_mse_test']\n",
    "    periodic_mse = results['periodic']['mean_mse_test']\n",
    "    if periodic_mse < fr_mse:\n",
    "        improvement = (fr_mse - periodic_mse) / fr_mse * 100\n",
    "        print(f\"   ‚úÖ Periodic kernel outperforms Full Rank by {improvement:.1f}%\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå Full Rank performed better than Periodic (unexpected)\")\n",
    "\n",
    "print(\"\\nüìÅ Generated Files:\")\n",
    "print(\"-\"*50)\n",
    "print(\"   - task3_near_vs_far.png\")\n",
    "print(\"   - task3_per_view_extrapolation.png\")\n",
    "print(\"   - task3_kernel_matrices.png\")\n",
    "print(\"   - task3_reconstructions.png\")\n",
    "print(\"   - task3_detailed_results.csv\")\n",
    "print(\"   - task3_summary.csv\")\n",
    "print(\"   - task3_per_view_mse.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ Analysis Complete!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ba694b",
   "metadata": {},
   "source": [
    "## 16. Extract Learned Kernel Parameters (Best Seeds)\n",
    "\n",
    "Extract the learned hyperparameters from the best-performing seed for each kernel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2072acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üìä LEARNED KERNEL PARAMETERS (BEST SEEDS)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for kernel_name, kernel_config in KERNEL_CONFIGS.items():\n",
    "    if kernel_name not in results or not results[kernel_name]['mse_test_per_seed']:\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üî∑ {kernel_config['display_name']}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Get best seed\n",
    "    best_seed_idx = np.argmin(results[kernel_name]['mse_test_per_seed'])\n",
    "    best_run = find_run_folders(CONFIG['results_base'], kernel_config['folder'])[best_seed_idx]\n",
    "    \n",
    "    print(f\"Best seed: {best_seed_idx} (Test MSE: {results[kernel_name]['mse_test_per_seed'][best_seed_idx]:.6f})\")\n",
    "    print(f\"Run folder: {os.path.basename(best_run)}\\n\")\n",
    "    \n",
    "    # Load checkpoint\n",
    "    weights_dir = os.path.join(best_run, 'weights')\n",
    "    gp_weights_path = os.path.join(weights_dir, 'gp_weights.best.pt')\n",
    "    \n",
    "    if os.path.exists(gp_weights_path):\n",
    "        checkpoint = torch.load(gp_weights_path, map_location='cpu')\n",
    "        \n",
    "        # Load the model to extract parameters\n",
    "        vm_temp = Vmodel(\n",
    "            P=P, Q=Q, p=CONFIG['xdim'],\n",
    "            view_kernel=kernel_config['view_kernel'],\n",
    "            **kernel_config['kernel_kwargs']\n",
    "        )\n",
    "        vm_temp.load_state_dict(checkpoint['vm_state'])\n",
    "        \n",
    "        gp_temp = GP(n_rand_effs=1)\n",
    "        gp_temp.load_state_dict(checkpoint['gp_state'])\n",
    "        \n",
    "        # Extract GP variance components\n",
    "        vs = gp_temp.get_vs().detach().cpu().numpy()\n",
    "        variance_ratio = vs[0] / (vs[0] + vs[1])\n",
    "        \n",
    "        print(f\"üìà GP Variance Components:\")\n",
    "        print(f\"   v_view (between-view):  {vs[0]:.6f}\")\n",
    "        print(f\"   v_noise (within-view):  {vs[1]:.6f}\")\n",
    "        print(f\"   Variance ratio (v_view / total): {variance_ratio:.4f}\")\n",
    "        \n",
    "        # Extract kernel-specific parameters\n",
    "        print(f\"\\nüîß Kernel Hyperparameters:\")\n",
    "        \n",
    "        if kernel_config['view_kernel'] == 'periodic':\n",
    "            # Periodic kernel parameters\n",
    "            state_dict = vm_temp.kernel.state_dict()\n",
    "            period = state_dict['period'].item() if 'period' in state_dict else 360.0\n",
    "            lengthscale = torch.exp(state_dict['log_lengthscale']).item() if 'log_lengthscale' in state_dict else None\n",
    "            variance = torch.exp(state_dict['log_variance']).item() if 'log_variance' in state_dict else None\n",
    "            \n",
    "            print(f\"   Period: {period:.2f}¬∞\")\n",
    "            if lengthscale is not None:\n",
    "                print(f\"   Lengthscale: {lengthscale:.4f}\")\n",
    "            if variance is not None:\n",
    "                print(f\"   Variance: {variance:.4f}\")\n",
    "        \n",
    "        elif kernel_config['view_kernel'] == 'sm_circle':\n",
    "            # Spectral Mixture parameters\n",
    "            state_dict = vm_temp.kernel.state_dict()\n",
    "            \n",
    "            if 'log_weight' in state_dict:\n",
    "                weights = torch.exp(state_dict['log_weight']).detach().cpu().numpy()\n",
    "                weights_normalized = weights / weights.sum()\n",
    "                print(f\"   Mixture weights: {weights_normalized}\")\n",
    "            \n",
    "            if 'log_freq' in state_dict:\n",
    "                freqs = torch.exp(state_dict['log_freq']).detach().cpu().numpy()\n",
    "                periods = 1.0 / freqs\n",
    "                print(f\"   Frequencies: {freqs}\")\n",
    "                print(f\"   Periods: {periods}¬∞\")\n",
    "            \n",
    "            if 'log_length' in state_dict:\n",
    "                lengths = torch.exp(state_dict['log_length']).detach().cpu().numpy()\n",
    "                print(f\"   Lengthscales: {lengths}\")\n",
    "            \n",
    "            if 'log_var' in state_dict:\n",
    "                variances = torch.exp(state_dict['log_var']).detach().cpu().numpy()\n",
    "                print(f\"   Component variances: {variances}\")\n",
    "        \n",
    "        elif kernel_config['view_kernel'] == 'full_rank':\n",
    "            # Full rank - just show the learned covariance structure\n",
    "            with torch.no_grad():\n",
    "                K = vm_temp.get_kernel_matrix().cpu().numpy()\n",
    "            print(f\"   Learned full Q√óQ covariance matrix\")\n",
    "            print(f\"   Matrix shape: {K.shape}\")\n",
    "            print(f\"   Mean correlation: {K[np.triu_indices_from(K, k=1)].mean():.4f}\")\n",
    "            print(f\"   Std correlation: {K[np.triu_indices_from(K, k=1)].std():.4f}\")\n",
    "        \n",
    "        # Show raw state dict keys for reference\n",
    "        print(f\"\\nüìù Available state dict keys:\")\n",
    "        for key in vm_temp.kernel.state_dict().keys():\n",
    "            value = vm_temp.kernel.state_dict()[key]\n",
    "            if value.numel() <= 10:  # Only show small tensors\n",
    "                print(f\"   {key}: {value.detach().cpu().numpy()}\")\n",
    "            else:\n",
    "                print(f\"   {key}: shape {value.shape}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Checkpoint not found: {gp_weights_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ Parameter extraction complete!\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bdbdf5",
   "metadata": {},
   "source": [
    "## 17. Visualize Learned SM Kernel Functions\n",
    "\n",
    "Plot the kernel functions k(Œ∏, Œ∏') for the best-performing SM Wrapped and SM Free models, along with GP prior samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa0d8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as pl\n",
    "pl.rcdefaults()\n",
    "\n",
    "# Define which SM kernels to visualize\n",
    "sm_kernels_to_plot = ['sm_wrapped', 'sm_free']\n",
    "sm_kernel_names = {'sm_wrapped': 'SM (Wrapped)', 'sm_free': 'SM (Free)'}\n",
    "sm_kernel_colors = {'sm_wrapped': '#9467bd', 'sm_free': '#8c564b'}\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "for row_idx, kernel_name in enumerate(sm_kernels_to_plot):\n",
    "    if kernel_name not in results or not results[kernel_name]['mse_test_per_seed']:\n",
    "        print(f\"‚ö†Ô∏è {kernel_name} not found in results\")\n",
    "        continue\n",
    "    \n",
    "    kernel_config = KERNEL_CONFIGS[kernel_name]\n",
    "    display_name = kernel_config['display_name']\n",
    "    color = sm_kernel_colors[kernel_name]\n",
    "    \n",
    "    # Get best seed and load model\n",
    "    best_seed_idx = np.argmin(results[kernel_name]['mse_test_per_seed'])\n",
    "    best_run = find_run_folders(CONFIG['results_base'], kernel_config['folder'])[best_seed_idx]\n",
    "    \n",
    "    # Load the model\n",
    "    weights_dir = os.path.join(best_run, 'weights')\n",
    "    gp_weights_path = os.path.join(weights_dir, 'gp_weights.best.pt')\n",
    "    checkpoint = torch.load(gp_weights_path, map_location='cpu')\n",
    "    \n",
    "    vm_temp = Vmodel(\n",
    "        P=P, Q=Q, p=CONFIG['xdim'],\n",
    "        view_kernel=kernel_config['view_kernel'],\n",
    "        **kernel_config['kernel_kwargs']\n",
    "    )\n",
    "    vm_temp.load_state_dict(checkpoint['vm_state'])\n",
    "    vm_temp.eval()\n",
    "    \n",
    "    # Get the kernel\n",
    "    kernel = vm_temp.kernel\n",
    "    \n",
    "    # =====================\n",
    "    # Plot 1: Kernel function k(0¬∞, Œ∏) - correlation with reference angle 0¬∞\n",
    "    # =====================\n",
    "    ax = axes[row_idx, 0]\n",
    "    \n",
    "    # Create dense angle grid for smooth visualization\n",
    "    dense_angles = torch.linspace(0, 360, 361)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        K_dense = kernel(dense_angles).cpu().numpy()\n",
    "    \n",
    "    # k(0¬∞, Œ∏) is the first row of K\n",
    "    k_from_0 = K_dense[0, :]\n",
    "    \n",
    "    ax.plot(dense_angles.numpy(), k_from_0, color=color, linewidth=2)\n",
    "    ax.axvline(x=200, color='red', linestyle='--', linewidth=1.5, alpha=0.7, label='Training boundary')\n",
    "    ax.axvspan(0, 200, alpha=0.1, color='green')\n",
    "    ax.axvspan(200, 360, alpha=0.1, color='red')\n",
    "    \n",
    "    ax.set_xlabel('Angle Œ∏ (¬∞)', fontsize=16)\n",
    "    ax.set_ylabel('k(0¬∞, Œ∏)', fontsize=16)\n",
    "    ax.set_title(f'{display_name}\\nKernel Function', fontsize=16)\n",
    "    ax.set_xlim(0, 360)\n",
    "    ax.set_xticks([0, 90, 180, 270, 360])\n",
    "    ax.tick_params(labelsize=14)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.legend(fontsize=12)\n",
    "    \n",
    "    # =====================\n",
    "    # Plot 2: Full kernel matrix (18x18) from learned parameters\n",
    "    # =====================\n",
    "    ax = axes[row_idx, 1]\n",
    "    \n",
    "    # Get the 18-view kernel matrix\n",
    "    view_angles = torch.tensor([i * 20.0 for i in range(18)])\n",
    "    with torch.no_grad():\n",
    "        K_18 = kernel(view_angles).cpu().numpy()\n",
    "    \n",
    "    im = ax.imshow(K_18, vmin=-0.5, vmax=1, aspect='auto', cmap='RdBu_r')\n",
    "    ax.axvline(x=9.5, color='black', linestyle='--', linewidth=2)\n",
    "    ax.axhline(y=9.5, color='black', linestyle='--', linewidth=2)\n",
    "    \n",
    "    tick_positions = [0, 4, 9, 13, 17]\n",
    "    tick_labels = [f\"{p*20}¬∞\" for p in tick_positions]\n",
    "    ax.set_xticks(tick_positions)\n",
    "    ax.set_xticklabels(tick_labels, fontsize=12)\n",
    "    ax.set_yticks(tick_positions)\n",
    "    ax.set_yticklabels(tick_labels, fontsize=12)\n",
    "    ax.set_title(f'{display_name}\\nLearned View Covariance', fontsize=16)\n",
    "    plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    \n",
    "    # =====================\n",
    "    # Plot 3: GP prior samples\n",
    "    # =====================\n",
    "    ax = axes[row_idx, 2]\n",
    "    \n",
    "    # Sample from GP prior with learned kernel\n",
    "    n_samples = 5\n",
    "    dense_angles_for_samples = torch.linspace(0, 340, 18)  # Match 18 views\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        K_for_samples = kernel(dense_angles_for_samples).cpu().numpy()\n",
    "    \n",
    "    # Add small jitter for numerical stability\n",
    "    K_for_samples = K_for_samples + 1e-4 * np.eye(K_for_samples.shape[0])\n",
    "    \n",
    "    # Cholesky decomposition for sampling\n",
    "    try:\n",
    "        L = np.linalg.cholesky(K_for_samples)\n",
    "        \n",
    "        np.random.seed(42)  # For reproducibility\n",
    "        for i in range(n_samples):\n",
    "            z = np.random.randn(K_for_samples.shape[0])\n",
    "            sample = L @ z\n",
    "            alpha = 0.5 if i > 0 else 1.0\n",
    "            lw = 1.5 if i > 0 else 2.5\n",
    "            ax.plot(dense_angles_for_samples.numpy(), sample, 'o-', \n",
    "                    color=color, alpha=alpha, linewidth=lw,\n",
    "                    label='GP prior samples' if i == 0 else None)\n",
    "        \n",
    "        ax.axvline(x=200, color='red', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "        ax.axvspan(0, 200, alpha=0.1, color='green')\n",
    "        ax.axvspan(200, 360, alpha=0.1, color='red')\n",
    "        \n",
    "    except np.linalg.LinAlgError:\n",
    "        ax.text(0.5, 0.5, 'Cholesky failed\\n(K not PSD)', \n",
    "                transform=ax.transAxes, ha='center', fontsize=14)\n",
    "    \n",
    "    ax.set_xlabel('View Angle (¬∞)', fontsize=16)\n",
    "    ax.set_ylabel('f(Œ∏)', fontsize=16)\n",
    "    ax.set_title(f'{display_name}\\nGP Prior Samples', fontsize=16)\n",
    "    ax.set_xlim(0, 360)\n",
    "    ax.set_xticks([0, 90, 180, 270, 360])\n",
    "    ax.tick_params(labelsize=14)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.legend(fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./notebooks/analysis/task3_sm_kernel_visualization.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Saved: task3_sm_kernel_visualization.png (300 DPI)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c265ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed comparison of SM kernel components\n",
    "print(\"=\"*70)\n",
    "print(\"üìä SM KERNEL COMPONENT ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "for idx, kernel_name in enumerate(['sm_wrapped', 'sm_free']):\n",
    "    if kernel_name not in results or not results[kernel_name]['mse_test_per_seed']:\n",
    "        continue\n",
    "    \n",
    "    kernel_config = KERNEL_CONFIGS[kernel_name]\n",
    "    display_name = kernel_config['display_name']\n",
    "    color = sm_kernel_colors[kernel_name]\n",
    "    \n",
    "    # Get best seed and load model\n",
    "    best_seed_idx = np.argmin(results[kernel_name]['mse_test_per_seed'])\n",
    "    best_run = find_run_folders(CONFIG['results_base'], kernel_config['folder'])[best_seed_idx]\n",
    "    \n",
    "    weights_dir = os.path.join(best_run, 'weights')\n",
    "    gp_weights_path = os.path.join(weights_dir, 'gp_weights.best.pt')\n",
    "    checkpoint = torch.load(gp_weights_path, map_location='cpu')\n",
    "    \n",
    "    vm_temp = Vmodel(\n",
    "        P=P, Q=Q, p=CONFIG['xdim'],\n",
    "        view_kernel=kernel_config['view_kernel'],\n",
    "        **kernel_config['kernel_kwargs']\n",
    "    )\n",
    "    vm_temp.load_state_dict(checkpoint['vm_state'])\n",
    "    kernel = vm_temp.kernel\n",
    "    \n",
    "    # Extract learned parameters\n",
    "    weights = kernel.weights.detach().cpu().numpy()\n",
    "    means = kernel.means.detach().cpu().numpy()  # frequencies\n",
    "    variances = kernel.variances.detach().cpu().numpy()\n",
    "    \n",
    "    print(f\"\\nüî∑ {display_name}:\")\n",
    "    print(f\"   Mixture weights: {weights}\")\n",
    "    print(f\"   Frequencies (Œº): {means}\")\n",
    "    print(f\"   Periods (1/Œº): {1.0/means}¬∞\")\n",
    "    print(f\"   Variances (œÉ¬≤): {variances}\")\n",
    "    \n",
    "    # =====================\n",
    "    # Left plot: Individual SM components\n",
    "    # =====================\n",
    "    ax = axes[idx, 0]\n",
    "    \n",
    "    # Dense angle grid\n",
    "    tau = np.linspace(0, 180, 361)  # lag distance for wrapped kernel\n",
    "    \n",
    "    colors_comp = ['#e74c3c', '#3498db', '#2ecc71', '#9b59b6'][:len(weights)]\n",
    "    \n",
    "    for q in range(len(weights)):\n",
    "        w = weights[q]\n",
    "        mu = means[q]\n",
    "        var = variances[q]\n",
    "        \n",
    "        # SM component: w * exp(-2*pi^2*var*tau^2) * cos(2*pi*mu*tau)\n",
    "        if kernel.use_angle_input:\n",
    "            # Normalized distance\n",
    "            D = tau / 360.0\n",
    "        else:\n",
    "            # Raw degree distance\n",
    "            D = tau\n",
    "        \n",
    "        exp_term = np.exp(-2 * (np.pi ** 2) * var * (D ** 2))\n",
    "        cos_term = np.cos(2 * np.pi * mu * D)\n",
    "        component = w * exp_term * cos_term\n",
    "        \n",
    "        period = 1.0 / mu if mu > 0 else np.inf\n",
    "        ax.plot(tau, component, color=colors_comp[q], linewidth=2.5, \n",
    "                label=f'Component {q+1}: w={w:.2f}, T={period:.0f}¬∞')\n",
    "    \n",
    "    # Total kernel\n",
    "    with torch.no_grad():\n",
    "        tau_torch = torch.tensor(tau, dtype=torch.float32)\n",
    "        # For k(0, tau), we compute full matrix and take first row\n",
    "        # But for efficiency, compute manually\n",
    "        if kernel.use_angle_input:\n",
    "            D_torch = tau_torch / 360.0\n",
    "        else:\n",
    "            D_torch = tau_torch\n",
    "        \n",
    "        K_total = torch.zeros_like(D_torch)\n",
    "        for q in range(len(weights)):\n",
    "            w = kernel.weights[q]\n",
    "            mu = kernel.means[q]\n",
    "            var = kernel.variances[q]\n",
    "            exp_term = torch.exp(-2 * (np.pi ** 2) * var * (D_torch ** 2))\n",
    "            cos_term = torch.cos(2 * np.pi * mu * D_torch)\n",
    "            K_total = K_total + w * exp_term * cos_term\n",
    "        \n",
    "        ax.plot(tau, K_total.numpy(), 'k--', linewidth=2, label='Total k(œÑ)')\n",
    "    \n",
    "    ax.axhline(y=0, color='gray', linestyle='-', linewidth=0.5, alpha=0.5)\n",
    "    ax.set_xlabel('Lag Distance œÑ (¬∞)', fontsize=16)\n",
    "    ax.set_ylabel('k(œÑ)', fontsize=16)\n",
    "    ax.set_title(f'{display_name}\\nSM Kernel Components', fontsize=16)\n",
    "    ax.set_xlim(0, 180)\n",
    "    ax.tick_params(labelsize=14)\n",
    "    ax.legend(fontsize=11, loc='upper right')\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    # =====================\n",
    "    # Right plot: Kernel correlation at key angles\n",
    "    # =====================\n",
    "    ax = axes[idx, 1]\n",
    "    \n",
    "    # Compute k(0¬∞, Œ∏) for all angles\n",
    "    angles_full = torch.linspace(0, 360, 361)\n",
    "    with torch.no_grad():\n",
    "        K_full = kernel(angles_full).cpu().numpy()\n",
    "    k_from_0 = K_full[0, :]\n",
    "    \n",
    "    ax.plot(angles_full.numpy(), k_from_0, color=color, linewidth=2.5, label='k(0¬∞, Œ∏)')\n",
    "    \n",
    "    # Mark specific angles\n",
    "    key_angles = [0, 20, 180, 200, 280, 340, 360]\n",
    "    for angle in key_angles:\n",
    "        idx_angle = int(angle)\n",
    "        if idx_angle < len(k_from_0):\n",
    "            ax.scatter(angle, k_from_0[idx_angle], s=80, color='black', zorder=5)\n",
    "            ax.annotate(f'{k_from_0[idx_angle]:.2f}', \n",
    "                       (angle, k_from_0[idx_angle]), \n",
    "                       textcoords='offset points', xytext=(5, 10), fontsize=10)\n",
    "    \n",
    "    ax.axvline(x=200, color='red', linestyle='--', linewidth=2, alpha=0.7, label='Training boundary')\n",
    "    ax.axvspan(0, 200, alpha=0.1, color='green')\n",
    "    ax.axvspan(200, 360, alpha=0.1, color='red')\n",
    "    \n",
    "    ax.set_xlabel('Angle Œ∏ (¬∞)', fontsize=16)\n",
    "    ax.set_ylabel('k(0¬∞, Œ∏)', fontsize=16)\n",
    "    ax.set_title(f'{display_name}\\nKernel Correlation from 0¬∞', fontsize=16)\n",
    "    ax.set_xlim(0, 360)\n",
    "    ax.set_xticks([0, 90, 180, 270, 360])\n",
    "    ax.tick_params(labelsize=14)\n",
    "    ax.legend(fontsize=12)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./notebooks/analysis/task3_sm_kernel_components.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Saved: task3_sm_kernel_components.png (300 DPI)\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
