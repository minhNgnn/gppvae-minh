{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76ec07dd",
   "metadata": {},
   "source": [
    "# GP-VAE Training on COIL-100 (Extrapolation Task) - Spectral Mixture Kernel\n",
    "\n",
    "This notebook trains **GP-VAE** on COIL-100 dataset using the **Spectral Mixture (SM) kernel** for the **extrapolation task**.\n",
    "\n",
    "## Task: Extrapolation\n",
    "- **Train**: 10 views (0¬∞-180¬∞) - first half of rotation\n",
    "- **Val**: 2 views (200¬∞, 220¬∞) - immediately after train\n",
    "- **Test**: 6 views (240¬∞-340¬∞) - far extrapolation\n",
    "- **Goal**: Predict views BEYOND the training range using GP extrapolation\n",
    "\n",
    "## Kernel: Spectral Mixture (SM)\n",
    "- **Mixture of Gaussians in spectral domain** for flexible patterns\n",
    "- k(Œ∏, Œ∏') = Œ£·µ¢ w·µ¢ √ó exp(-2œÄ¬≤œÉ·µ¢¬≤d¬≤) √ó cos(2œÄŒº·µ¢d)\n",
    "- where d = wrapped lag distance\n",
    "- **Parameters**: 3 per mixture component (weight, frequency, lengthscale)\n",
    "- **Best for**: Complex periodic patterns, multiple frequency components\n",
    "\n",
    "## Dataset Info:\n",
    "- **COIL-100**: 100 objects √ó 18 views (every 20¬∞: 0¬∞, 20¬∞, ..., 340¬∞)\n",
    "- **Image size**: 128√ó128√ó3 RGB\n",
    "\n",
    "## Prerequisites:\n",
    "- ‚úÖ Trained VAE weights from `train_vae_colab_extrapolation.ipynb`\n",
    "- ‚úÖ COIL-100 data file: `data/coil-100/coil100_task3_extrapolation.h5`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51805daa",
   "metadata": {},
   "source": [
    "## 1. Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d70b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è WARNING: GPU not detected!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49832bce",
   "metadata": {},
   "source": [
    "## 2. Auto-Detect Project Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c4731a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "print(f\"üìç Current directory: {current_dir}\")\n",
    "\n",
    "# Task configuration\n",
    "DATA_TASK = \"task3_extrapolation\"\n",
    "KERNEL_TYPE = \"sm_circle\"\n",
    "\n",
    "if current_dir == '/content':\n",
    "    print(\"\\nüîÑ Mounting Google Drive...\")\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        drive_path = '/content/drive/MyDrive/gppvae'\n",
    "        if os.path.exists(drive_path):\n",
    "            PROJECT_PATH = drive_path\n",
    "            print(f\"‚úÖ Found project in Google Drive: {PROJECT_PATH}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Project not found at: {drive_path}\")\n",
    "            PROJECT_PATH = '/content'\n",
    "    except Exception as e:\n",
    "        print(f\"Could not mount Drive: {e}\")\n",
    "        PROJECT_PATH = '/content'\n",
    "else:\n",
    "    if 'notebooks' in current_dir:\n",
    "        PROJECT_PATH = os.path.dirname(current_dir)\n",
    "    else:\n",
    "        PROJECT_PATH = current_dir\n",
    "    print(f\"üíª Using project path: {PROJECT_PATH}\")\n",
    "\n",
    "# Check required files\n",
    "print(f\"\\nüîç Checking required files:\")\n",
    "data_path = os.path.join(PROJECT_PATH, f'data/coil-100/coil100_{DATA_TASK}.h5')\n",
    "required = {\n",
    "    'GPPVAE code': os.path.exists(os.path.join(PROJECT_PATH, 'GPPVAE')),\n",
    "    'COIL-100 data': os.path.exists(data_path),\n",
    "}\n",
    "\n",
    "# Look for VAE weights trained on extrapolation task\n",
    "vae_base_dir = os.path.join(PROJECT_PATH, f'out/vae_colab_{DATA_TASK}')\n",
    "vae_run_found = False\n",
    "if os.path.exists(vae_base_dir):\n",
    "    runs = [d for d in os.listdir(vae_base_dir) if os.path.isdir(os.path.join(vae_base_dir, d))]\n",
    "    for run in runs:\n",
    "        weights_dir = os.path.join(vae_base_dir, run, 'weights')\n",
    "        if os.path.exists(weights_dir) and any(f.endswith('.pt') for f in os.listdir(weights_dir)):\n",
    "            vae_run_found = True\n",
    "            break\n",
    "required['VAE weights'] = vae_run_found\n",
    "\n",
    "for name, exists in required.items():\n",
    "    status = \"‚úÖ\" if exists else \"‚ùå\"\n",
    "    print(f\"   {status} {name}\")\n",
    "\n",
    "print(f\"\\nüìä Extrapolation Task Info:\")\n",
    "print(f\"   Train: 10 views (0¬∞-180¬∞) √ó 100 objects = 1000 samples\")\n",
    "print(f\"   Val: 2 views (200¬∞, 220¬∞) √ó 100 objects = 200 samples\")\n",
    "print(f\"   Test: 6 views (240¬∞-340¬∞) √ó 100 objects = 600 samples\")\n",
    "print(f\"   ‚ö†Ô∏è This is a HARD task: predicting beyond training range!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3890c430",
   "metadata": {},
   "source": [
    "## 3. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f880897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q wandb==0.12.21 imageio==2.15.0 pyyaml\n",
    "\n",
    "import wandb\n",
    "import numpy as np\n",
    "print(\"‚úÖ All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe87337",
   "metadata": {},
   "source": [
    "## 4. Login to W&B (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb8fadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8360b4",
   "metadata": {},
   "source": [
    "## 5. Navigate to Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba335e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir(PROJECT_PATH)\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "\n",
    "sys.path.insert(0, os.path.join(PROJECT_PATH, 'GPPVAE/pysrc/coil100'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1e62f9",
   "metadata": {},
   "source": [
    "## 6. Find VAE Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3001e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# Look for VAE trained on extrapolation task\n",
    "vae_base_dir = f'./out/vae_colab_{DATA_TASK}'\n",
    "vae_runs = []\n",
    "\n",
    "if os.path.exists(vae_base_dir):\n",
    "    for run_dir in sorted(os.listdir(vae_base_dir), reverse=True):\n",
    "        run_path = os.path.join(vae_base_dir, run_dir)\n",
    "        cfg_path = os.path.join(run_path, 'vae.cfg.p')\n",
    "        weights_dir = os.path.join(run_path, 'weights')\n",
    "\n",
    "        if os.path.exists(cfg_path) and os.path.exists(weights_dir):\n",
    "            weight_files = sorted([f for f in os.listdir(weights_dir) if f.endswith('.pt')])\n",
    "            if weight_files:\n",
    "                vae_runs.append({\n",
    "                    'run_dir': run_dir,\n",
    "                    'cfg_path': cfg_path,\n",
    "                    'weights_dir': weights_dir,\n",
    "                    'weight_files': weight_files\n",
    "                })\n",
    "\n",
    "if vae_runs:\n",
    "    print(f\"‚úÖ Found {len(vae_runs)} VAE run(s) for extrapolation task\")\n",
    "    latest = vae_runs[0]\n",
    "    print(f\"\\nüí° Latest: {latest['run_dir']}\")\n",
    "    print(f\"   VAE_CFG = '{latest['cfg_path']}'\")\n",
    "    print(f\"   VAE_WEIGHTS = '{os.path.join(latest['weights_dir'], latest['weight_files'][-1])}'\")\n",
    "else:\n",
    "    print(\"‚ùå No VAE runs found for extrapolation task!\")\n",
    "    print(\"   Run train_vae_colab_extrapolation.ipynb first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252e805d",
   "metadata": {},
   "source": [
    "## 7. Configure Training\n",
    "\n",
    "**Spectral Mixture Kernel Parameters:**\n",
    "- `num_mixtures`: Number of mixture components (default: 2)\n",
    "- SM kernel learns: weights, frequencies (means), variances\n",
    "\n",
    "**‚ö†Ô∏è Important for Extrapolation:**\n",
    "- SM kernel with wrapped distance helps capture circular structure\n",
    "- Views at 340¬∞ are only 20¬∞ away from 0¬∞ (which IS in training) via wrapped distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64b1d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# ============================================================================\n",
    "# UPDATE THESE PATHS!\n",
    "# ============================================================================\n",
    "VAE_CFG = './out/vae_colab_task3_extrapolation/YYYYMMDD_HHMMSS/vae.cfg.p'  # UPDATE\n",
    "VAE_WEIGHTS = './out/vae_colab_task3_extrapolation/YYYYMMDD_HHMMSS/weights/weights.00499.pt'  # UPDATE\n",
    "\n",
    "CONFIG = {\n",
    "    # Data\n",
    "    'data': f'./data/coil-100/coil100_{DATA_TASK}.h5',\n",
    "    'outdir': f'./out/gppvae_coil100_{KERNEL_TYPE}_{DATA_TASK}/{timestamp}',\n",
    "\n",
    "    # VAE\n",
    "    'vae_cfg': VAE_CFG,\n",
    "    'vae_weights': VAE_WEIGHTS,\n",
    "\n",
    "    # Training\n",
    "    'epochs': 1500,\n",
    "    'batch_size': 64,\n",
    "    'vae_lr': 0.001,\n",
    "    'gp_lr': 0.001,\n",
    "    'xdim': 64,\n",
    "\n",
    "    # Kernel - Spectral Mixture\n",
    "    'view_kernel': KERNEL_TYPE,\n",
    "    'kernel_kwargs': {\n",
    "        'num_mixtures': 2,  # 2 mixtures to avoid overfitting\n",
    "        # Frequencies, lengthscales, weights are learned automatically\n",
    "    },\n",
    "\n",
    "    # Logging\n",
    "    'epoch_cb': 100,\n",
    "    'use_wandb': True,\n",
    "    'wandb_project': 'gppvae-coil100',\n",
    "    'wandb_run_name': f'gppvae_{KERNEL_TYPE}_{DATA_TASK}_{timestamp}',\n",
    "    'seed': 0,\n",
    "}\n",
    "\n",
    "print(\"GP-VAE Training Configuration (Extrapolation Task):\")\n",
    "print(\"=\" * 60)\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key:20s}: {value}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if not os.path.exists(CONFIG['vae_weights']):\n",
    "    print(f\"\\n‚ö†Ô∏è Update VAE_CFG and VAE_WEIGHTS paths!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5459d4",
   "metadata": {},
   "source": [
    "## 8. Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2896684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Add coil100 to path FIRST before importing anything\n",
    "# This ensures coil100's data_parser is used, not faceplace's\n",
    "import sys\n",
    "import os\n",
    "\n",
    "coil100_path = os.path.join(PROJECT_PATH, 'GPPVAE/pysrc/coil100')\n",
    "sys.path.insert(0, coil100_path)    # Add coil100 first (so it has priority)\n",
    "\n",
    "os.chdir(coil100_path)\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "print(f\"sys.path priority: coil100 > faceplace\")\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from vae import FaceVAE\n",
    "from vmod import Vmodel\n",
    "from gp import GP\n",
    "import numpy as np\n",
    "import logging\n",
    "import pylab as pl\n",
    "from utils import smartSum, smartAppendDict, smartAppend, export_scripts\n",
    "from callbacks import callback_gppvae\n",
    "import pickle\n",
    "import time\n",
    "import wandb\n",
    "\n",
    "# COIL-100 data parser (explicitly import from coil100, not faceplace)\n",
    "from data_parser import COIL100Dataset, get_n_views, get_num_objects\n",
    "\n",
    "# Verify we're using the right data_parser\n",
    "import data_parser\n",
    "print(f\"‚úÖ data_parser loaded from: {data_parser.__file__}\")\n",
    "if 'coil100' in data_parser.__file__:\n",
    "    print(\"‚úÖ Using COIL-100 data_parser (correct!)\")\n",
    "else:\n",
    "    print(\"‚ùå WARNING: Using faceplace data_parser (wrong!)\")\n",
    "print(\"‚úÖ All modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca85659d",
   "metadata": {},
   "source": [
    "## 9. Setup Training Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af1f86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(PROJECT_PATH)\n",
    "\n",
    "outdir = CONFIG['outdir']\n",
    "wdir = os.path.join(outdir, \"weights\")\n",
    "fdir = os.path.join(outdir, \"plots\")\n",
    "os.makedirs(wdir, exist_ok=True)\n",
    "os.makedirs(fdir, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "log_format = \"%(asctime)s %(message)s\"\n",
    "logging.basicConfig(level=logging.INFO, format=log_format, datefmt=\"%m/%d %I:%M:%S %p\")\n",
    "fh = logging.FileHandler(os.path.join(outdir, \"log.txt\"))\n",
    "fh.setFormatter(logging.Formatter(log_format))\n",
    "logging.getLogger().addHandler(fh)\n",
    "\n",
    "export_scripts(os.path.join(outdir, \"scripts\"))\n",
    "print(f\"‚úÖ Output: {outdir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a287a4c",
   "metadata": {},
   "source": [
    "## 10. Initialize Models\n",
    "\n",
    "**Extrapolation Task Specifics:**\n",
    "- Training views: indices [0-9] ‚Üí angles [0¬∞, 20¬∞, ..., 180¬∞]\n",
    "- Validation views: indices [10, 11] ‚Üí angles [200¬∞, 220¬∞]\n",
    "- Test views: indices [12-17] ‚Üí angles [240¬∞, 260¬∞, ..., 340¬∞]\n",
    "- The GP must learn to predict views BEYOND the training range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f73e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(CONFIG['seed'])\n",
    "\n",
    "if CONFIG['use_wandb']:\n",
    "    wandb.init(project=CONFIG['wandb_project'], name=CONFIG['wandb_run_name'], config=CONFIG)\n",
    "\n",
    "# Load VAE\n",
    "vae_cfg = pickle.load(open(CONFIG['vae_cfg'], \"rb\"))\n",
    "vae = FaceVAE(**vae_cfg).to(device)\n",
    "vae.load_state_dict(torch.load(CONFIG['vae_weights'], map_location=device))\n",
    "print(f\"‚úÖ VAE loaded\")\n",
    "\n",
    "# Load data\n",
    "train_data = COIL100Dataset(CONFIG['data'], split='train', use_angle_encoding=False)\n",
    "val_data = COIL100Dataset(CONFIG['data'], split='val', use_angle_encoding=False)\n",
    "train_queue = DataLoader(train_data, batch_size=CONFIG['batch_size'], shuffle=True)\n",
    "val_queue = DataLoader(val_data, batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "\n",
    "# IMPORTANT: Use get_num_objects for correct P (includes all objects from all splits)\n",
    "P = get_num_objects(CONFIG['data'])  # 100 for COIL-100\n",
    "Q = get_n_views()  # 18 total views\n",
    "print(f\"P={P}, Q={Q}\")\n",
    "\n",
    "# Show extrapolation task structure\n",
    "train_views = sorted(train_data.Rid.unique().tolist())\n",
    "val_views = sorted(val_data.Rid.unique().tolist())\n",
    "print(f\"\\nüìä Extrapolation Task:\")\n",
    "print(f\"   Train views (Rid): {train_views} ‚Üí angles {[v*20 for v in train_views]}¬∞\")\n",
    "print(f\"   Val views (Rid):   {val_views} ‚Üí angles {[v*20 for v in val_views]}¬∞\")\n",
    "print(f\"   Train samples: {len(train_data)}, Val samples: {len(val_data)}\")\n",
    "print(f\"   ‚ö†Ô∏è Val views are BEYOND training range (extrapolation)!\")\n",
    "\n",
    "# Create object and view tensors (Did and Rid are 1D tensors)\n",
    "Dt = Variable(train_data.Did.long(), requires_grad=False).to(device)\n",
    "Dv = Variable(val_data.Did.long(), requires_grad=False).to(device)\n",
    "Wt = Variable(train_data.Rid.long(), requires_grad=False).to(device)\n",
    "Wv = Variable(val_data.Rid.long(), requires_grad=False).to(device)\n",
    "\n",
    "# Initialize Vmodel with SM kernel\n",
    "print(f\"\\nüî¨ Initializing '{KERNEL_TYPE}' kernel (num_mixtures={CONFIG['kernel_kwargs']['num_mixtures']})...\")\n",
    "vm = Vmodel(P=P, Q=Q, p=CONFIG['xdim'], view_kernel=CONFIG['view_kernel'], **CONFIG['kernel_kwargs']).to(device)\n",
    "gp = GP(n_rand_effs=1).to(device)\n",
    "\n",
    "# Show kernel matrix - important for extrapolation!\n",
    "K = vm.get_kernel_matrix()\n",
    "print(f\"\\nüìà Kernel correlations (critical for extrapolation):\")\n",
    "print(f\"   K[0,0]={K[0,0].item():.4f} (self, 0¬∞)\")\n",
    "print(f\"   K[0,9]={K[0,9].item():.4f} (180¬∞ apart - edge of training)\")\n",
    "print(f\"   K[0,10]={K[0,10].item():.4f} (200¬∞ apart - val view, extrapolation!)\")\n",
    "print(f\"   K[0,17]={K[0,17].item():.4f} (340¬∞ = 20¬∞ wrapped distance!)\")\n",
    "\n",
    "gp_params = nn.ParameterList()\n",
    "gp_params.extend(vm.parameters())\n",
    "gp_params.extend(gp.parameters())\n",
    "\n",
    "vae_optimizer = optim.Adam(vae.parameters(), lr=CONFIG['vae_lr'])\n",
    "gp_optimizer = optim.Adam(gp_params, lr=CONFIG['gp_lr'])\n",
    "print(f\"\\n‚úÖ Models initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd6a571",
   "metadata": {},
   "source": [
    "## 11. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5e85fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_Y(vae, train_queue):\n",
    "    vae.eval()\n",
    "    with torch.no_grad():\n",
    "        n = train_queue.dataset.Y.shape[0]\n",
    "        Zm = Variable(torch.zeros(n, vae_cfg[\"zdim\"]), requires_grad=False).to(device)\n",
    "        Zs = Variable(torch.zeros(n, vae_cfg[\"zdim\"]), requires_grad=False).to(device)\n",
    "        for data in train_queue:\n",
    "            y = data[0].to(device)\n",
    "            idxs = data[-1].to(device)\n",
    "            zm, zs = vae.encode(y)\n",
    "            Zm[idxs], Zs[idxs] = zm.detach(), zs.detach()\n",
    "    return Zm, Zs\n",
    "\n",
    "def eval_step(vae, gp, vm, val_queue, Zm, Vt, Vv, Wv, val_Rid):\n",
    "    \"\"\"Evaluate GP-VAE on validation set (unseen views for extrapolation task).\n",
    "    \n",
    "    Args:\n",
    "        val_Rid: View indices for validation set (to compute per-view MSE)\n",
    "    \n",
    "    Returns:\n",
    "        rv: Dict with mse_out, mse_val, and per-view MSE (mse_view_XXX)\n",
    "    \"\"\"\n",
    "    rv = {}\n",
    "    with torch.no_grad():\n",
    "        _X = vm.x().data.cpu().numpy()\n",
    "        _W = vm.v().data.cpu().numpy()\n",
    "        covs = {\"XX\": np.dot(_X, _X.T), \"WW\": np.dot(_W, _W.T)}\n",
    "        rv[\"vars\"] = gp.get_vs().data.cpu().numpy()\n",
    "\n",
    "        # GP prediction: predict validation latents from training latents\n",
    "        vs = gp.get_vs()\n",
    "        U, UBi, _ = gp.U_UBi_Shb([Vt], vs)\n",
    "        Kiz = gp.solve(Zm, U, UBi, vs)\n",
    "        # Zo: predicted latents for validation views using GP extrapolation\n",
    "        Zo = vs[0] * Vv.mm(Vt.transpose(0, 1).mm(Kiz))\n",
    "\n",
    "        mse_out = Variable(torch.zeros(Vv.shape[0], 1), requires_grad=False).to(device)\n",
    "        mse_val = Variable(torch.zeros(Vv.shape[0], 1), requires_grad=False).to(device)\n",
    "        all_Yv, all_Yr, all_Yo = [], [], []\n",
    "\n",
    "        for data in val_queue:\n",
    "            idxs = data[-1].to(device)\n",
    "            Yv = data[0].to(device)  # Ground truth validation images\n",
    "            Zv = vae.encode(Yv)[0].detach()  # Encoded validation latents\n",
    "            Yr = vae.decode(Zv)  # Reconstruction (encode-decode)\n",
    "            Yo = vae.decode(Zo[idxs])  # GP-predicted images (extrapolated!)\n",
    "\n",
    "            # mse_out: How well can we predict views BEYOND training range?\n",
    "            mse_out[idxs] = ((Yv - Yo) ** 2).view(Yv.shape[0], -1).mean(1)[:, None].detach()\n",
    "            mse_val[idxs] = ((Yv - Yr) ** 2).view(Yv.shape[0], -1).mean(1)[:, None].detach()\n",
    "            all_Yv.append(Yv.data.cpu().numpy().transpose(0, 2, 3, 1))\n",
    "            all_Yr.append(Yr.data.cpu().numpy().transpose(0, 2, 3, 1))\n",
    "            all_Yo.append(Yo.data.cpu().numpy().transpose(0, 2, 3, 1))\n",
    "\n",
    "        all_Yv = np.concatenate(all_Yv, axis=0)\n",
    "        all_Yr = np.concatenate(all_Yr, axis=0)\n",
    "        all_Yo = np.concatenate(all_Yo, axis=0)\n",
    "        n_total = all_Yv.shape[0]\n",
    "        sample_indices = np.arange(0, n_total, max(1, n_total // 24))[:24]\n",
    "        imgs = {\"Yv\": all_Yv[sample_indices], \"Yr\": all_Yr[sample_indices], \"Yo\": all_Yo[sample_indices]}\n",
    "        rv[\"mse_out\"] = float(mse_out.data.mean().cpu())\n",
    "        rv[\"mse_val\"] = float(mse_val.data.mean().cpu())\n",
    "        \n",
    "        # Compute per-view MSE for extrapolation analysis\n",
    "        mse_out_cpu = mse_out.data.cpu().squeeze()\n",
    "        val_Rid_cpu = val_Rid.cpu()\n",
    "        unique_views = torch.unique(val_Rid_cpu).tolist()\n",
    "        for view_idx in unique_views:\n",
    "            mask = (val_Rid_cpu == view_idx)\n",
    "            view_mse = mse_out_cpu[mask].mean().item()\n",
    "            angle = int(view_idx * 20)  # Convert index to angle\n",
    "            rv[f\"mse_view_{angle:03d}\"] = view_mse\n",
    "        \n",
    "    return rv, imgs, covs\n",
    "\n",
    "def backprop_and_update(vae, gp, vm, train_queue, Dt, Wt, Eps, Zb, Vbs, vbs, vae_optimizer, gp_optimizer):\n",
    "    rv = {}\n",
    "    vae_optimizer.zero_grad()\n",
    "    gp_optimizer.zero_grad()\n",
    "    vae.train(); gp.train(); vm.train()\n",
    "\n",
    "    for data in train_queue:\n",
    "        y = data[0].to(device)\n",
    "        eps = Eps[data[-1]]\n",
    "        _d, _w = Dt[data[-1]], Wt[data[-1]]\n",
    "        _Zb = Zb[data[-1]]\n",
    "        _Vbs = [Vbs[0][data[-1]]]\n",
    "\n",
    "        zm, zs = vae.encode(y)\n",
    "        z = zm + zs * eps\n",
    "        yr = vae.decode(z)\n",
    "        recon_term, mse = vae.nll(y, yr)\n",
    "\n",
    "        _Vs = [vm(_d, _w)]\n",
    "        gp_nll_fo = gp.taylor_expansion(z, _Vs, _Zb, _Vbs, vbs) / vae.K\n",
    "        pen_term = -0.5 * zs.sum(1)[:, None] / vae.K\n",
    "\n",
    "        loss = (recon_term + gp_nll_fo + pen_term).sum()\n",
    "        loss.backward()\n",
    "\n",
    "        _n = train_queue.dataset.Y.shape[0]\n",
    "        smartSum(rv, \"mse\", float(mse.data.sum().cpu()) / _n)\n",
    "        smartSum(rv, \"recon_term\", float(recon_term.data.sum().cpu()) / _n)\n",
    "        smartSum(rv, \"pen_term\", float(pen_term.data.sum().cpu()) / _n)\n",
    "\n",
    "    vae_optimizer.step()\n",
    "    gp_optimizer.step()\n",
    "    return rv\n",
    "\n",
    "print(\"‚úÖ Training functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497e81dc",
   "metadata": {},
   "source": [
    "## 12. Train GP-VAE üöÄ\n",
    "\n",
    "**Key Metrics for Extrapolation:**\n",
    "- `mse_out`: MSE on **unseen views** (extrapolated) - This is the key metric!\n",
    "- `mse_view_XXX`: Per-view MSE for each validation angle (200¬∞, 220¬∞)\n",
    "- SM kernel parameters are automatically learned and logged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24376236",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {}\n",
    "start_time = time.time()\n",
    "\n",
    "# Get validation view indices for per-view MSE tracking\n",
    "val_Rid = val_data.Rid.to(device)\n",
    "val_view_angles = sorted([int(v * 20) for v in val_data.Rid.unique().tolist()])\n",
    "print(f\"üìä Tracking per-view MSE for validation angles: {val_view_angles}¬∞\")\n",
    "\n",
    "# Helper: extract SM kernel parameters for logging/plotting\n",
    "def get_sm_param_log_dict(vm):\n",
    "    k = vm.kernel\n",
    "    if not hasattr(k, \"num_mixtures\"):\n",
    "        return {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        weights = k.weights.detach().cpu().numpy()\n",
    "        means = k.means.detach().cpu().numpy()\n",
    "        variances = k.variances.detach().cpu().numpy()\n",
    "        eff_lens = 1.0 / (np.sqrt(variances) + 1e-12)\n",
    "\n",
    "    d = {}\n",
    "    # Aggregate summaries\n",
    "    d[\"sm/weights_entropy\"] = float(-(weights * np.log(weights + 1e-12)).sum())\n",
    "    d[\"sm/mean_freq\"] = float(means.mean())\n",
    "    d[\"sm/mean_eff_lengthscale\"] = float(eff_lens.mean())\n",
    "\n",
    "    # Per-mixture\n",
    "    for i in range(int(k.num_mixtures)):\n",
    "        d[f\"sm/mix{i}/weight\"] = float(weights[i])\n",
    "        d[f\"sm/mix{i}/freq\"] = float(means[i])\n",
    "        d[f\"sm/mix{i}/eff_lengthscale\"] = float(eff_lens[i])\n",
    "\n",
    "    return d\n",
    "\n",
    "print(f\"\\nüöÄ Training GP-VAE with {KERNEL_TYPE} kernel for {CONFIG['epochs']} epochs...\")\n",
    "print(f\"   Task: EXTRAPOLATION (predicting views BEYOND training range)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for epoch in range(CONFIG['epochs']):\n",
    "    epoch_start = time.time()\n",
    "\n",
    "    Zm, Zs = encode_Y(vae, train_queue)\n",
    "    Eps = Variable(torch.randn(*Zs.shape), requires_grad=False).to(device)\n",
    "    Z = Zm + Eps * Zs\n",
    "\n",
    "    Vt = vm(Dt, Wt).detach()\n",
    "    Vv = vm(Dv, Wv).detach()\n",
    "\n",
    "    # Pass val_Rid for per-view MSE computation\n",
    "    rv_eval, imgs, covs = eval_step(vae, gp, vm, val_queue, Zm, Vt, Vv, Wv, val_Rid)\n",
    "    Zb, Vbs, vbs, gp_nll = gp.taylor_coeff(Z, [Vt])\n",
    "    rv_eval[\"gp_nll\"] = float(gp_nll.data.mean().cpu()) / vae.K\n",
    "\n",
    "    rv_back = backprop_and_update(\n",
    "        vae, gp, vm, train_queue, Dt, Wt, Eps, Zb, Vbs, vbs, vae_optimizer, gp_optimizer\n",
    "    )\n",
    "    rv_back[\"loss\"] = rv_back[\"recon_term\"] + rv_eval[\"gp_nll\"] + rv_back[\"pen_term\"]\n",
    "\n",
    "    smartAppendDict(history, rv_eval)\n",
    "    smartAppendDict(history, rv_back)\n",
    "    smartAppend(history, \"vs\", gp.get_vs().data.cpu().numpy())\n",
    "\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    vs = gp.get_vs().data.cpu().numpy()\n",
    "    variance_ratio = vs[0] / (vs[0] + vs[1])\n",
    "\n",
    "    # Extract SM kernel params (learned) for printing/logging\n",
    "    sm_log = get_sm_param_log_dict(vm)\n",
    "\n",
    "    if epoch % 5 == 0 or epoch == CONFIG['epochs'] - 1:\n",
    "        # Print per-view MSE summary\n",
    "        view_mse_str = \" | \".join([f\"{a}¬∞:{rv_eval[f'mse_view_{a:03d}']:.4f}\" for a in val_view_angles])\n",
    "        print(\n",
    "            f\"Epoch {epoch:4d} | MSE: {rv_back['mse']:.6f} | Extrap: {rv_eval['mse_out']:.6f} | \"\n",
    "            f\"GP NLL: {rv_eval['gp_nll']:.4f} | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): {variance_ratio:.3f}\"\n",
    "        )\n",
    "        print(f\"         Per-view: {view_mse_str}\")\n",
    "\n",
    "        # Lightweight print of learned SM params\n",
    "        if sm_log:\n",
    "            mixes = int(vm.kernel.num_mixtures)\n",
    "            mix_str = []\n",
    "            for i in range(mixes):\n",
    "                mix_str.append(\n",
    "                    f\"mix{i}: w={sm_log[f'sm/mix{i}/weight']:.3f}, \"\n",
    "                    f\"f={sm_log[f'sm/mix{i}/freq']:.5f}, \"\n",
    "                    f\"‚Ñì‚âà{sm_log[f'sm/mix{i}/eff_lengthscale']:.2f}\"\n",
    "                )\n",
    "            print(\"         SM params: \" + \" | \".join(mix_str))\n",
    "\n",
    "    if CONFIG['use_wandb']:\n",
    "        # Log basic metrics\n",
    "        log_dict = {\n",
    "            \"epoch\": epoch,\n",
    "            \"mse_train\": rv_back[\"mse\"],\n",
    "            \"mse_extrap\": rv_eval[\"mse_out\"],\n",
    "            \"gp_nll\": rv_eval[\"gp_nll\"],\n",
    "            \"variance_ratio\": variance_ratio,\n",
    "        }\n",
    "\n",
    "        # Log per-view MSE\n",
    "        for angle in val_view_angles:\n",
    "            log_dict[f\"mse_view_{angle:03d}\"] = rv_eval[f\"mse_view_{angle:03d}\"]\n",
    "\n",
    "        # Log SM learned parameters\n",
    "        log_dict.update(sm_log)\n",
    "\n",
    "        wandb.log(log_dict)\n",
    "\n",
    "    if epoch % CONFIG['epoch_cb'] == 0 or epoch == CONFIG['epochs'] - 1:\n",
    "        torch.save(vae.state_dict(), os.path.join(wdir, f\"vae_weights.{epoch:05d}.pt\"))\n",
    "        torch.save({\"gp_state\": gp.state_dict(), \"vm_state\": vm.state_dict()}, os.path.join(wdir, f\"gp_weights.{epoch:05d}.pt\"))\n",
    "        ffile = os.path.join(fdir, f\"plot.{epoch:05d}.png\")\n",
    "        callback_gppvae(epoch, history, covs, imgs, ffile)\n",
    "        if CONFIG['use_wandb']:\n",
    "            wandb.log({\"reconstructions\": wandb.Image(ffile)})\n",
    "        print(f\"  ‚úì Checkpoint saved\")\n",
    "\n",
    "print(f\"\\n‚úÖ Complete! Time: {(time.time()-start_time)/60:.1f}min\")\n",
    "print(f\"   Final extrapolation MSE: {rv_eval['mse_out']:.6f}\")\n",
    "print(f\"\\nüìä Final per-view MSE:\")\n",
    "for angle in val_view_angles:\n",
    "    print(f\"   {angle:3d}¬∞: {rv_eval[f'mse_view_{angle:03d}']:.6f}\")\n",
    "if CONFIG['use_wandb']:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400cafb2",
   "metadata": {},
   "source": [
    "## 13. Evaluate on Test Set (Far Extrapolation)\n",
    "\n",
    "Test set contains views [12-17] ‚Üí angles [240¬∞, 260¬∞, 280¬∞, 300¬∞, 320¬∞, 340¬∞]\n",
    "\n",
    "**Note:** This is FAR extrapolation - views 60¬∞-160¬∞ beyond training range!\n",
    "But 340¬∞ is only 20¬∞ from 0¬∞ via wrapped distance, so SM kernel should help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70f4467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_data = COIL100Dataset(CONFIG['data'], split='test', use_angle_encoding=False)\n",
    "test_queue = DataLoader(test_data, batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "\n",
    "test_views = sorted(test_data.Rid.unique().tolist())\n",
    "print(f\"Test views (Rid): {test_views} ‚Üí angles {[v*20 for v in test_views]}¬∞\")\n",
    "print(f\"Test samples: {len(test_data)}\")\n",
    "print(f\"‚ö†Ô∏è These are FAR extrapolation views (60¬∞-160¬∞ beyond training)!\")\n",
    "print(f\"üí° But via wrapped distance: 340¬∞‚Üí20¬∞, 320¬∞‚Üí40¬∞ from training views!\")\n",
    "\n",
    "# Create test tensors\n",
    "Dtest = Variable(test_data.Did.long(), requires_grad=False).to(device)\n",
    "Wtest = Variable(test_data.Rid.long(), requires_grad=False).to(device)\n",
    "\n",
    "# Evaluate\n",
    "vae.eval()\n",
    "vm.eval()\n",
    "gp.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Re-encode training data\n",
    "    Zm, _ = encode_Y(vae, train_queue)\n",
    "    Vt = vm(Dt, Wt).detach()\n",
    "    Vtest = vm(Dtest, Wtest).detach()\n",
    "\n",
    "    # GP prediction for test set\n",
    "    vs = gp.get_vs()\n",
    "    U, UBi, _ = gp.U_UBi_Shb([Vt], vs)\n",
    "    Kiz = gp.solve(Zm, U, UBi, vs)\n",
    "    Zo_test = vs[0] * Vtest.mm(Vt.transpose(0, 1).mm(Kiz))\n",
    "\n",
    "    # Per-view test MSE\n",
    "    test_Rid = test_data.Rid\n",
    "    mse_per_view = {}\n",
    "    mse_test_total = 0.0\n",
    "    \n",
    "    for data in test_queue:\n",
    "        idxs = data[-1].to(device)\n",
    "        Ytest = data[0].to(device)\n",
    "        Yo = vae.decode(Zo_test[idxs])\n",
    "        mse_batch = ((Ytest - Yo) ** 2).view(Ytest.shape[0], -1).mean(1)\n",
    "        \n",
    "        # Accumulate per-view\n",
    "        for i, idx in enumerate(data[-1]):\n",
    "            view = int(test_Rid[idx].item())\n",
    "            if view not in mse_per_view:\n",
    "                mse_per_view[view] = []\n",
    "            mse_per_view[view].append(mse_batch[i].item())\n",
    "        \n",
    "        mse_test_total += mse_batch.sum().item()\n",
    "\n",
    "    mse_test = mse_test_total / len(test_data)\n",
    "    print(f\"\\nüéØ Test MSE (far extrapolation): {mse_test:.6f}\")\n",
    "    print(f\"\\nüìä Test per-view MSE:\")\n",
    "    for view in sorted(mse_per_view.keys()):\n",
    "        angle = int(view * 20)\n",
    "        view_mse = np.mean(mse_per_view[view])\n",
    "        wrapped_dist = min(angle, 360 - angle)  # Wrapped distance from 0¬∞\n",
    "        if wrapped_dist <= 40:\n",
    "            print(f\"   {angle:3d}¬∞: {view_mse:.6f}  (wrapped: {wrapped_dist}¬∞ from 0¬∞)\")\n",
    "        else:\n",
    "            print(f\"   {angle:3d}¬∞: {view_mse:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c4e51a",
   "metadata": {},
   "source": [
    "## 14. View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46407ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import glob\n",
    "\n",
    "plot_files = sorted(glob.glob(os.path.join(fdir, \"*.png\")))\n",
    "if plot_files:\n",
    "    display(Image(filename=plot_files[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3089857",
   "metadata": {},
   "source": [
    "## 15. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8d5afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r /content/gppvae_sm_extrapolation_output.zip {CONFIG['outdir']}\n",
    "from google.colab import files\n",
    "files.download('/content/gppvae_sm_extrapolation_output.zip')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
