{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98775da7",
   "metadata": {},
   "source": [
    "# GPPVAE Training on Google Colab\n",
    "\n",
    "This notebook trains the VAE model using Google Colab's free GPU (50-100x faster than M1 CPU).\n",
    "\n",
    "## Setup Instructions for VS Code + Colab:\n",
    "\n",
    "1. **Open this notebook in VS Code**\n",
    "2. **Connect to Colab**: Click kernel picker (top-right) ‚Üí \"Connect to Colab\" ‚Üí Choose GPU runtime (T4)\n",
    "3. **Important**: When prompted with \"Alias your server\", just press Enter to confirm\n",
    "4. **Run cell 2 below** - it will automatically detect your project location\n",
    "5. **Note**: Your files are synced to the Colab runtime, but in a different path than your local Mac\n",
    "\n",
    "The notebook will automatically figure out where your files are!\n",
    "\n",
    "## Output Directory Structure:\n",
    "\n",
    "Each training run creates a **timestamped directory** to avoid overwriting previous runs:\n",
    "- Format: `./out/vae_colab/YYYYMMDD_HHMMSS/`\n",
    "- Example: `./out/vae_colab/20251224_143022/weights/weights.00100.pt`\n",
    "- This allows you to compare different training runs and keep a history!\n",
    "\n",
    "## Expected Performance:\n",
    "- **10 epochs**: ~5-10 minutes (vs 2 hours on M1 CPU!)\n",
    "- **100 epochs**: ~30-60 minutes  \n",
    "- **1000 epochs**: ~5-10 hours\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199ee350",
   "metadata": {},
   "source": [
    "## 1. Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55166359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.0+cu126\n",
      "CUDA available: True\n",
      "GPU Device: Tesla T4\n",
      "GPU Memory: 15.83 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è WARNING: GPU not detected! Go to Runtime ‚Üí Change runtime type ‚Üí GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a2dcbc",
   "metadata": {},
   "source": [
    "## 2. Auto-Detect Project Path\n",
    "\n",
    "This cell automatically finds your project files wherever they are on the Colab runtime.\n",
    "VS Code syncs your workspace, but the path on Colab is different from your local Mac path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f41e7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìç Current directory: /content\n",
      "\n",
      "üîÑ You're on Colab but files aren't synced yet.\n",
      "\n",
      "Option 1: Upload via Google Drive (Recommended)\n",
      "============================================================\n",
      "Could not mount Drive: mount failed\n",
      "\n",
      "üìÇ Using project path: /content\n",
      "\n",
      "üìÅ Contents of /content:\n",
      "   üìÇ .config/\n",
      "   üìÇ sample_data/\n",
      "\n",
      "üîç Checking required files:\n",
      "   ‚ùå GPPVAE\n",
      "   ‚ùå data\n",
      "   ‚ùå data_faces.h5\n",
      "\n",
      "‚ö†Ô∏è  Missing files! Please upload your gppvae folder to Google Drive\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "print(f\"üìç Current directory: {current_dir}\")\n",
    "\n",
    "# Check if we're in /content (Colab) and need to upload files\n",
    "if current_dir == '/content':\n",
    "    print(\"\\nüîÑ You're on Colab but files aren't synced yet.\")\n",
    "    print(\"\\nOption 1: Upload via Google Drive (Recommended)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Try to mount Google Drive\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        \n",
    "        # Check if project exists in Drive\n",
    "        drive_path = '/content/drive/MyDrive/gppvae'\n",
    "        if os.path.exists(drive_path):\n",
    "            PROJECT_PATH = drive_path\n",
    "            print(f\"‚úÖ Found project in Google Drive: {PROJECT_PATH}\")\n",
    "        else:\n",
    "            print(f\"\\n‚ö†Ô∏è  Project not found at: {drive_path}\")\n",
    "            print(\"\\nTo upload your project to Google Drive:\")\n",
    "            print(\"1. Go to https://drive.google.com\")\n",
    "            print(\"2. Create a folder called 'gppvae' in My Drive\")\n",
    "            print(\"3. Upload these folders into it:\")\n",
    "            print(\"   - GPPVAE/ (code)\")\n",
    "            print(\"   - data/ (your data_faces.h5 file)\")\n",
    "            print(\"   - notebooks/ (this notebook)\")\n",
    "            PROJECT_PATH = '/content'\n",
    "    except Exception as e:\n",
    "        print(f\"Could not mount Drive: {e}\")\n",
    "        PROJECT_PATH = '/content'\n",
    "        \n",
    "    print(f\"\\nüìÇ Using project path: {PROJECT_PATH}\")\n",
    "else:\n",
    "    # Running locally or files are synced\n",
    "    if 'notebooks' in current_dir:\n",
    "        PROJECT_PATH = os.path.dirname(current_dir)\n",
    "    else:\n",
    "        PROJECT_PATH = current_dir\n",
    "    print(f\"üíª Using project path: {PROJECT_PATH}\")\n",
    "\n",
    "# Verify what we have\n",
    "print(f\"\\nüìÅ Contents of {PROJECT_PATH}:\")\n",
    "if os.path.exists(PROJECT_PATH):\n",
    "    items = os.listdir(PROJECT_PATH)\n",
    "    for item in sorted(items)[:15]:\n",
    "        item_path = os.path.join(PROJECT_PATH, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            print(f\"   üìÇ {item}/\")\n",
    "        else:\n",
    "            print(f\"   üìÑ {item}\")\n",
    "    \n",
    "    # Check for required folders\n",
    "    print(f\"\\nüîç Checking required files:\")\n",
    "    required = {\n",
    "        'GPPVAE': os.path.exists(os.path.join(PROJECT_PATH, 'GPPVAE')),\n",
    "        'data': os.path.exists(os.path.join(PROJECT_PATH, 'data')),\n",
    "        'data_faces.h5': os.path.exists(os.path.join(PROJECT_PATH, 'data/faceplace/data_faces.h5'))\n",
    "    }\n",
    "    \n",
    "    for name, exists in required.items():\n",
    "        status = \"‚úÖ\" if exists else \"‚ùå\"\n",
    "        print(f\"   {status} {name}\")\n",
    "    \n",
    "    if not all(required.values()):\n",
    "        print(f\"\\n‚ö†Ô∏è  Missing files! Please upload your gppvae folder to Google Drive\")\n",
    "else:\n",
    "    print(f\"‚ùå Path doesn't exist: {PROJECT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c23ffbb",
   "metadata": {},
   "source": [
    "## 3. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2cb187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q wandb==0.12.21 imageio==2.15.0 pyyaml\n",
    "\n",
    "# Check installations\n",
    "import wandb\n",
    "import imageio\n",
    "import yaml\n",
    "print(\"‚úÖ All dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f92a17",
   "metadata": {},
   "source": [
    "## 4. Login to Weights & Biases (Optional)\n",
    "\n",
    "If you want to track your experiments, login to W&B. Otherwise, skip this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c1a938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "# Or set to offline mode if you don't want to use W&B\n",
    "# os.environ['WANDB_MODE'] = 'offline'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82568f91",
   "metadata": {},
   "source": [
    "## 5. Navigate to Project Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af09b01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(PROJECT_PATH)\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "\n",
    "# Add project to Python path\n",
    "import sys\n",
    "sys.path.insert(0, os.path.join(PROJECT_PATH, 'GPPVAE/pysrc/faceplace'))\n",
    "\n",
    "# List files to verify\n",
    "print(\"\\nProject structure:\")\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba830110",
   "metadata": {},
   "source": [
    "## 6. Check Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97734e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/faceplace/data_faces.h5'\n",
    "\n",
    "if os.path.exists(data_path):\n",
    "    import h5py\n",
    "    with h5py.File(data_path, 'r') as f:\n",
    "        print(\"‚úÖ Data file found!\")\n",
    "        print(\"\\nDatasets in file:\")\n",
    "        for key in f.keys():\n",
    "            print(f\"  - {key}: {f[key].shape}\")\n",
    "else:\n",
    "    print(f\"‚ùå Data file not found at: {data_path}\")\n",
    "    print(\"\\nPlease ensure you've uploaded the data folder to Google Drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b789dd2e",
   "metadata": {},
   "source": [
    "## 7. Configure Training Parameters\n",
    "\n",
    "Adjust these parameters as needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2724d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Training configuration\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "CONFIG = {\n",
    "    'data': './data/faceplace/data_faces.h5',\n",
    "    'outdir': f'./out/vae_colab/{timestamp}',  # Timestamped directory for each run\n",
    "    'epochs': 100,  # Start with 100 epochs (~30-60 min)\n",
    "    'batch_size': 64,\n",
    "    'lr': 0.0002,\n",
    "    'zdim': 256,\n",
    "    'filts': 32,\n",
    "    'epoch_cb': 10,  # Save every 10 epochs\n",
    "    'use_wandb': True,\n",
    "    'wandb_project': 'gppvae',\n",
    "    'wandb_run_name': f'colab_vae_gpu_{timestamp}',  # Also add timestamp to run name\n",
    "}\n",
    "\n",
    "print(\"Training configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bff14b",
   "metadata": {},
   "source": [
    "## 8. Import Training Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb690ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to the training script directory\n",
    "os.chdir(os.path.join(PROJECT_PATH, 'GPPVAE/pysrc/faceplace'))\n",
    "\n",
    "# Import required modules\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from vae import FaceVAE\n",
    "import h5py\n",
    "import scipy as sp\n",
    "import logging\n",
    "import pylab as pl\n",
    "from utils import smartSum, smartAppendDict, smartAppend, export_scripts\n",
    "from callbacks import callback\n",
    "from data_parser import read_face_data, FaceDataset\n",
    "import pickle\n",
    "import time\n",
    "import wandb\n",
    "\n",
    "print(\"‚úÖ All modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e501b6c",
   "metadata": {},
   "source": [
    "## 9. Setup Training Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e092b233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go back to project root\n",
    "os.chdir(PROJECT_PATH)\n",
    "\n",
    "# Create output directories\n",
    "outdir = CONFIG['outdir']\n",
    "wdir = os.path.join(outdir, \"weights\")\n",
    "fdir = os.path.join(outdir, \"plots\")\n",
    "os.makedirs(wdir, exist_ok=True)\n",
    "os.makedirs(fdir, exist_ok=True)\n",
    "\n",
    "# Setup device (GPU)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Setup logging\n",
    "log_format = \"%(asctime)s %(message)s\"\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=log_format,\n",
    "    datefmt=\"%m/%d %I:%M:%S %p\",\n",
    ")\n",
    "fh = logging.FileHandler(os.path.join(outdir, \"log.txt\"))\n",
    "fh.setFormatter(logging.Formatter(log_format))\n",
    "logging.getLogger().addHandler(fh)\n",
    "\n",
    "print(\"‚úÖ Training environment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab7c141",
   "metadata": {},
   "source": [
    "## 10. Initialize Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f3c4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Initialize wandb\n",
    "if CONFIG['use_wandb']:\n",
    "    wandb.init(\n",
    "        project=CONFIG['wandb_project'],\n",
    "        name=CONFIG['wandb_run_name'],\n",
    "        config=CONFIG\n",
    "    )\n",
    "\n",
    "# Define VAE config\n",
    "vae_cfg = {\n",
    "    \"nf\": CONFIG['filts'],\n",
    "    \"zdim\": CONFIG['zdim'],\n",
    "    \"vy\": 0.002\n",
    "}\n",
    "\n",
    "# Save VAE config\n",
    "pickle.dump(vae_cfg, open(os.path.join(outdir, \"vae.cfg.p\"), \"wb\"))\n",
    "\n",
    "# Create VAE model\n",
    "vae = FaceVAE(**vae_cfg).to(device)\n",
    "print(f\"‚úÖ VAE model created with {sum(p.numel() for p in vae.parameters()):,} parameters\")\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = optim.Adam(vae.parameters(), lr=CONFIG['lr'])\n",
    "\n",
    "# Load data\n",
    "print(\"Loading data...\")\n",
    "img, obj, view = read_face_data(CONFIG['data'])\n",
    "train_data = FaceDataset(img[\"train\"], obj[\"train\"], view[\"train\"])\n",
    "val_data = FaceDataset(img[\"val\"], obj[\"val\"], view[\"val\"])\n",
    "train_queue = DataLoader(train_data, batch_size=CONFIG['batch_size'], shuffle=True)\n",
    "val_queue = DataLoader(val_data, batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "\n",
    "print(f\"‚úÖ Data loaded: {len(train_data)} training samples, {len(val_data)} validation samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94642148",
   "metadata": {},
   "source": [
    "## 11. Define Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d032dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ep(vae, train_queue, optimizer, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    rv = {}\n",
    "    vae.train()\n",
    "\n",
    "    for batch_i, data in enumerate(train_queue):\n",
    "        # Forward pass\n",
    "        y = data[0]\n",
    "        eps = Variable(torch.randn(y.shape[0], CONFIG['zdim']), requires_grad=False)\n",
    "        y, eps = y.to(device), eps.to(device)\n",
    "        elbo, mse, nll, kld = vae.forward(y, eps)\n",
    "        loss = elbo.sum()\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate metrics\n",
    "        _n = train_queue.dataset.Y.shape[0]\n",
    "        smartSum(rv, \"mse\", float(mse.data.sum().cpu()) / float(_n))\n",
    "        smartSum(rv, \"nll\", float(nll.data.sum().cpu()) / float(_n))\n",
    "        smartSum(rv, \"kld\", float(kld.data.sum().cpu()) / float(_n))\n",
    "        smartSum(rv, \"loss\", float(elbo.data.sum().cpu()) / float(_n))\n",
    "\n",
    "    return rv\n",
    "\n",
    "\n",
    "def eval_ep(vae, val_queue, device):\n",
    "    \"\"\"Evaluate for one epoch\"\"\"\n",
    "    rv = {}\n",
    "    vae.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_i, data in enumerate(val_queue):\n",
    "            # Forward pass\n",
    "            y = data[0]\n",
    "            eps = Variable(torch.randn(y.shape[0], CONFIG['zdim']), requires_grad=False)\n",
    "            y, eps = y.to(device), eps.to(device)\n",
    "            elbo, mse, nll, kld = vae.forward(y, eps)\n",
    "\n",
    "            # Accumulate metrics\n",
    "            _n = val_queue.dataset.Y.shape[0]\n",
    "            smartSum(rv, \"mse_val\", float(mse.data.sum().cpu()) / float(_n))\n",
    "            smartSum(rv, \"nll_val\", float(nll.data.sum().cpu()) / float(_n))\n",
    "            smartSum(rv, \"kld_val\", float(kld.data.sum().cpu()) / float(_n))\n",
    "            smartSum(rv, \"loss_val\", float(elbo.data.sum().cpu()) / float(_n))\n",
    "\n",
    "    return rv\n",
    "\n",
    "print(\"‚úÖ Training functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b63f48b",
   "metadata": {},
   "source": [
    "## 12. Train the Model üöÄ\n",
    "\n",
    "This is where the magic happens! Monitor the output to see training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938164a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "history = {}\n",
    "start_time = time.time()\n",
    "\n",
    "print(f\"üöÄ Starting training for {CONFIG['epochs']} epochs...\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for epoch in range(CONFIG['epochs']):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # Train and evaluate\n",
    "    ht = train_ep(vae, train_queue, optimizer, device)\n",
    "    hv = eval_ep(vae, val_queue, device)\n",
    "    smartAppendDict(history, ht)\n",
    "    smartAppendDict(history, hv)\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    # Print progress\n",
    "    if epoch % 5 == 0 or epoch == CONFIG['epochs'] - 1:\n",
    "        print(f\"Epoch {epoch:4d}/{CONFIG['epochs']} | \"\n",
    "              f\"Train MSE: {ht['mse']:.6f} | \"\n",
    "              f\"Val MSE: {hv['mse_val']:.6f} | \"\n",
    "              f\"Time: {epoch_time:.1f}s | \"\n",
    "              f\"Total: {total_time/60:.1f}min\")\n",
    "    \n",
    "    # Log to wandb\n",
    "    if CONFIG['use_wandb']:\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch,\n",
    "            \"train/mse\": ht[\"mse\"],\n",
    "            \"train/nll\": ht[\"nll\"],\n",
    "            \"train/kld\": ht[\"kld\"],\n",
    "            \"train/loss\": ht[\"loss\"],\n",
    "            \"val/mse\": hv[\"mse_val\"],\n",
    "            \"val/nll\": hv[\"nll_val\"],\n",
    "            \"val/kld\": hv[\"kld_val\"],\n",
    "            \"val/loss\": hv[\"loss_val\"],\n",
    "            \"time/epoch_seconds\": epoch_time,\n",
    "        })\n",
    "    \n",
    "    # Save checkpoint\n",
    "    if epoch % CONFIG['epoch_cb'] == 0 or epoch == CONFIG['epochs'] - 1:\n",
    "        logging.info(f\"Epoch {epoch} - saving checkpoint\")\n",
    "        wfile = os.path.join(wdir, f\"weights.{epoch:05d}.pt\")\n",
    "        ffile = os.path.join(fdir, f\"plot.{epoch:05d}.png\")\n",
    "        torch.save(vae.state_dict(), wfile)\n",
    "        callback(epoch, val_queue, vae, history, ffile, device)\n",
    "        \n",
    "        if CONFIG['use_wandb']:\n",
    "            wandb.log({\"reconstructions\": wandb.Image(ffile)})\n",
    "        \n",
    "        print(f\"  ‚úì Checkpoint saved at epoch {epoch}\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"‚úÖ Training complete! Total time: {total_time/60:.1f} minutes ({total_time/3600:.2f} hours)\")\n",
    "print(f\"   Average time per epoch: {total_time/CONFIG['epochs']:.1f} seconds\")\n",
    "print(f\"   Final validation MSE: {hv['mse_val']:.6f}\")\n",
    "\n",
    "if CONFIG['use_wandb']:\n",
    "    wandb.finish()\n",
    "    print(\"\\nüîó View results in W&B dashboard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2decf894",
   "metadata": {},
   "source": [
    "## 13. Download Results to Local Machine\n",
    "\n",
    "Download the trained model and plots to your computer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d11775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compress output folder\n",
    "!zip -r /content/vae_output.zip {CONFIG['outdir']}\n",
    "\n",
    "# Download via Colab\n",
    "from google.colab import files\n",
    "print(\"Preparing download...\")\n",
    "files.download('/content/vae_output.zip')\n",
    "print(\"\\n‚úÖ Download started! Extract the zip file on your local machine.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd16cfd",
   "metadata": {},
   "source": [
    "## 14. View Sample Reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3610fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import glob\n",
    "\n",
    "# Get latest plot\n",
    "plot_files = sorted(glob.glob(os.path.join(fdir, \"*.png\")))\n",
    "if plot_files:\n",
    "    latest_plot = plot_files[-1]\n",
    "    print(f\"Latest reconstruction plot: {latest_plot}\")\n",
    "    display(Image(filename=latest_plot))\n",
    "else:\n",
    "    print(\"No plots generated yet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a4a4c6",
   "metadata": {},
   "source": [
    "## 15. Next Steps\n",
    "\n",
    "### To continue training:\n",
    "1. Keep this notebook running\n",
    "2. Increase `CONFIG['epochs']` in cell 7\n",
    "3. Re-run cells 10-12\n",
    "\n",
    "### To train GPPVAE next:\n",
    "1. Use the trained VAE weights from this run\n",
    "2. Create a similar notebook for `train_gppvae.py`\n",
    "3. Or download weights and run locally\n",
    "\n",
    "### Performance comparison:\n",
    "- **Colab GPU (T4)**: ~5-10 min for 100 epochs\n",
    "- **M1 Pro CPU**: ~2 hours for 10 epochs\n",
    "- **Speedup**: 50-100x faster! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
