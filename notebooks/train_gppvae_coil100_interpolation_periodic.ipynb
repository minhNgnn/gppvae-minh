{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "537883bb",
   "metadata": {
    "id": "537883bb"
   },
   "source": [
    "# GP-VAE Training on COIL-100 (Interpolation Task) - Periodic Kernel\n",
    "\n",
    "This notebook trains **GP-VAE** on COIL-100 dataset using the **Periodic kernel** for the **interpolation task**.\n",
    "\n",
    "## Task: Interpolation\n",
    "- **Train**: 9 views at even indices (0¬∞, 40¬∞, 80¬∞, 120¬∞, 160¬∞, 200¬∞, 240¬∞, 280¬∞, 320¬∞)\n",
    "- **Val**: 5 views at odd indices (20¬∞, 100¬∞, 180¬∞, 260¬∞, 340¬∞)\n",
    "- **Test**: 4 views (60¬∞, 140¬∞, 220¬∞, 300¬∞)\n",
    "- **Goal**: Predict unseen intermediate views using GP interpolation\n",
    "\n",
    "## Kernel: Periodic\n",
    "- **Standard periodic kernel** for exact periodic patterns\n",
    "- k(Œ∏, Œ∏') = variance √ó exp(-2 √ó sin¬≤(œÄ|Œ∏-Œ∏'|/period) / lengthscale¬≤)\n",
    "- **period=360¬∞** fixed for full rotation\n",
    "- **Parameters**: 2 learnable (lengthscale, variance)\n",
    "- **Best for**: Data with exact periodicity (360¬∞ = 0¬∞)\n",
    "\n",
    "## Dataset Info:\n",
    "- **COIL-100**: 100 objects √ó 18 views (every 20¬∞: 0¬∞, 20¬∞, ..., 340¬∞)\n",
    "- **Image size**: 128√ó128√ó3 RGB\n",
    "\n",
    "## Prerequisites:\n",
    "- ‚úÖ Trained VAE weights from `train_vae_colab_interpolation.ipynb`\n",
    "- ‚úÖ COIL-100 data file: `data/coil100/coil100_task2_interpolation.h5`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0c0528",
   "metadata": {
    "id": "3c0c0528"
   },
   "source": [
    "## 1. Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb9161ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bb9161ac",
    "outputId": "cc004c8a-d6ac-484a-a2e0-180a51e0f418"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.0+cu126\n",
      "CUDA available: True\n",
      "GPU Device: Tesla T4\n",
      "GPU Memory: 15.83 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è WARNING: GPU not detected!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27190fa7",
   "metadata": {
    "id": "27190fa7"
   },
   "source": [
    "## 2. Auto-Detect Project Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1b9aeb8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1b9aeb8",
    "outputId": "1e9433f0-7da3-46f7-9850-21bb2a7c34a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìç Current directory: /content\n",
      "\n",
      "üîÑ Mounting Google Drive...\n",
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "‚úÖ Found project in Google Drive: /content/drive/MyDrive/gppvae\n",
      "\n",
      "üîç Checking required files:\n",
      "   ‚úÖ GPPVAE code\n",
      "   ‚úÖ COIL-100 data\n",
      "   ‚úÖ VAE weights\n",
      "\n",
      "üìä Interpolation Task Info:\n",
      "   Train: 9 views (even indices) √ó 100 objects = 900 samples\n",
      "   Val: 5 views (odd indices) √ó 100 objects = 500 samples\n",
      "   Test: 4 views √ó 100 objects = 400 samples\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "print(f\"üìç Current directory: {current_dir}\")\n",
    "\n",
    "# Task configuration\n",
    "DATA_TASK = \"task2_interpolation\"\n",
    "KERNEL_TYPE = \"periodic\"\n",
    "\n",
    "if current_dir == '/content':\n",
    "    print(\"\\nüîÑ Mounting Google Drive...\")\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        drive_path = '/content/drive/MyDrive/gppvae'\n",
    "        if os.path.exists(drive_path):\n",
    "            PROJECT_PATH = drive_path\n",
    "            print(f\"‚úÖ Found project in Google Drive: {PROJECT_PATH}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Project not found at: {drive_path}\")\n",
    "            PROJECT_PATH = '/content'\n",
    "    except Exception as e:\n",
    "        print(f\"Could not mount Drive: {e}\")\n",
    "        PROJECT_PATH = '/content'\n",
    "else:\n",
    "    if 'notebooks' in current_dir:\n",
    "        PROJECT_PATH = os.path.dirname(current_dir)\n",
    "    else:\n",
    "        PROJECT_PATH = current_dir\n",
    "    print(f\"üíª Using project path: {PROJECT_PATH}\")\n",
    "\n",
    "# Check required files\n",
    "print(f\"\\nüîç Checking required files:\")\n",
    "data_path = os.path.join(PROJECT_PATH, f'data/coil100/coil100_{DATA_TASK}.h5')\n",
    "required = {\n",
    "    'GPPVAE code': os.path.exists(os.path.join(PROJECT_PATH, 'GPPVAE')),\n",
    "    'COIL-100 data': os.path.exists(data_path),\n",
    "}\n",
    "\n",
    "# Look for VAE weights trained on interpolation task\n",
    "vae_base_dir = os.path.join(PROJECT_PATH, f'out/vae_colab_{DATA_TASK}')\n",
    "vae_run_found = False\n",
    "if os.path.exists(vae_base_dir):\n",
    "    runs = [d for d in os.listdir(vae_base_dir) if os.path.isdir(os.path.join(vae_base_dir, d))]\n",
    "    for run in runs:\n",
    "        weights_dir = os.path.join(vae_base_dir, run, 'weights')\n",
    "        if os.path.exists(weights_dir) and any(f.endswith('.pt') for f in os.listdir(weights_dir)):\n",
    "            vae_run_found = True\n",
    "            break\n",
    "required['VAE weights'] = vae_run_found\n",
    "\n",
    "for name, exists in required.items():\n",
    "    status = \"‚úÖ\" if exists else \"‚ùå\"\n",
    "    print(f\"   {status} {name}\")\n",
    "\n",
    "print(f\"\\nüìä Interpolation Task Info:\")\n",
    "print(f\"   Train: 9 views (even indices) √ó 100 objects = 900 samples\")\n",
    "print(f\"   Val: 5 views (odd indices) √ó 100 objects = 500 samples\")\n",
    "print(f\"   Test: 4 views √ó 100 objects = 400 samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10d7479",
   "metadata": {
    "id": "e10d7479"
   },
   "source": [
    "## 3. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27021436",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "27021436",
    "outputId": "01de394a-9b3a-4a69-ef66-49e8a90b458c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m√ó\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m√ó\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "‚úÖ All dependencies installed!\n"
     ]
    }
   ],
   "source": [
    "!pip install -q wandb==0.12.21 imageio==2.15.0 pyyaml\n",
    "\n",
    "import wandb\n",
    "import numpy as np\n",
    "print(\"‚úÖ All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f39d0bb",
   "metadata": {
    "id": "3f39d0bb"
   },
   "source": [
    "## 4. Login to W&B (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "292d8518",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "292d8518",
    "outputId": "3ee655e9-94c7-4f1f-8afc-00ae9ac6a9a6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mminh1008\u001b[0m (\u001b[33mminh1008-ludwig-maximilianuniversity-of-munich\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f72204",
   "metadata": {
    "id": "e5f72204"
   },
   "source": [
    "## 5. Navigate to Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d2da1f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6d2da1f6",
    "outputId": "31222345-d030-4462-f0bd-f91ebedf1be8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /content/drive/MyDrive/gppvae\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir(PROJECT_PATH)\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "\n",
    "sys.path.insert(0, os.path.join(PROJECT_PATH, 'GPPVAE/pysrc/coil100'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4a3110",
   "metadata": {
    "id": "3e4a3110"
   },
   "source": [
    "## 6. Find VAE Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "264338ce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "264338ce",
    "outputId": "cefa0b57-80fc-4986-f880-8bb3f954f3cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found 1 VAE run(s) for interpolation task\n",
      "\n",
      "üí° Latest: 20260119_135537\n",
      "   VAE_CFG = './out/vae_colab_task2_interpolation/20260119_135537/vae.cfg.p'\n",
      "   VAE_WEIGHTS = './out/vae_colab_task2_interpolation/20260119_135537/weights/weights.00499.pt'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# Look for VAE trained on interpolation task\n",
    "vae_base_dir = f'./out/vae_colab_{DATA_TASK}'\n",
    "vae_runs = []\n",
    "\n",
    "if os.path.exists(vae_base_dir):\n",
    "    for run_dir in sorted(os.listdir(vae_base_dir), reverse=True):\n",
    "        run_path = os.path.join(vae_base_dir, run_dir)\n",
    "        cfg_path = os.path.join(run_path, 'vae.cfg.p')\n",
    "        weights_dir = os.path.join(run_path, 'weights')\n",
    "\n",
    "        if os.path.exists(cfg_path) and os.path.exists(weights_dir):\n",
    "            weight_files = sorted([f for f in os.listdir(weights_dir) if f.endswith('.pt')])\n",
    "            if weight_files:\n",
    "                vae_runs.append({\n",
    "                    'run_dir': run_dir,\n",
    "                    'cfg_path': cfg_path,\n",
    "                    'weights_dir': weights_dir,\n",
    "                    'weight_files': weight_files\n",
    "                })\n",
    "\n",
    "if vae_runs:\n",
    "    print(f\"‚úÖ Found {len(vae_runs)} VAE run(s) for interpolation task\")\n",
    "    latest = vae_runs[0]\n",
    "    print(f\"\\nüí° Latest: {latest['run_dir']}\")\n",
    "    print(f\"   VAE_CFG = '{latest['cfg_path']}'\")\n",
    "    print(f\"   VAE_WEIGHTS = '{os.path.join(latest['weights_dir'], latest['weight_files'][-1])}'\")\n",
    "else:\n",
    "    print(\"‚ùå No VAE runs found for interpolation task!\")\n",
    "    print(\"   Run train_vae_colab_interpolation.ipynb first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461661c0",
   "metadata": {
    "id": "461661c0"
   },
   "source": [
    "## 7. Configure Training\n",
    "\n",
    "**Periodic Kernel Parameters:**\n",
    "- `period`: Fixed at 360¬∞ for full rotation\n",
    "- `lengthscale`: Controls smoothness within one period. **Use ~1.0 for proper interpolation**\n",
    "- `variance`: Signal variance. Default: 1.0\n",
    "\n",
    "**‚ö†Ô∏è Important:** For the interpolation task, the lengthscale is critical!\n",
    "- `lengthscale=30` ‚Üí all views 99.9% correlated (no interpolation structure)\n",
    "- `lengthscale=1.0` ‚Üí proper correlation decay with angle difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72a7b9a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "72a7b9a7",
    "outputId": "bccf06eb-e6ac-4ef9-fb66-67bcb1849e43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GP-VAE Training Configuration (Interpolation Task):\n",
      "============================================================\n",
      "  data                : ./data/coil100/coil100_task2_interpolation.h5\n",
      "  outdir              : ./out/gppvae_coil100_periodic_task2_interpolation/20260119_180211\n",
      "  vae_cfg             : ./out/vae_colab_task2_interpolation/20260119_135537/vae.cfg.p\n",
      "  vae_weights         : ./out/vae_colab_task2_interpolation/20260119_135537/weights/weights.00499.pt\n",
      "  epochs              : 1500\n",
      "  batch_size          : 64\n",
      "  vae_lr              : 0.001\n",
      "  gp_lr               : 0.001\n",
      "  xdim                : 64\n",
      "  view_kernel         : periodic\n",
      "  kernel_kwargs       : {'period': 360.0, 'lengthscale': 1.0, 'variance': 1.0}\n",
      "  epoch_cb            : 100\n",
      "  use_wandb           : True\n",
      "  wandb_project       : gppvae-coil100\n",
      "  wandb_run_name      : gppvae_periodic_task2_interpolation_20260119_180211\n",
      "  seed                : 0\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# ============================================================================\n",
    "# UPDATE THESE PATHS!\n",
    "# ============================================================================\n",
    "VAE_CFG = './out/vae_colab_task2_interpolation/20260119_135537/vae.cfg.p'\n",
    "VAE_WEIGHTS = './out/vae_colab_task2_interpolation/20260119_135537/weights/weights.00499.pt'\n",
    "\n",
    "CONFIG = {\n",
    "    # Data\n",
    "    'data': f'./data/coil100/coil100_{DATA_TASK}.h5',\n",
    "    'outdir': f'./out/gppvae_coil100_{KERNEL_TYPE}_{DATA_TASK}/{timestamp}',\n",
    "\n",
    "    # VAE\n",
    "    'vae_cfg': VAE_CFG,\n",
    "    'vae_weights': VAE_WEIGHTS,\n",
    "\n",
    "    # Training\n",
    "    'epochs': 1500,\n",
    "    'batch_size': 64,\n",
    "    'vae_lr': 0.001,\n",
    "    'gp_lr': 0.001,\n",
    "    'xdim': 64,\n",
    "\n",
    "    # Kernel - Periodic (IMPORTANT: use proper lengthscale for interpolation!)\n",
    "    'view_kernel': KERNEL_TYPE,\n",
    "    'kernel_kwargs': {\n",
    "        'period': 360.0,      # Fixed: full rotation\n",
    "        'lengthscale': 1.0,   # Proper scale for interpolation (NOT 30!)\n",
    "        'variance': 1.0,\n",
    "    },\n",
    "\n",
    "    # Logging\n",
    "    'epoch_cb': 100,\n",
    "    'use_wandb': True,\n",
    "    'wandb_project': 'gppvae-coil100',\n",
    "    'wandb_run_name': f'gppvae_{KERNEL_TYPE}_{DATA_TASK}_{timestamp}',\n",
    "    'seed': 0,\n",
    "}\n",
    "\n",
    "print(\"GP-VAE Training Configuration (Interpolation Task):\")\n",
    "print(\"=\" * 60)\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key:20s}: {value}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if not os.path.exists(CONFIG['vae_weights']):\n",
    "    print(f\"\\n‚ö†Ô∏è Update VAE_CFG and VAE_WEIGHTS paths!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a311fce2",
   "metadata": {
    "id": "a311fce2"
   },
   "source": [
    "## 8. Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d0afeda",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5d0afeda",
    "outputId": "8f584b11-e6e7-4c40-c0de-67fac7e48dcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /content/drive/MyDrive/gppvae/GPPVAE/pysrc/coil100\n",
      "sys.path priority: coil100 > faceplace\n",
      "‚úÖ data_parser loaded from: /content/drive/MyDrive/gppvae/GPPVAE/pysrc/coil100/data_parser.py\n",
      "‚úÖ Using COIL-100 data_parser (correct!)\n",
      "‚úÖ All modules imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: Add coil100 to path FIRST before importing anything\n",
    "# This ensures coil100's data_parser is used, not faceplace's\n",
    "import sys\n",
    "import os\n",
    "\n",
    "coil100_path = os.path.join(PROJECT_PATH, 'GPPVAE/pysrc/coil100')\n",
    "sys.path.insert(0, coil100_path)    # Add coil100 first (so it has priority)\n",
    "\n",
    "os.chdir(coil100_path)\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "print(f\"sys.path priority: coil100 > faceplace\")\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from vae import FaceVAE\n",
    "from vmod import Vmodel\n",
    "from gp import GP\n",
    "import numpy as np\n",
    "import logging\n",
    "import pylab as pl\n",
    "from utils import smartSum, smartAppendDict, smartAppend, export_scripts\n",
    "from callbacks import callback_gppvae\n",
    "import pickle\n",
    "import time\n",
    "import wandb\n",
    "\n",
    "# COIL-100 data parser (explicitly import from coil100, not faceplace)\n",
    "from data_parser import COIL100Dataset, get_n_views, get_num_objects\n",
    "\n",
    "# Verify we're using the right data_parser\n",
    "import data_parser\n",
    "print(f\"‚úÖ data_parser loaded from: {data_parser.__file__}\")\n",
    "if 'coil100' in data_parser.__file__:\n",
    "    print(\"‚úÖ Using COIL-100 data_parser (correct!)\")\n",
    "else:\n",
    "    print(\"‚ùå WARNING: Using faceplace data_parser (wrong!)\")\n",
    "print(\"‚úÖ All modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae4fbd8",
   "metadata": {
    "id": "cae4fbd8"
   },
   "source": [
    "## 9. Setup Training Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c2215fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6c2215fa",
    "outputId": "5d537496-d4a6-4958-b962-b0d455f92b26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "‚úÖ Output: ./out/gppvae_coil100_periodic_task2_interpolation/20260119_180211\n"
     ]
    }
   ],
   "source": [
    "os.chdir(PROJECT_PATH)\n",
    "\n",
    "outdir = CONFIG['outdir']\n",
    "wdir = os.path.join(outdir, \"weights\")\n",
    "fdir = os.path.join(outdir, \"plots\")\n",
    "os.makedirs(wdir, exist_ok=True)\n",
    "os.makedirs(fdir, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "log_format = \"%(asctime)s %(message)s\"\n",
    "logging.basicConfig(level=logging.INFO, format=log_format, datefmt=\"%m/%d %I:%M:%S %p\")\n",
    "fh = logging.FileHandler(os.path.join(outdir, \"log.txt\"))\n",
    "fh.setFormatter(logging.Formatter(log_format))\n",
    "logging.getLogger().addHandler(fh)\n",
    "\n",
    "export_scripts(os.path.join(outdir, \"scripts\"))\n",
    "print(f\"‚úÖ Output: {outdir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce94c33b",
   "metadata": {
    "id": "ce94c33b"
   },
   "source": [
    "## 10. Initialize Models\n",
    "\n",
    "**Interpolation Task Specifics:**\n",
    "- Training views: indices [0, 2, 4, 6, 8, 10, 12, 14, 16] ‚Üí angles [0¬∞, 40¬∞, 80¬∞, ...]\n",
    "- Validation views: indices [1, 5, 9, 13, 17] ‚Üí angles [20¬∞, 100¬∞, 180¬∞, ...]\n",
    "- The GP must learn to predict intermediate views from training views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3774923",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 853
    },
    "id": "f3774923",
    "outputId": "e6fb54c3-a8d4-4ebd-b9c9-a73b39266c62"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">gppvae_periodic_task2_interpolation_20260119_175604</strong> at: <a href='https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae-coil100/runs/2hno970l' target=\"_blank\">https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae-coil100/runs/2hno970l</a><br> View project at: <a href='https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae-coil100' target=\"_blank\">https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae-coil100</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/content/wandb/run-20260119_175653-2hno970l/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20260119_180213-pk56zrm9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae-coil100/runs/pk56zrm9' target=\"_blank\">gppvae_periodic_task2_interpolation_20260119_180211</a></strong> to <a href='https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae-coil100' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae-coil100' target=\"_blank\">https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae-coil100</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae-coil100/runs/pk56zrm9' target=\"_blank\">https://wandb.ai/minh1008-ludwig-maximilianuniversity-of-munich/gppvae-coil100/runs/pk56zrm9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ VAE loaded\n",
      "Built object ID mapping: 100 objects -> indices [0, 99]\n",
      "Loaded COIL-100 train: 900 samples\n",
      "  Y shape: torch.Size([900, 3, 128, 128])\n",
      "  Unique objects: 100\n",
      "  Did range: [0, 99] (remapped to contiguous)\n",
      "  Angle encoding: indices [0, 17]\n",
      "Loaded COIL-100 val: 500 samples\n",
      "  Y shape: torch.Size([500, 3, 128, 128])\n",
      "  Unique objects: 100\n",
      "  Did range: [0, 99] (remapped to contiguous)\n",
      "  Angle encoding: indices [0, 17]\n",
      "P=100, Q=18\n",
      "\n",
      "üìä Interpolation Task:\n",
      "   Train views (Rid): [0, 2, 4, 6, 8, 10, 12, 14, 16] ‚Üí angles [0, 40, 80, 120, 160, 200, 240, 280, 320]¬∞\n",
      "   Val views (Rid):   [1, 5, 9, 13, 17] ‚Üí angles [20, 100, 180, 260, 340]¬∞\n",
      "   Train samples: 900, Val samples: 500\n",
      "\n",
      "üî¨ Initializing 'periodic' kernel (period=360.0¬∞)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/gppvae/GPPVAE/pysrc/coil100/vmod.py:101: UserWarning: torch.cholesky is deprecated in favor of torch.linalg.cholesky and will be removed in a future PyTorch release.\n",
      "L = torch.cholesky(A)\n",
      "should be replaced with\n",
      "L = torch.linalg.cholesky(A)\n",
      "and\n",
      "U = torch.cholesky(A, upper=True)\n",
      "should be replaced with\n",
      "U = torch.linalg.cholesky(A).mH\n",
      "This transform will produce equivalent results for all valid (symmetric positive definite) inputs. (Triggered internally at /pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:1765.)\n",
      "  L = torch.cholesky(K)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Kernel correlations (critical for interpolation):\n",
      "   K[0,0]=1.0000 (self, 0¬∞)\n",
      "   K[0,1]=0.9415 (20¬∞ apart - val view from train)\n",
      "   K[0,2]=0.7914 (40¬∞ apart - next train view)\n",
      "   K[0,9]=0.1353 (180¬∞ apart)\n",
      "\n",
      "‚úÖ Models initialized\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(CONFIG['seed'])\n",
    "\n",
    "if CONFIG['use_wandb']:\n",
    "    wandb.init(project=CONFIG['wandb_project'], name=CONFIG['wandb_run_name'], config=CONFIG)\n",
    "\n",
    "# Load VAE\n",
    "vae_cfg = pickle.load(open(CONFIG['vae_cfg'], \"rb\"))\n",
    "vae = FaceVAE(**vae_cfg).to(device)\n",
    "vae.load_state_dict(torch.load(CONFIG['vae_weights'], map_location=device))\n",
    "print(f\"‚úÖ VAE loaded\")\n",
    "\n",
    "# Load data\n",
    "train_data = COIL100Dataset(CONFIG['data'], split='train', use_angle_encoding=False)\n",
    "val_data = COIL100Dataset(CONFIG['data'], split='val', use_angle_encoding=False)\n",
    "train_queue = DataLoader(train_data, batch_size=CONFIG['batch_size'], shuffle=True)\n",
    "val_queue = DataLoader(val_data, batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "\n",
    "# IMPORTANT: Use get_num_objects for correct P (includes all objects from all splits)\n",
    "P = get_num_objects(CONFIG['data'])  # 100 for COIL-100\n",
    "Q = get_n_views()  # 18 total views\n",
    "print(f\"P={P}, Q={Q}\")\n",
    "\n",
    "# Show interpolation task structure\n",
    "train_views = sorted(train_data.Rid.unique().tolist())\n",
    "val_views = sorted(val_data.Rid.unique().tolist())\n",
    "print(f\"\\nüìä Interpolation Task:\")\n",
    "print(f\"   Train views (Rid): {train_views} ‚Üí angles {[v*20 for v in train_views]}¬∞\")\n",
    "print(f\"   Val views (Rid):   {val_views} ‚Üí angles {[v*20 for v in val_views]}¬∞\")\n",
    "print(f\"   Train samples: {len(train_data)}, Val samples: {len(val_data)}\")\n",
    "\n",
    "# Create object and view tensors (Did and Rid are 1D tensors)\n",
    "Dt = Variable(train_data.Did.long(), requires_grad=False).to(device)\n",
    "Dv = Variable(val_data.Did.long(), requires_grad=False).to(device)\n",
    "Wt = Variable(train_data.Rid.long(), requires_grad=False).to(device)\n",
    "Wv = Variable(val_data.Rid.long(), requires_grad=False).to(device)\n",
    "\n",
    "# Initialize Vmodel with Periodic kernel\n",
    "print(f\"\\nüî¨ Initializing '{KERNEL_TYPE}' kernel (period={CONFIG['kernel_kwargs']['period']}¬∞)...\")\n",
    "vm = Vmodel(P=P, Q=Q, p=CONFIG['xdim'], view_kernel=CONFIG['view_kernel'], **CONFIG['kernel_kwargs']).to(device)\n",
    "gp = GP(n_rand_effs=1).to(device)\n",
    "\n",
    "# Show kernel matrix - important for interpolation!\n",
    "K = vm.get_kernel_matrix()\n",
    "print(f\"\\nüìà Kernel correlations (critical for interpolation):\")\n",
    "print(f\"   K[0,0]={K[0,0].item():.4f} (self, 0¬∞)\")\n",
    "print(f\"   K[0,1]={K[0,1].item():.4f} (20¬∞ apart - val view from train)\")\n",
    "print(f\"   K[0,2]={K[0,2].item():.4f} (40¬∞ apart - next train view)\")\n",
    "print(f\"   K[0,9]={K[0,9].item():.4f} (180¬∞ apart)\")\n",
    "\n",
    "gp_params = nn.ParameterList()\n",
    "gp_params.extend(vm.parameters())\n",
    "gp_params.extend(gp.parameters())\n",
    "\n",
    "vae_optimizer = optim.Adam(vae.parameters(), lr=CONFIG['vae_lr'])\n",
    "gp_optimizer = optim.Adam(gp_params, lr=CONFIG['gp_lr'])\n",
    "print(f\"\\n‚úÖ Models initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b72e3fd",
   "metadata": {
    "id": "0b72e3fd"
   },
   "source": [
    "## 11. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f494231d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f494231d",
    "outputId": "4f9578a3-5bb9-49f7-bd01-9f5b7261181b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training functions defined\n"
     ]
    }
   ],
   "source": [
    "def encode_Y(vae, train_queue):\n",
    "    vae.eval()\n",
    "    with torch.no_grad():\n",
    "        n = train_queue.dataset.Y.shape[0]\n",
    "        Zm = Variable(torch.zeros(n, vae_cfg[\"zdim\"]), requires_grad=False).to(device)\n",
    "        Zs = Variable(torch.zeros(n, vae_cfg[\"zdim\"]), requires_grad=False).to(device)\n",
    "        for data in train_queue:\n",
    "            y = data[0].to(device)\n",
    "            idxs = data[-1].to(device)\n",
    "            zm, zs = vae.encode(y)\n",
    "            Zm[idxs], Zs[idxs] = zm.detach(), zs.detach()\n",
    "    return Zm, Zs\n",
    "\n",
    "def eval_step(vae, gp, vm, val_queue, Zm, Vt, Vv, Wv, val_Rid):\n",
    "    \"\"\"Evaluate GP-VAE on validation set (unseen views for interpolation task).\n",
    "    \n",
    "    Args:\n",
    "        val_Rid: View indices for validation set (to compute per-view MSE)\n",
    "    \n",
    "    Returns:\n",
    "        rv: Dict with mse_out, mse_val, and per-view MSE (mse_view_XXX)\n",
    "    \"\"\"\n",
    "    rv = {}\n",
    "    with torch.no_grad():\n",
    "        _X = vm.x().data.cpu().numpy()\n",
    "        _W = vm.v().data.cpu().numpy()\n",
    "        covs = {\"XX\": np.dot(_X, _X.T), \"WW\": np.dot(_W, _W.T)}\n",
    "        rv[\"vars\"] = gp.get_vs().data.cpu().numpy()\n",
    "\n",
    "        # GP prediction: predict validation latents from training latents\n",
    "        vs = gp.get_vs()\n",
    "        U, UBi, _ = gp.U_UBi_Shb([Vt], vs)\n",
    "        Kiz = gp.solve(Zm, U, UBi, vs)\n",
    "        # Zo: predicted latents for validation views using GP interpolation\n",
    "        Zo = vs[0] * Vv.mm(Vt.transpose(0, 1).mm(Kiz))\n",
    "\n",
    "        mse_out = Variable(torch.zeros(Vv.shape[0], 1), requires_grad=False).to(device)\n",
    "        mse_val = Variable(torch.zeros(Vv.shape[0], 1), requires_grad=False).to(device)\n",
    "        all_Yv, all_Yr, all_Yo = [], [], []\n",
    "\n",
    "        for data in val_queue:\n",
    "            idxs = data[-1].to(device)\n",
    "            Yv = data[0].to(device)  # Ground truth validation images\n",
    "            Zv = vae.encode(Yv)[0].detach()  # Encoded validation latents\n",
    "            Yr = vae.decode(Zv)  # Reconstruction (encode-decode)\n",
    "            Yo = vae.decode(Zo[idxs])  # GP-predicted images (interpolated!)\n",
    "\n",
    "            # mse_out: How well can we predict UNSEEN views?\n",
    "            mse_out[idxs] = ((Yv - Yo) ** 2).view(Yv.shape[0], -1).mean(1)[:, None].detach()\n",
    "            mse_val[idxs] = ((Yv - Yr) ** 2).view(Yv.shape[0], -1).mean(1)[:, None].detach()\n",
    "            all_Yv.append(Yv.data.cpu().numpy().transpose(0, 2, 3, 1))\n",
    "            all_Yr.append(Yr.data.cpu().numpy().transpose(0, 2, 3, 1))\n",
    "            all_Yo.append(Yo.data.cpu().numpy().transpose(0, 2, 3, 1))\n",
    "\n",
    "        all_Yv = np.concatenate(all_Yv, axis=0)\n",
    "        all_Yr = np.concatenate(all_Yr, axis=0)\n",
    "        all_Yo = np.concatenate(all_Yo, axis=0)\n",
    "        n_total = all_Yv.shape[0]\n",
    "        sample_indices = np.arange(0, n_total, max(1, n_total // 24))[:24]\n",
    "        imgs = {\"Yv\": all_Yv[sample_indices], \"Yr\": all_Yr[sample_indices], \"Yo\": all_Yo[sample_indices]}\n",
    "        rv[\"mse_out\"] = float(mse_out.data.mean().cpu())\n",
    "        rv[\"mse_val\"] = float(mse_val.data.mean().cpu())\n",
    "        \n",
    "        # Compute per-view MSE for interpolation analysis\n",
    "        mse_out_cpu = mse_out.data.cpu().squeeze()\n",
    "        val_Rid_cpu = val_Rid.cpu()\n",
    "        unique_views = torch.unique(val_Rid_cpu).tolist()\n",
    "        for view_idx in unique_views:\n",
    "            mask = (val_Rid_cpu == view_idx)\n",
    "            view_mse = mse_out_cpu[mask].mean().item()\n",
    "            angle = int(view_idx * 20)  # Convert index to angle\n",
    "            rv[f\"mse_view_{angle:03d}\"] = view_mse\n",
    "        \n",
    "    return rv, imgs, covs\n",
    "\n",
    "def backprop_and_update(vae, gp, vm, train_queue, Dt, Wt, Eps, Zb, Vbs, vbs, vae_optimizer, gp_optimizer):\n",
    "    rv = {}\n",
    "    vae_optimizer.zero_grad()\n",
    "    gp_optimizer.zero_grad()\n",
    "    vae.train(); gp.train(); vm.train()\n",
    "\n",
    "    for data in train_queue:\n",
    "        y = data[0].to(device)\n",
    "        eps = Eps[data[-1]]\n",
    "        _d, _w = Dt[data[-1]], Wt[data[-1]]\n",
    "        _Zb = Zb[data[-1]]\n",
    "        _Vbs = [Vbs[0][data[-1]]]\n",
    "\n",
    "        zm, zs = vae.encode(y)\n",
    "        z = zm + zs * eps\n",
    "        yr = vae.decode(z)\n",
    "        recon_term, mse = vae.nll(y, yr)\n",
    "\n",
    "        _Vs = [vm(_d, _w)]\n",
    "        gp_nll_fo = gp.taylor_expansion(z, _Vs, _Zb, _Vbs, vbs) / vae.K\n",
    "        pen_term = -0.5 * zs.sum(1)[:, None] / vae.K\n",
    "\n",
    "        loss = (recon_term + gp_nll_fo + pen_term).sum()\n",
    "        loss.backward()\n",
    "\n",
    "        _n = train_queue.dataset.Y.shape[0]\n",
    "        smartSum(rv, \"mse\", float(mse.data.sum().cpu()) / _n)\n",
    "        smartSum(rv, \"recon_term\", float(recon_term.data.sum().cpu()) / _n)\n",
    "        smartSum(rv, \"pen_term\", float(pen_term.data.sum().cpu()) / _n)\n",
    "\n",
    "    vae_optimizer.step()\n",
    "    gp_optimizer.step()\n",
    "    return rv\n",
    "\n",
    "print(\"‚úÖ Training functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bc04b7",
   "metadata": {
    "id": "c4bc04b7"
   },
   "source": [
    "## 12. Train GP-VAE üöÄ\n",
    "\n",
    "**Key Metrics for Interpolation:**\n",
    "- `mse_out`: MSE on **unseen views** (interpolated) - This is the key metric!\n",
    "- `mse_val`: MSE on encode-decode (VAE reconstruction quality)\n",
    "- `lengthscale`: Learned kernel lengthscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ae8bde",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "04ae8bde",
    "outputId": "f0c94403-4561-4fa8-d236-e8670f9238ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Training GP-VAE with periodic kernel for 1500 epochs...\n",
      "   Task: INTERPOLATION (predicting unseen intermediate views)\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/gppvae/GPPVAE/pysrc/coil100/vae.py:46: UserWarning: `nn.functional.upsample` is deprecated. Use `nn.functional.interpolate` instead.\n",
      "  x = F.upsample(x, scale_factor=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0 | MSE: 0.002326 | Interp: 0.046617 | GP NLL: 0.0115 | ‚Ñì: 1.00 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.500\n",
      "  ‚úì Checkpoint saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/gppvae/GPPVAE/pysrc/coil100/vae.py:46: UserWarning: `nn.functional.upsample` is deprecated. Use `nn.functional.interpolate` instead.\n",
      "  x = F.upsample(x, scale_factor=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    5 | MSE: 0.008273 | Interp: 0.045350 | GP NLL: 0.0137 | ‚Ñì: 1.00 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.497\n",
      "Epoch   10 | MSE: 0.004539 | Interp: 0.037264 | GP NLL: 0.0128 | ‚Ñì: 1.00 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.495\n",
      "Epoch   15 | MSE: 0.003405 | Interp: 0.030681 | GP NLL: 0.0112 | ‚Ñì: 1.01 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.492\n",
      "Epoch   20 | MSE: 0.002854 | Interp: 0.027375 | GP NLL: 0.0093 | ‚Ñì: 1.02 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.490\n",
      "Epoch   25 | MSE: 0.002402 | Interp: 0.026184 | GP NLL: 0.0092 | ‚Ñì: 1.02 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.488\n",
      "Epoch   30 | MSE: 0.002214 | Interp: 0.024415 | GP NLL: 0.0091 | ‚Ñì: 1.03 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.486\n",
      "Epoch   35 | MSE: 0.002067 | Interp: 0.023304 | GP NLL: 0.0081 | ‚Ñì: 1.03 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.484\n",
      "Epoch   40 | MSE: 0.001946 | Interp: 0.022318 | GP NLL: 0.0079 | ‚Ñì: 1.04 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.482\n",
      "Epoch   45 | MSE: 0.001864 | Interp: 0.021306 | GP NLL: 0.0075 | ‚Ñì: 1.04 | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): 0.480\n"
     ]
    }
   ],
   "source": [
    "history = {}\n",
    "start_time = time.time()\n",
    "\n",
    "# Get validation view indices for per-view MSE tracking\n",
    "val_Rid = val_data.Rid.to(device)\n",
    "val_view_angles = sorted([int(v * 20) for v in val_data.Rid.unique().tolist()])\n",
    "print(f\"\udcca Tracking per-view MSE for validation angles: {val_view_angles}¬∞\")\n",
    "\n",
    "print(f\"\\n\ud83düöÄ Training GP-VAE with {KERNEL_TYPE} kernel for {CONFIG['epochs']} epochs...\")\n",
    "print(f\"   Task: INTERPOLATION (predicting unseen intermediate views)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for epoch in range(CONFIG['epochs']):\n",
    "    epoch_start = time.time()\n",
    "\n",
    "    Zm, Zs = encode_Y(vae, train_queue)\n",
    "    Eps = Variable(torch.randn(*Zs.shape), requires_grad=False).to(device)\n",
    "    Z = Zm + Eps * Zs\n",
    "\n",
    "    Vt = vm(Dt, Wt).detach()\n",
    "    Vv = vm(Dv, Wv).detach()\n",
    "\n",
    "    # Pass val_Rid for per-view MSE computation\n",
    "    rv_eval, imgs, covs = eval_step(vae, gp, vm, val_queue, Zm, Vt, Vv, Wv, val_Rid)\n",
    "    Zb, Vbs, vbs, gp_nll = gp.taylor_coeff(Z, [Vt])\n",
    "    rv_eval[\"gp_nll\"] = float(gp_nll.data.mean().cpu()) / vae.K\n",
    "\n",
    "    rv_back = backprop_and_update(vae, gp, vm, train_queue, Dt, Wt, Eps, Zb, Vbs, vbs, vae_optimizer, gp_optimizer)\n",
    "    rv_back[\"loss\"] = rv_back[\"recon_term\"] + rv_eval[\"gp_nll\"] + rv_back[\"pen_term\"]\n",
    "\n",
    "    smartAppendDict(history, rv_eval)\n",
    "    smartAppendDict(history, rv_back)\n",
    "    smartAppend(history, \"vs\", gp.get_vs().data.cpu().numpy())\n",
    "\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    vs = gp.get_vs().data.cpu().numpy()\n",
    "    variance_ratio = vs[0] / (vs[0] + vs[1])\n",
    "\n",
    "    # Get learned lengthscale\n",
    "    learned_ls = vm.kernel.lengthscale.item()\n",
    "\n",
    "    if epoch % 5 == 0 or epoch == CONFIG['epochs'] - 1:\n",
    "        # Print per-view MSE summary\n",
    "        view_mse_str = \" | \".join([f\"{a}¬∞:{rv_eval[f'mse_view_{a:03d}']:.4f}\" for a in val_view_angles])\n",
    "        print(f\"Epoch {epoch:4d} | MSE: {rv_back['mse']:.6f} | Interp: {rv_eval['mse_out']:.6f} | \"\n",
    "              f\"GP NLL: {rv_eval['gp_nll']:.4f} | ‚Ñì: {learned_ls:.2f} | v‚ÇÄ/(v‚ÇÄ+v‚ÇÅ): {variance_ratio:.3f}\")\n",
    "        print(f\"         Per-view: {view_mse_str}\")\n",
    "\n",
    "    if CONFIG['use_wandb']:\n",
    "        # Log basic metrics\n",
    "        log_dict = {\n",
    "            \"epoch\": epoch, \"mse_train\": rv_back[\"mse\"], \"mse_interp\": rv_eval[\"mse_out\"],\n",
    "            \"gp_nll\": rv_eval[\"gp_nll\"], \"lengthscale\": learned_ls, \"variance_ratio\": variance_ratio,\n",
    "        }\n",
    "        # Log per-view MSE\n",
    "        for angle in val_view_angles:\n",
    "            log_dict[f\"mse_view_{angle:03d}\"] = rv_eval[f\"mse_view_{angle:03d}\"]\n",
    "        wandb.log(log_dict)\n",
    "\n",
    "    if epoch % CONFIG['epoch_cb'] == 0 or epoch == CONFIG['epochs'] - 1:\n",
    "        torch.save(vae.state_dict(), os.path.join(wdir, f\"vae_weights.{epoch:05d}.pt\"))\n",
    "        torch.save({'gp_state': gp.state_dict(), 'vm_state': vm.state_dict()},\n",
    "                   os.path.join(wdir, f\"gp_weights.{epoch:05d}.pt\"))\n",
    "        ffile = os.path.join(fdir, f\"plot.{epoch:05d}.png\")\n",
    "        callback_gppvae(epoch, history, covs, imgs, ffile)\n",
    "        if CONFIG['use_wandb']:\n",
    "            wandb.log({\"reconstructions\": wandb.Image(ffile)})\n",
    "        print(f\"  ‚úì Checkpoint saved\")\n",
    "\n",
    "print(f\"\\n‚úÖ Complete! Time: {(time.time()-start_time)/60:.1f}min\")\n",
    "print(f\"   Final interpolation MSE: {rv_eval['mse_out']:.6f}\")\n",
    "print(f\"   Learned lengthscale: {learned_ls:.2f}\")\n",
    "print(f\"\\nüìä Final per-view MSE:\")\n",
    "for angle in val_view_angles:\n",
    "    print(f\"   {angle:3d}¬∞: {rv_eval[f'mse_view_{angle:03d}']:.6f}\")\n",
    "if CONFIG['use_wandb']: wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fe0e78",
   "metadata": {
    "id": "b3fe0e78"
   },
   "source": [
    "## 13. Evaluate on Test Set (Optional)\n",
    "\n",
    "Test set contains views [3, 7, 11, 15] ‚Üí angles [60¬∞, 140¬∞, 220¬∞, 300¬∞]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720ebb3a",
   "metadata": {
    "id": "720ebb3a"
   },
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_data = COIL100Dataset(CONFIG['data'], split='test', use_angle_encoding=False)\n",
    "test_queue = DataLoader(test_data, batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "\n",
    "test_views = sorted(test_data.Rid.unique().tolist())\n",
    "print(f\"Test views (Rid): {test_views} ‚Üí angles {[v*20 for v in test_views]}¬∞\")\n",
    "print(f\"Test samples: {len(test_data)}\")\n",
    "\n",
    "# Create test tensors\n",
    "Dtest = Variable(test_data.Did.long(), requires_grad=False).to(device)\n",
    "Wtest = Variable(test_data.Rid.long(), requires_grad=False).to(device)\n",
    "\n",
    "# Evaluate\n",
    "vae.eval()\n",
    "vm.eval()\n",
    "gp.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Re-encode training data\n",
    "    Zm, _ = encode_Y(vae, train_queue)\n",
    "    Vt = vm(Dt, Wt).detach()\n",
    "    Vtest = vm(Dtest, Wtest).detach()\n",
    "\n",
    "    # GP prediction for test set\n",
    "    vs = gp.get_vs()\n",
    "    U, UBi, _ = gp.U_UBi_Shb([Vt], vs)\n",
    "    Kiz = gp.solve(Zm, U, UBi, vs)\n",
    "    Zo_test = vs[0] * Vtest.mm(Vt.transpose(0, 1).mm(Kiz))\n",
    "\n",
    "    # Per-view test MSE\n",
    "    test_Rid = test_data.Rid\n",
    "    mse_per_view = {}\n",
    "    mse_test_total = 0.0\n",
    "    \n",
    "    for data in test_queue:\n",
    "        idxs = data[-1].to(device)\n",
    "        Ytest = data[0].to(device)\n",
    "        Yo = vae.decode(Zo_test[idxs])\n",
    "        mse_batch = ((Ytest - Yo) ** 2).view(Ytest.shape[0], -1).mean(1)\n",
    "        \n",
    "        # Accumulate per-view\n",
    "        for i, idx in enumerate(data[-1]):\n",
    "            view = int(test_Rid[idx].item())\n",
    "            if view not in mse_per_view:\n",
    "                mse_per_view[view] = []\n",
    "            mse_per_view[view].append(mse_batch[i].item())\n",
    "        \n",
    "        mse_test_total += mse_batch.sum().item()\n",
    "\n",
    "    mse_test = mse_test_total / len(test_data)\n",
    "    print(f\"\\nüéØ Test MSE (interpolation to unseen views): {mse_test:.6f}\")\n",
    "    print(f\"\\nüìä Test per-view MSE:\")\n",
    "    for view in sorted(mse_per_view.keys()):\n",
    "        angle = int(view * 20)\n",
    "        view_mse = np.mean(mse_per_view[view])\n",
    "        print(f\"   {angle:3d}¬∞: {view_mse:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e724a6d",
   "metadata": {
    "id": "4e724a6d"
   },
   "source": [
    "## 14. View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5583cc70",
   "metadata": {
    "id": "5583cc70"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import glob\n",
    "\n",
    "plot_files = sorted(glob.glob(os.path.join(fdir, \"*.png\")))\n",
    "if plot_files:\n",
    "    display(Image(filename=plot_files[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e370f573",
   "metadata": {
    "id": "e370f573"
   },
   "source": [
    "## 15. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5c0a08",
   "metadata": {
    "id": "cb5c0a08"
   },
   "outputs": [],
   "source": [
    "!zip -r /content/gppvae_periodic_interpolation_output.zip {CONFIG['outdir']}\n",
    "from google.colab import files\n",
    "files.download('/content/gppvae_periodic_interpolation_output.zip')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
